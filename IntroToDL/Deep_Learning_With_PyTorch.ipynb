{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1q6LpgsXf8mQsy_Cg1hA6LTDnn5JGsEhf","authorship_tag":"ABX9TyN2dmHWeZJUKHQNCsS68out"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a03374b4b0c14ab9b46959ffc0e72886":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d8c4ad63df5341e091d5510c30519ca9","IPY_MODEL_c0cd5b7d04a041cb8381cecca50fac6f","IPY_MODEL_05aa96eeb13448cdac4af1a75ec9b0f1"],"layout":"IPY_MODEL_88d561ca8a354e9fb42ba38480407cac"}},"d8c4ad63df5341e091d5510c30519ca9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_38c3e88851824a1ebd39a186ce8180b3","placeholder":"​","style":"IPY_MODEL_af005a11fcac441bb634cb609fca5d97","value":""}},"c0cd5b7d04a041cb8381cecca50fac6f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b42abadbd6564831bc7df59dc8390a9e","max":9912422,"min":0,"orientation":"horizontal","style":"IPY_MODEL_852120de77a94062a8b8d40846c03921","value":9912422}},"05aa96eeb13448cdac4af1a75ec9b0f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c31f9af80386459f984dedc8aa011f93","placeholder":"​","style":"IPY_MODEL_8e9574f5561e4c5c8879cea2faa783d7","value":" 9913344/? [00:00&lt;00:00, 7063015.01it/s]"}},"88d561ca8a354e9fb42ba38480407cac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38c3e88851824a1ebd39a186ce8180b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af005a11fcac441bb634cb609fca5d97":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b42abadbd6564831bc7df59dc8390a9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"852120de77a94062a8b8d40846c03921":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c31f9af80386459f984dedc8aa011f93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e9574f5561e4c5c8879cea2faa783d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e108e139b0a841b2ad08c1f946d8372b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cbaf9e9e35da41f1bef39985e6e53663","IPY_MODEL_49e335d8a53242d987d38aba36a4990b","IPY_MODEL_12c7f6e8fe1e4463a3fcea184ead61a2"],"layout":"IPY_MODEL_1d954e36bb254ac28865b23f9565c427"}},"cbaf9e9e35da41f1bef39985e6e53663":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d1500ae5cab4d108b1c431d90d41d25","placeholder":"​","style":"IPY_MODEL_d276040e87aa45969f39bd97224c1870","value":""}},"49e335d8a53242d987d38aba36a4990b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8b2756875884849abdeeafdacf4b277","max":28881,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c7dc0f3f26fa44b3bb97c3552dc4a802","value":28881}},"12c7f6e8fe1e4463a3fcea184ead61a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_136bdab0aa584d0d875ff42364a6ec24","placeholder":"​","style":"IPY_MODEL_fae0e751da1f4e7d9cbbe4882cf80db2","value":" 29696/? [00:00&lt;00:00, 539094.68it/s]"}},"1d954e36bb254ac28865b23f9565c427":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d1500ae5cab4d108b1c431d90d41d25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d276040e87aa45969f39bd97224c1870":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b8b2756875884849abdeeafdacf4b277":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7dc0f3f26fa44b3bb97c3552dc4a802":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"136bdab0aa584d0d875ff42364a6ec24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fae0e751da1f4e7d9cbbe4882cf80db2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b115e6fd3f14a8794028f38864e4cd9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1ccb3c7dea29417d9b9342ad89fb68f1","IPY_MODEL_9ae8ab5eed434c71881596ca83ccf5fc","IPY_MODEL_3573252a8ee144e3a869b096b8629a4a"],"layout":"IPY_MODEL_b5a6bc8837a2474da431288549e36efb"}},"1ccb3c7dea29417d9b9342ad89fb68f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ab27203173749c28c59afcbd20da860","placeholder":"​","style":"IPY_MODEL_774dd0765e734e73b9e4a7e8391f0db3","value":""}},"9ae8ab5eed434c71881596ca83ccf5fc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_962600532bc54dd199cb7df5fd5691a2","max":1648877,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8102a725b86a4beca5b54d7b05544c95","value":1648877}},"3573252a8ee144e3a869b096b8629a4a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eca3a09520d8463a9da81f1a805a0957","placeholder":"​","style":"IPY_MODEL_2e3d420feee741a79d4791e19357892d","value":" 1649664/? [00:00&lt;00:00, 17276902.96it/s]"}},"b5a6bc8837a2474da431288549e36efb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ab27203173749c28c59afcbd20da860":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"774dd0765e734e73b9e4a7e8391f0db3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"962600532bc54dd199cb7df5fd5691a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8102a725b86a4beca5b54d7b05544c95":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eca3a09520d8463a9da81f1a805a0957":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e3d420feee741a79d4791e19357892d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d640bed41c8c49048126b18fce032920":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_77054d034f5c43479d449438fcef1833","IPY_MODEL_e11690fcc01941af8ab1a113fdd06a1c","IPY_MODEL_e3398cd2f99447a5a5afb89db8290a7b"],"layout":"IPY_MODEL_f0429acdd0434fa5b925622c3f521a74"}},"77054d034f5c43479d449438fcef1833":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_20032fd32f9f4fec9635207d462b3312","placeholder":"​","style":"IPY_MODEL_eafc36b52ad64dde81e81009f8f27959","value":""}},"e11690fcc01941af8ab1a113fdd06a1c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_901841b26e54463d92959be9a00daf4e","max":4542,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bcdaf068e4204252b89eade551567408","value":4542}},"e3398cd2f99447a5a5afb89db8290a7b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0972bb7908c14843b7ede1805b8167bc","placeholder":"​","style":"IPY_MODEL_e75e3ed1d6474799ab09fc7729c5b915","value":" 5120/? [00:00&lt;00:00, 106019.26it/s]"}},"f0429acdd0434fa5b925622c3f521a74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20032fd32f9f4fec9635207d462b3312":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eafc36b52ad64dde81e81009f8f27959":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"901841b26e54463d92959be9a00daf4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcdaf068e4204252b89eade551567408":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0972bb7908c14843b7ede1805b8167bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e75e3ed1d6474799ab09fc7729c5b915":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a6bcbd3ab3f41118821f69485c118db":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e47067ab7a0b412b84a1c28a6baa30b6","IPY_MODEL_89147e9b34b14f8e847eb46902f352a0","IPY_MODEL_12393f7c85394002807577bb5c1b567b"],"layout":"IPY_MODEL_d3b2594c6bc940b294cfbdb285c2c33b"}},"e47067ab7a0b412b84a1c28a6baa30b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a67c71d7a04496dbb93b03c920b9899","placeholder":"​","style":"IPY_MODEL_9f4a070ef50248e6849c03d85e499622","value":""}},"89147e9b34b14f8e847eb46902f352a0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_687408ebd1074b55b7ef727f6f7947c2","max":9912422,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6664def685354a319889cd01ac396ada","value":9912422}},"12393f7c85394002807577bb5c1b567b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_165dd04570f34f2f8a2a8aa53c58e280","placeholder":"​","style":"IPY_MODEL_d3ed2c3e4bb247e291d9255bb4ba893b","value":" 9913344/? [00:00&lt;00:00, 18563710.97it/s]"}},"d3b2594c6bc940b294cfbdb285c2c33b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a67c71d7a04496dbb93b03c920b9899":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f4a070ef50248e6849c03d85e499622":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"687408ebd1074b55b7ef727f6f7947c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6664def685354a319889cd01ac396ada":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"165dd04570f34f2f8a2a8aa53c58e280":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3ed2c3e4bb247e291d9255bb4ba893b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4eb35a7d1e74bc29e74f4490fffb54f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_42fe5d01ae39459889b8c3dc37a8137a","IPY_MODEL_214e350173e5426e82fcf267d39e09ae","IPY_MODEL_a9ec39fdb41b4177a4b0c9ab979cf5e6"],"layout":"IPY_MODEL_1be10f3694a14a4fb97a2fd520203f1f"}},"42fe5d01ae39459889b8c3dc37a8137a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_445f70f47f9c4f40827cd3cc0d7aec46","placeholder":"​","style":"IPY_MODEL_f666a5d197c24b20980f2eb0ab7fdb23","value":""}},"214e350173e5426e82fcf267d39e09ae":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ab81e01dbe9445a9475b258a2eb50d6","max":28881,"min":0,"orientation":"horizontal","style":"IPY_MODEL_02f58df0ee39458bb1c1993c1f8f1e2b","value":28881}},"a9ec39fdb41b4177a4b0c9ab979cf5e6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e93fc104ba345dcab10117f2c8d093d","placeholder":"​","style":"IPY_MODEL_b920db6e7cac4be2ba6a4c524293d74b","value":" 29696/? [00:00&lt;00:00, 457984.97it/s]"}},"1be10f3694a14a4fb97a2fd520203f1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"445f70f47f9c4f40827cd3cc0d7aec46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f666a5d197c24b20980f2eb0ab7fdb23":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8ab81e01dbe9445a9475b258a2eb50d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02f58df0ee39458bb1c1993c1f8f1e2b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3e93fc104ba345dcab10117f2c8d093d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b920db6e7cac4be2ba6a4c524293d74b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e5f9dcb624764d05b9bbb8ac97c96552":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_831aa47cd1974775b630ef71ce32b830","IPY_MODEL_68c50b7991f943a0a2075345478afee8","IPY_MODEL_72673ffc65b54b54aea6e0d58f3d5082"],"layout":"IPY_MODEL_9f10fe6b944a43e383282e6bd335167a"}},"831aa47cd1974775b630ef71ce32b830":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8562451600c34de1806c23c55854a40d","placeholder":"​","style":"IPY_MODEL_ae84fefc067142348fcfc9667961683f","value":""}},"68c50b7991f943a0a2075345478afee8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9643f30849b940858ef64e26baf4b410","max":1648877,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e754bf55528d4e499246959980b22de2","value":1648877}},"72673ffc65b54b54aea6e0d58f3d5082":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_23b6f6023132458796cfbf547eb42e1e","placeholder":"​","style":"IPY_MODEL_9fb42f486b2c49baa5982f7a50fed6a8","value":" 1649664/? [00:00&lt;00:00, 9818811.59it/s]"}},"9f10fe6b944a43e383282e6bd335167a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8562451600c34de1806c23c55854a40d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae84fefc067142348fcfc9667961683f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9643f30849b940858ef64e26baf4b410":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e754bf55528d4e499246959980b22de2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"23b6f6023132458796cfbf547eb42e1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fb42f486b2c49baa5982f7a50fed6a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5899e62a1058491bb36f536f2a125740":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9ecbb16984c449f39571316b6a010737","IPY_MODEL_848c150d08f942dfafe9c9152476c405","IPY_MODEL_a88a020ca7f645749d0d56a75667b0b2"],"layout":"IPY_MODEL_67161c6868844e638b7efa3077837299"}},"9ecbb16984c449f39571316b6a010737":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43287a76ae4447d2b059132e400f973b","placeholder":"​","style":"IPY_MODEL_2932e992948b4d0ea8486fe91e4360f5","value":""}},"848c150d08f942dfafe9c9152476c405":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0277f41bb924447aab51af6b3f38b70","max":4542,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3ea65e15897a484f84f830b0256fb650","value":4542}},"a88a020ca7f645749d0d56a75667b0b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e781e8f1c4548b68979d7d398b624c7","placeholder":"​","style":"IPY_MODEL_8e3d291b32634c888cc3bf8a51c638d1","value":" 5120/? [00:00&lt;00:00, 9091.96it/s]"}},"67161c6868844e638b7efa3077837299":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43287a76ae4447d2b059132e400f973b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2932e992948b4d0ea8486fe91e4360f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b0277f41bb924447aab51af6b3f38b70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ea65e15897a484f84f830b0256fb650":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7e781e8f1c4548b68979d7d398b624c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e3d291b32634c888cc3bf8a51c638d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["From \"**Deep Learning with PyTorch**\" YouTube Video: [Click here for the link](https://www.youtube.com/watch?v=c36lUUr864M&t=6491s)"],"metadata":{"id":"o1VPw7keeBC3"}},{"cell_type":"markdown","source":["# Tensor Basics"],"metadata":{"id":"E4bBGDYSTi4i"}},{"cell_type":"markdown","source":["* Everything in pytorch is based on Tensor operations.\n","* A tensor can have different dimensions\n","* So it can be 1d, 2d, or even 3d and higher"],"metadata":{"id":"gCXp9qfvY8ST"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8P2Si2f2PILz"},"outputs":[],"source":["import torch"]},{"cell_type":"markdown","source":[" scalar, vector, matrix, tensor;\n"," `torch.empty(size)`: uninitiallized"],"metadata":{"id":"A-uGFrmUZg93"}},{"cell_type":"code","source":["x = torch.empty(1) # scalar\n","print(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_6BDI3WUPMq3","executionInfo":{"status":"ok","timestamp":1653619462783,"user_tz":-540,"elapsed":252,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"357b061b-5991-4696-cc63-dfda0d6f9559"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([4.6975e-35])\n"]}]},{"cell_type":"code","source":["x = torch.empty(3) # vector, 1D\n","print(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7BCp8-IMPj3q","executionInfo":{"status":"ok","timestamp":1653620063629,"user_tz":-540,"elapsed":7,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"b11ec068-3872-4015-d773-97f10ca98b2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([4.6977e-35, 0.0000e+00, 1.5975e-43])\n"]}]},{"cell_type":"code","source":["x = torch.empty(2,3) # matrix, 2D\n","print(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O-tTQ_5cP0ba","executionInfo":{"status":"ok","timestamp":1653620339026,"user_tz":-540,"elapsed":277,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"80c5997a-e9a1-40e3-f634-fef07f91da0a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[4.6977e-35, 0.0000e+00, 1.5975e-43],\n","        [1.3873e-43, 1.4574e-43, 6.4460e-44]])\n"]}]},{"cell_type":"code","source":["x = torch.empty(2,2,3) # tensor, 3 dimensions\n","#x = torch.empty(2,2,2,3) # tensor, 4 dimensions\n","print(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q2qgwNCHP0ji","executionInfo":{"status":"ok","timestamp":1653620402835,"user_tz":-540,"elapsed":271,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"1208dec1-27d5-4af1-f5cc-0a69be0f659d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[4.6976e-35, 0.0000e+00, 2.3694e-38],\n","         [2.3694e-38, 2.3694e-38, 2.3694e-38]],\n","\n","        [[3.7293e-08, 1.4838e-41, 0.0000e+00],\n","         [0.0000e+00, 0.0000e+00, 0.0000e+00]]])\n"]}]},{"cell_type":"code","source":["# torch.rand(size): random numbers [0, 1]\n","x = torch.rand(5, 3)\n","print(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QRoKjYYZP0mS","executionInfo":{"status":"ok","timestamp":1653620445167,"user_tz":-540,"elapsed":261,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"3f2154bd-54ef-4b06-9a83-b5a6557a1008"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.5672, 0.8228, 0.3395],\n","        [0.3979, 0.6180, 0.6771],\n","        [0.1103, 0.5884, 0.7290],\n","        [0.7251, 0.5134, 0.1976],\n","        [0.3679, 0.4008, 0.2950]])\n"]}]},{"cell_type":"code","source":["x = torch.zeros(2, 3) # fill with 0\n","print(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V4qpPBSxP0pS","executionInfo":{"status":"ok","timestamp":1653618069248,"user_tz":-540,"elapsed":252,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"8f497ce6-c048-428d-ae58-c716ec1c0817"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0., 0., 0.],\n","        [0., 0., 0.]])\n"]}]},{"cell_type":"code","source":["x = torch.ones(2, 3) # fill with 1\n","print(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pxYJn6vWP0sB","executionInfo":{"status":"ok","timestamp":1653618092502,"user_tz":-540,"elapsed":266,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"31a9946d-949a-4682-8203-46d24a917568"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 1., 1.],\n","        [1., 1., 1.]])\n"]}]},{"cell_type":"code","source":["x = torch.ones(2, 3)\n","print(x.dtype) # check data type"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"id1va3WCP0vS","executionInfo":{"status":"ok","timestamp":1653618133746,"user_tz":-540,"elapsed":284,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"726fe0e4-c139-4435-d30c-8a678d208de3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.float32\n"]}]},{"cell_type":"code","source":["x = torch.ones(2, 3, dtype=torch.int)\n","print(x.dtype)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mVdqApqqP0yB","executionInfo":{"status":"ok","timestamp":1653618171790,"user_tz":-540,"elapsed":252,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"df7bd3d4-f8a9-48a1-a6be-1ee11ff31a01"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.int32\n"]}]},{"cell_type":"code","source":["x = torch.ones(2, 3, dtype=torch.double)\n","print(x.dtype)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xJ0y6L2mP00x","executionInfo":{"status":"ok","timestamp":1653618195476,"user_tz":-540,"elapsed":272,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"ca257805-834f-42e6-d6d3-f09d9d67f590"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.float64\n"]}]},{"cell_type":"code","source":["x = torch.ones(2, 3, dtype=torch.float16)\n","print(x.dtype)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aQzGv07BP03y","executionInfo":{"status":"ok","timestamp":1653618216082,"user_tz":-540,"elapsed":269,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"7b51cb34-e87a-4f6d-8fbc-f63160f277df"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.float16\n"]}]},{"cell_type":"code","source":["x = torch.ones(2, 3, dtype=torch.float16)\n","print(x.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lb9ThaOEP06i","executionInfo":{"status":"ok","timestamp":1653618254579,"user_tz":-540,"elapsed":265,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"06a70501-d9c8-4efb-88ae-730e562e2041"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 3])\n"]}]},{"cell_type":"code","source":["x = torch.tensor([2.5, 0.1])\n","print(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_LxfnTk7P09z","executionInfo":{"status":"ok","timestamp":1653621767625,"user_tz":-540,"elapsed":245,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"e8cf2e0d-9d63-49f2-dca0-a187affe265e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([2.5000, 0.1000])\n"]}]},{"cell_type":"code","source":["# Operations\n","x = torch.rand(2, 2)\n","y = torch.rand(2, 2)\n","print(x)\n","print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9botrJqlP1Ai","executionInfo":{"status":"ok","timestamp":1653621779691,"user_tz":-540,"elapsed":262,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"a34dcce2-4247-4cc5-887a-03c26c994790"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.9094, 0.8179],\n","        [0.8646, 0.9581]])\n","tensor([[0.2120, 0.5753],\n","        [0.1175, 0.2905]])\n"]}]},{"cell_type":"code","source":["z = x + y # elementwise addition\n","print(z)\n","z=torch.add(x,y)\n","print(z)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7s3OfN2WVcnU","executionInfo":{"status":"ok","timestamp":1653621781752,"user_tz":-540,"elapsed":274,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"2f246e8e-40c1-4e6e-8e1c-7436750d60d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1.1215, 1.3932],\n","        [0.9820, 1.2486]])\n","tensor([[1.1215, 1.3932],\n","        [0.9820, 1.2486]])\n"]}]},{"cell_type":"markdown","source":["Everything with a trailing underscore is an inplace operation i.e. it will modify the variable"],"metadata":{"id":"9CaMw_KNiBMw"}},{"cell_type":"code","source":["y.add_(x) # in place addition\n","print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fqKj3hw0Vcqi","executionInfo":{"status":"ok","timestamp":1653621785569,"user_tz":-540,"elapsed":276,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"2d168c78-e4d4-4e63-d4e8-573a8376fd58"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1.1215, 1.3932],\n","        [0.9820, 1.2486]])\n"]}]},{"cell_type":"code","source":["# substraction\n","z = x - y\n","print(z)\n","z = torch.sub(x, y)\n","print(z)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l8RnH-BjVcth","executionInfo":{"status":"ok","timestamp":1653621791755,"user_tz":-540,"elapsed":309,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"58064e41-9de4-4566-bfd8-af52ae37ab69"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-0.2120, -0.5753],\n","        [-0.1175, -0.2905]])\n","tensor([[-0.2120, -0.5753],\n","        [-0.1175, -0.2905]])\n"]}]},{"cell_type":"code","source":["# multiplication\n","z = x * y\n","print(z)\n","z = torch.mul(x,y)\n","print(z)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"USE6-y3fVcwR","executionInfo":{"status":"ok","timestamp":1653621826241,"user_tz":-540,"elapsed":259,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"284517f9-c4e2-4977-ad2e-9c2403f55e1a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1.0199, 1.1395],\n","        [0.8490, 1.1963]])\n","tensor([[1.0199, 1.1395],\n","        [0.8490, 1.1963]])\n"]}]},{"cell_type":"code","source":["# division\n","z = x / y\n","print(z)\n","z = torch.div(x,y)\n","print(z)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yohIVvHIVczT","executionInfo":{"status":"ok","timestamp":1653621909842,"user_tz":-540,"elapsed":254,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"71561184-7bf7-4053-b7dc-2e73a91296e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.8109, 0.5871],\n","        [0.8804, 0.7673]])\n","tensor([[0.8109, 0.5871],\n","        [0.8804, 0.7673]])\n"]}]},{"cell_type":"code","source":["# Slicing\n","x = torch.rand(5,3)\n","print(x)\n","print(x[:, 0]) # all rows, column 0\n","print(x[1, :]) # row 1, all columns\n","print(x[1,1]) # element at 1, 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"10aE7JvmVc2h","executionInfo":{"status":"ok","timestamp":1653622019110,"user_tz":-540,"elapsed":298,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"4b6c2ee3-4ef6-478f-af9c-5d5aec4b9a1d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.5249, 0.9961, 0.5842],\n","        [0.9622, 0.0606, 0.8993],\n","        [0.6565, 0.3402, 0.8047],\n","        [0.7752, 0.9877, 0.4872],\n","        [0.8699, 0.8331, 0.1048]])\n","tensor([0.5249, 0.9622, 0.6565, 0.7752, 0.8699])\n","tensor([0.9622, 0.0606, 0.8993])\n","tensor(0.0606)\n"]}]},{"cell_type":"code","source":["# Get the actual value if only 1 element in your tensor\n","print(x[1,1].item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qYIr5IRdVc52","executionInfo":{"status":"ok","timestamp":1653622144512,"user_tz":-540,"elapsed":275,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"66d31deb-42a1-4d0c-aa75-dad6df17d761"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.06058245897293091\n"]}]},{"cell_type":"code","source":["x = torch.rand(5,3) # random uniform in the range [0, 1)]\n","print(x)\n","x = torch.randn(5,3) # random normal \n","print(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ooLNJ7N0KQYK","executionInfo":{"status":"ok","timestamp":1653699376460,"user_tz":-540,"elapsed":273,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"cd009eb8-08f8-4d37-8e38-d5df1e551753"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.4513, 0.1744, 0.8245],\n","        [0.8980, 0.6100, 0.9107],\n","        [0.6592, 0.0993, 0.5298],\n","        [0.2996, 0.3201, 0.1770],\n","        [0.6085, 0.8829, 0.0431]])\n","tensor([[ 0.4141,  0.3286,  0.3980],\n","        [ 0.0365, -0.1027,  0.9783],\n","        [ 1.4268,  0.3441,  2.0506],\n","        [ 0.5388, -0.4085,  0.2203],\n","        [ 0.6451, -0.9974,  0.4990]])\n"]}]},{"cell_type":"code","source":["# Reshape with torch.view()\n","x = torch.randn(4, 4)\n","print(x)\n","y = x.view(16) # 1D tensor, 16=4*4, no of items should be equal\n","print(y)\n","z = x.view(-1, 8)  # a by 8 tensor, -1 makes a to be determined by default\n","print(z)\n","print(x.size(), y.size(), z.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uycBfkyEVc81","executionInfo":{"status":"ok","timestamp":1653699689869,"user_tz":-540,"elapsed":289,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"5a96c761-86c9-492d-8fd0-74d4c306f64a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1.0764,  1.1663, -0.3732, -0.8716],\n","        [-0.0479,  0.7651,  1.3575, -0.2965],\n","        [-0.0433, -0.9484, -0.1214, -0.8519],\n","        [ 1.0038,  0.3724,  0.5212, -0.7675]])\n","tensor([ 1.0764,  1.1663, -0.3732, -0.8716, -0.0479,  0.7651,  1.3575, -0.2965,\n","        -0.0433, -0.9484, -0.1214, -0.8519,  1.0038,  0.3724,  0.5212, -0.7675])\n","tensor([[ 1.0764,  1.1663, -0.3732, -0.8716, -0.0479,  0.7651,  1.3575, -0.2965],\n","        [-0.0433, -0.9484, -0.1214, -0.8519,  1.0038,  0.3724,  0.5212, -0.7675]])\n","torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"]}]},{"cell_type":"code","source":["# Numpy\n","# Converting a Torch Tensor to a NumPy array and vice versa is very easy\n","a = torch.ones(5)\n","print(a)\n","# torch to numpy with .numpy()\n","b = a.numpy()\n","print(b)\n","print(type(b))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G0Svfy9PVdAG","executionInfo":{"status":"ok","timestamp":1653700081892,"user_tz":-540,"elapsed":281,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"60ded724-1f02-4d1f-d328-24352545122f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 1., 1., 1., 1.])\n","[1. 1. 1. 1. 1.]\n","<class 'numpy.ndarray'>\n"]}]},{"cell_type":"markdown","source":["**Careful**: If the Tensor is on the CPU (not the GPU), both objects will share the same memory location, so changing one will also change the other"],"metadata":{"id":"T1jIfQY5M02X"}},{"cell_type":"code","source":["a.add_(1)\n","print(a)\n","print(b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sBvhl9BSVdDV","executionInfo":{"status":"ok","timestamp":1653700087962,"user_tz":-540,"elapsed":282,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"3d168194-5b65-440f-9a2c-e0023bba524e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([2., 2., 2., 2., 2.])\n","[2. 2. 2. 2. 2.]\n"]}]},{"cell_type":"code","source":["# numpy to torch with .from_numpy(x)\n","import numpy as np\n","a = np.ones(5)\n","b = torch.from_numpy(a)\n","print(a)\n","print(b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C9VkxOcbVdGW","executionInfo":{"status":"ok","timestamp":1653700168197,"user_tz":-540,"elapsed":292,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"4d31dddb-842f-447a-d71e-e6377869cb7a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1. 1. 1. 1. 1.]\n","tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"]}]},{"cell_type":"code","source":["# again be careful when modifying\n","a += 1\n","print(a)\n","print(b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XH1BlAD7Nlk2","executionInfo":{"status":"ok","timestamp":1653700200162,"user_tz":-540,"elapsed":310,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"45a93fb8-635c-4e0d-9761-6960945c0250"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2. 2. 2. 2. 2.]\n","tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"]}]},{"cell_type":"markdown","source":["By default all tensors are created on the CPU, but you can also move them to the GPU (only if it's available)"],"metadata":{"id":"8rd2F7hwO9Dd"}},{"cell_type":"code","source":["if torch.cuda.is_available:\n","  device = torch.device(\"cuda\")\n","  x = torch.ones(5, device = device)\n","  print(x)\n","  y = torch.ones(5)\n","  print(y)\n","  y = y.to(device)\n","  z = x + y\n","  print(z)\n","  #z = z.numpy() provides error b/c numpy only handle CPU tensors, not GPU's.\n","  # move to CPU again\n","  z = z.to(\"cpu\")  # ``.to`` can also change dtype together!\n","  print(z)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iOm3TuGaNtpE","executionInfo":{"status":"ok","timestamp":1653701142663,"user_tz":-540,"elapsed":267,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"91168b53-4ae6-44a5-9622-dd60f0ad4afd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 1., 1., 1., 1.], device='cuda:0')\n","tensor([1., 1., 1., 1., 1.])\n","tensor([2., 2., 2., 2., 2.], device='cuda:0')\n","tensor([2., 2., 2., 2., 2.])\n"]}]},{"cell_type":"markdown","source":["`requires_grad` argument tell pytorch that it will need to calculate the gradients for this tensor (later in your optimization steps, i.e. this is *a variable in your model that you want to optimize*)."],"metadata":{"id":"ZXM4KD7sSUTf"}},{"cell_type":"code","source":["x = torch.ones(5, requires_grad=True) # default is False\n","print(x)\n","x = torch.tensor([2.5, 0.1], requires_grad = True) \n","print(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8DC8nKVtNtsG","executionInfo":{"status":"ok","timestamp":1653701442371,"user_tz":-540,"elapsed":411,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"06f9b8e1-6f71-4a29-f394-146dba8f988d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([2.5000, 0.1000], requires_grad=True)\n"]}]},{"cell_type":"markdown","source":["#Autograd: Gradient Computation\n","\n","The autograd package provides automatic differentiation for all operations on Tensors\n","\n","* `requires_grad = True` -> tracks all operations on the tensor. "],"metadata":{"id":"Oslw7g_US1sI"}},{"cell_type":"code","source":["import torch"],"metadata":{"id":"BU9-ELA6NtvD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = torch.randn(3, requires_grad=True)\n","print(x)\n","y = x + 2\n","print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HVMllBOaTrlL","executionInfo":{"status":"ok","timestamp":1653702967040,"user_tz":-540,"elapsed":273,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"129fada3-09a2-4b53-81e4-50324849c121"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([-1.8266,  0.3103,  0.9727], requires_grad=True)\n","tensor([0.1734, 2.3103, 2.9727], grad_fn=<AddBackward0>)\n"]}]},{"cell_type":"markdown","source":["`y` was created as a result of an operation, so it has a `grad_fn` attribute. \n","\n","* `grad_fn`: references a function that has created the tensor.\n","* `AddBackward0` is addition function."],"metadata":{"id":"-Rbovrb6UGZt"}},{"cell_type":"code","source":["print(x) # created by the user -> grad_fn is None\n","print(y)\n","print(y.grad_fn)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vd6X919RTroJ","executionInfo":{"status":"ok","timestamp":1653702247369,"user_tz":-540,"elapsed":295,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"af0f4e57-01a6-4b0b-db89-c9bf3832b4a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([-0.2233, -0.3814,  1.2137], requires_grad=True)\n","tensor([1.7767, 1.6186, 3.2137], grad_fn=<AddBackward0>)\n","<AddBackward0 object at 0x7f0e60351690>\n"]}]},{"cell_type":"code","source":["z = y*y*2\n","print(z)\n","z= z.mean()\n","print(z)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XGD2VHsVTrrI","executionInfo":{"status":"ok","timestamp":1653702429575,"user_tz":-540,"elapsed":266,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"b3f64b9a-9e73-4955-ddc6-4ccf80956c09"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 6.3131,  5.2396, 20.6563], grad_fn=<MulBackward0>)\n","tensor(10.7363, grad_fn=<MeanBackward0>)\n"]}]},{"cell_type":"markdown","source":["Let's compute the gradients with backpropagation. When we finish our computation we can call `.backward()` and have all the gradients computed automatically. The gradient for this tensor will be accumulated into `.grad` attribute. It is the *partial derivate* of the function w.r.t. the tensor."],"metadata":{"id":"B3LJ49doWRkw"}},{"cell_type":"code","source":["z.backward() # Since z is a scalar, no need to put an argument in ()\n","print(x.grad) # dz/dx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZYIfGeEKTrt8","executionInfo":{"status":"ok","timestamp":1653702690653,"user_tz":-540,"elapsed":301,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"39b2a9b8-d839-4ca6-e946-bef9ebeec69d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([2.3689, 2.1581, 4.2850])\n"]}]},{"cell_type":"markdown","source":["Generally speaking, torch.autograd is an engine for computing vector-Jacobian product. It computes partial derivates while applying the chain rule."],"metadata":{"id":"xellxfVRc1Ih"}},{"cell_type":"markdown","source":["If a tensor is non-scalar (more than 1 elements), we need to specify arguments for `backward()` specify a gradient argument that is a tensor of matching shape. Needed for vector-Jacobian product.\n"],"metadata":{"id":"qwSM16s3dBxj"}},{"cell_type":"code","source":["x = torch.randn(3, requires_grad=True)\n","print(x)\n","y = x + 2\n","print(y)\n","z = y*y*2\n","print(z)\n","v= torch.tensor([0.1, 1.0, 0.001], dtype=torch.float32)\n","print(v)\n","z.backward(v) \n","print(x.grad) # dz/dx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ExtzQXVTrxA","executionInfo":{"status":"ok","timestamp":1653704104752,"user_tz":-540,"elapsed":272,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"a2476233-69f3-42c2-92af-3875650ddece"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 1.8898,  0.8628, -0.0724], requires_grad=True)\n","tensor([3.8898, 2.8628, 1.9276], grad_fn=<AddBackward0>)\n","tensor([30.2617, 16.3912,  7.4310], grad_fn=<MulBackward0>)\n","tensor([0.1000, 1.0000, 0.0010])\n","tensor([1.5559e+00, 1.1451e+01, 7.7102e-03])\n"]}]},{"cell_type":"code","source":["x = torch.randn(3, requires_grad=True)\n","\n","y = x * 2\n","for _ in range(10):\n","    y = y * 2\n","print(y)\n","print(y.shape)\n","v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float32)\n","y.backward(v)\n","print(x.grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oJkRr8kKda8z","executionInfo":{"status":"ok","timestamp":1653704365647,"user_tz":-540,"elapsed":272,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"204a3444-2bcb-4c96-8e5d-2c0affedd742"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([   40.8103,   195.6378, -2460.3403], grad_fn=<MulBackward0>)\n","torch.Size([3])\n","tensor([2.0480e+02, 2.0480e+03, 2.0480e-01])\n"]}]},{"cell_type":"markdown","source":["## Stop a tensor from tracking history:\n","For example during our training loop when we want to update our weights, then this update operation should not be part of the gradient computation. Three options: `x.requires_grad_(False)`; `x.detach()` and wrap in '`with torch.no_grad():`'."],"metadata":{"id":"IIrPdlC2eAOC"}},{"cell_type":"markdown","source":["`.requires_grad_(...)` changes an existing flag in-place."],"metadata":{"id":"ojQaFVOXhs2c"}},{"cell_type":"code","source":["x = torch.randn(3, requires_grad=True)\n","print(x)\n","x = x.requires_grad_(False)\n","print(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HJsIDArhhuWj","executionInfo":{"status":"ok","timestamp":1653705555486,"user_tz":-540,"elapsed":285,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"b2ede1a3-32dd-4134-a4df-4fd66ee4c719"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 0.2072, -1.2185, -1.8177], requires_grad=True)\n","tensor([ 0.2072, -1.2185, -1.8177])\n"]}]},{"cell_type":"code","source":["a = torch.randn(2, 2)\n","print(a)\n","print(a.requires_grad)\n","\n","b = ((a * 3) / (a - 1))\n","print(b)\n","print(b.grad_fn)\n","\n","a.requires_grad_(True)\n","print(a.requires_grad)\n","\n","b = (a * a).sum()\n","print(b)\n","print(b.grad_fn)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-BZf7NVQTrzs","executionInfo":{"status":"ok","timestamp":1653705902909,"user_tz":-540,"elapsed":275,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"3808d775-9140-469f-c506-f73434fe5705"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1.8705, -0.4400],\n","        [ 0.2439,  0.2094]])\n","False\n","tensor([[ 6.4464,  0.9166],\n","        [-0.9677, -0.7946]])\n","None\n","True\n","tensor(3.7955, grad_fn=<SumBackward0>)\n","<SumBackward0 object at 0x7f0f1eb2ca50>\n"]}]},{"cell_type":"markdown","source":["`x.detach()` get a new Tensor with the same content but no gradient computation:"],"metadata":{"id":"0Yzrzcw0iL17"}},{"cell_type":"code","source":["a = torch.randn(2, 2, requires_grad=True)\n","print(a)\n","print(a.requires_grad)\n","b = a.detach()\n","print(b)\n","print(b.requires_grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oBoy4LqeTr2u","executionInfo":{"status":"ok","timestamp":1653705931564,"user_tz":-540,"elapsed":266,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"0a05b208-a956-455b-cb16-2a3915e2fe49"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.2120, -0.1929],\n","        [-0.0765, -1.0866]], requires_grad=True)\n","True\n","tensor([[ 0.2120, -0.1929],\n","        [-0.0765, -1.0866]])\n","False\n"]}]},{"cell_type":"markdown","source":["Wrap in '`with torch.no_grad():`'"],"metadata":{"id":"g1FLxUpnirJt"}},{"cell_type":"code","source":["a = torch.randn(2, 2, requires_grad=True)\n","print(a)\n","print(a.requires_grad)\n","with torch.no_grad():\n","  y = a**2\n","  print(y)\n","  print(y.requires_grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IXhwXrCGTr5c","executionInfo":{"status":"ok","timestamp":1653706117514,"user_tz":-540,"elapsed":277,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"a601ca69-f868-4967-ad77-2621a1abc9d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.0272, -0.5992],\n","        [ 0.0538,  0.5871]], requires_grad=True)\n","True\n","tensor([[0.0007, 0.3591],\n","        [0.0029, 0.3447]])\n","False\n"]}]},{"cell_type":"markdown","source":["`backward()` accumulates the gradient for this tensor into `.grad` attribute.\n","* !!! We need to be careful during optimization !!!\n","* Use `.zero_()` to empty the gradients before a new optimization step!"],"metadata":{"id":"4DZlO-Aqkdx1"}},{"cell_type":"code","source":["weights = torch.ones(4, requires_grad=True)\n","\n","for epoch in range(1):\n","    # just a dummy opration\n","    model_output = (weights*3).sum()\n","    model_output.backward()\n","    print(weights.grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wTSGa4BUln4s","executionInfo":{"status":"ok","timestamp":1653706601977,"user_tz":-540,"elapsed":266,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"aeea8233-7735-4ee9-f3d0-85363c0ae9d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([3., 3., 3., 3.])\n"]}]},{"cell_type":"code","source":["weights = torch.ones(4, requires_grad=True)\n","\n","for epoch in range(2):\n","    # just a dummy opration\n","    model_output = (weights*3).sum()\n","    model_output.backward()\n","    print(weights.grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fLLf7uxml9sQ","executionInfo":{"status":"ok","timestamp":1653706606467,"user_tz":-540,"elapsed":272,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"db2ec4af-5e18-4d81-f407-77370571592a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([3., 3., 3., 3.])\n","tensor([6., 6., 6., 6.])\n"]}]},{"cell_type":"code","source":["weights = torch.ones(4, requires_grad=True)\n","\n","for epoch in range(3):\n","    # just a dummy opration\n","    model_output = (weights*3).sum()\n","    model_output.backward()\n","    print(weights.grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yiy53Yc4mIdi","executionInfo":{"status":"ok","timestamp":1653706631878,"user_tz":-540,"elapsed":280,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"f4374a94-5a6f-41fd-fa91-8bc27b5ed5bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([3., 3., 3., 3.])\n","tensor([6., 6., 6., 6.])\n","tensor([9., 9., 9., 9.])\n"]}]},{"cell_type":"markdown","source":["gradients are accumulated at each iteration."],"metadata":{"id":"m1akWhHJmX8w"}},{"cell_type":"code","source":["weights = torch.ones(4, requires_grad=True)\n","\n","for epoch in range(3):\n","    # just a dummy opration\n","    model_output = (weights*3).sum()\n","    model_output.backward()\n","    print(weights.grad)\n","\n","    # this is important! It affects the final weights & output\n","    weights.grad.zero_()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x6jFv7FImWU4","executionInfo":{"status":"ok","timestamp":1653706746125,"user_tz":-540,"elapsed":278,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"27cffe73-64bd-47a0-c7d5-cbc4d8a2d172"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([3., 3., 3., 3.])\n","tensor([3., 3., 3., 3.])\n","tensor([3., 3., 3., 3.])\n"]}]},{"cell_type":"markdown","source":["The gradients above are correct."],"metadata":{"id":"d2XUl8RqmnsT"}},{"cell_type":"code","source":["weights = torch.ones(4, requires_grad=True)\n","\n","for epoch in range(3):\n","    # just a dummy opration\n","    model_output = (weights*3).sum()\n","    model_output.backward()\n","    \n","    print(weights.grad)\n","\n","    # optimize model, i.e. adjust weights...\n","    with torch.no_grad():\n","        weights -= 0.1 * weights.grad\n","\n","    # this is important! It affects the final weights & output\n","    weights.grad.zero_()\n","\n","print(weights)\n","print(model_output)"],"metadata":{"id":"5dDiYjdzNtyG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Builtin Optimizers\n","\n","* Optimizer has `zero_grad()` method."],"metadata":{"id":"x_Fm4boTm6Mn"}},{"cell_type":"code","source":["#weights = torch.ones(4, requires_grad=True)\n","#optimizer = torch.optim.SGD(weights, lr=0.01)\n","#optimizer.step()\n","#optimizer.zero_grad()"],"metadata":{"id":"p_91GgO3Nt1E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Backpropagation\n","\n","Three steps:\n","* Forward pass: compute loss\n","* Compute local gradients\n","* Backward pass: compute dLoss/dWeights using chain rule."],"metadata":{"id":"OqbJEK4ioYTH"}},{"cell_type":"code","source":["import torch"],"metadata":{"id":"vVMoTl7lNt31"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = torch.tensor(1.0)\n","print(x)\n","y = torch.tensor(2.0)\n","print(y)\n","\n","#`w` is the parameter we want to optimize -> `requires_grad=True`\n","w = torch.tensor(1.0, requires_grad=True)\n","print(w)"],"metadata":{"id":"2Bc8jOO7Nt60","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653724049801,"user_tz":-540,"elapsed":281,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"b57d6852-284c-415c-c612-51c8c9ff0813"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(1.)\n","tensor(2.)\n","tensor(1., requires_grad=True)\n"]}]},{"cell_type":"markdown","source":["**Forward pass** to compute loss"],"metadata":{"id":"ePcvfmwTnVZT"}},{"cell_type":"code","source":["y_hat= w * x\n","loss = (y_hat - y)**2\n","print(loss)"],"metadata":{"id":"MjACVdQhNt93","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653724139615,"user_tz":-540,"elapsed":256,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"bd27a808-a0cb-45c0-a0a2-d65f08a4e692"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(1., grad_fn=<PowBackward0>)\n"]}]},{"cell_type":"markdown","source":["**Backward pass** to compute gradient `dLoss/dw`"],"metadata":{"id":"_9RtC3CZpFOG"}},{"cell_type":"code","source":["loss.backward()\n","print(w.grad)\n","# this is the first gradient"],"metadata":{"id":"wGB9_kkHNuBF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653724256135,"user_tz":-540,"elapsed":278,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"d8c9dc62-7d3d-41d5-a34f-b70a2471cddd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(-2.)\n"]}]},{"cell_type":"markdown","source":["**Update weights**: \n","* next forward and backward pass...\n","* continue optimizing:\n","* update weights, this operation should not be part of the computational graph\n"],"metadata":{"id":"-eISF4E4pwt3"}},{"cell_type":"code","source":["with torch.no_grad():\n","    w -= 0.01 * w.grad\n","# don't forget to zero the gradients\n","w.grad.zero_()\n","# next forward and backward pass..."],"metadata":{"id":"9lDylSfMNuEI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653724506790,"user_tz":-540,"elapsed":260,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"2449f0a6-076d-4dec-c30e-f4ded41db376"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.)"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["# Gradient Descent using Autograd"],"metadata":{"id":"vBlY6Ww5qdtx"}},{"cell_type":"markdown","source":["## Step 1: Using `NumPy`\n","\n","Compute every step manually.  \n","* Prediction: Manually\n","* Gradients computation: Manually\n","* Loss computation: Manually\n","* Parameter updates: Manually"],"metadata":{"id":"4c9jIcpOree8"}},{"cell_type":"code","source":["import numpy as np "],"metadata":{"id":"Iq8GUFMLNuHE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Linear regression: `f = w * x`. Here here : `f = 2 * x`. "],"metadata":{"id":"mgdHrPsLrvY8"}},{"cell_type":"code","source":["X = np.array([1, 2, 3, 4], dtype=np.float32)\n","Y = np.array([2, 4, 6, 8], dtype=np.float32)\n","\n","# initializing the weight\n","w = 0.0 "],"metadata":{"id":"UV14TpO6rqDj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Model prediction: `wx`"],"metadata":{"id":"YA94t8BnsOkC"}},{"cell_type":"code","source":["def forward(x):\n","    return w * x"],"metadata":{"id":"eooPokDZrqGj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In linear regression: **Loss = MSE**.\n","$$J = MSE = \\frac{1}{N}(wx - y)^2 $$"],"metadata":{"id":"WGo29M1PsbyQ"}},{"cell_type":"code","source":["def loss(y, y_pred):\n","    return ((y_pred - y)**2).mean()\n"],"metadata":{"id":"b2phjQC_rqJj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Gradient**: \n","Since $J = MSE = \\frac{1}{N}(wx - y)^2 \\Rightarrow \\frac{\\partial{J}}{\\partial{w}} = \\frac{1}{N} \\times 2x\\times (wx - y)$"],"metadata":{"id":"7m-GWpYrsylb"}},{"cell_type":"code","source":["def gradient(x, y, y_pred):\n","    return np.dot(2*x, y_pred - y).mean()\n","    \n","print(f'Prediction before training: f(5) = {forward(5):.3f}')"],"metadata":{"id":"LtLqYHKVrqMj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Training loop**"],"metadata":{"id":"4D24XwL_uB2y"}},{"cell_type":"code","source":["learning_rate = 0.01\n","n_iters = 10                 # Here, 10 iterations\n","\n","for epoch in range(n_iters):\n","    # First we do the prediction = forward pass\n","    y_pred = forward(X)         \n","\n","    # Second caculate the loss\n","    l = loss(Y, y_pred)   \n","\n","    # Third, we need to get the gradients\n","    dw = gradient(X, Y, y_pred) \n","\n","    # Then we have to update the weights\n","    w -= learning_rate * dw    \n","\n","    # we may need to print some information, say every 2nd one\n","    if epoch % 2 == 0:         \n","        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n","     \n","print(f'Prediction after training: f(5) = {forward(5):.3f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VNfTLi1xrqPj","executionInfo":{"status":"ok","timestamp":1653728161704,"user_tz":-540,"elapsed":263,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"e38c1f2a-3fb2-469b-b4d5-cfe08dbef952"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 1: w = 1.200, loss = 30.00000000\n","epoch 3: w = 1.872, loss = 0.76800019\n","epoch 5: w = 1.980, loss = 0.01966083\n","epoch 7: w = 1.997, loss = 0.00050331\n","epoch 9: w = 1.999, loss = 0.00001288\n","Prediction after training: f(5) = 9.999\n"]}]},{"cell_type":"markdown","source":["Next cell increase to 20 iterations, previous cell is 10 iterations."],"metadata":{"id":"p4xeiws0nm0w"}},{"cell_type":"code","source":["learning_rate = 0.01\n","n_iters = 20                 # Now, 20 iterations\n","\n","for epoch in range(n_iters):\n","    # First we do the prediction = forward pass\n","    y_pred = forward(X)         \n","\n","    # Second caculate the loss\n","    l = loss(Y, y_pred)   \n","\n","    # Third, we need to get the gradients\n","    dw = gradient(X, Y, y_pred) \n","\n","    # Then we have to update the weights\n","    w -= learning_rate * dw    \n","\n","    # we may need to print some information, say every 2nd one\n","    if epoch % 2 == 0:         \n","        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n","     \n","print(f'Prediction after training: f(5) = {forward(5):.3f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jdE_ji8GrqSH","executionInfo":{"status":"ok","timestamp":1653728265920,"user_tz":-540,"elapsed":272,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"7755176b-2138-40af-e6ad-79107ed807a7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 1: w = 2.000, loss = 0.00000033\n","epoch 3: w = 2.000, loss = 0.00000001\n","epoch 5: w = 2.000, loss = 0.00000000\n","epoch 7: w = 2.000, loss = 0.00000000\n","epoch 9: w = 2.000, loss = 0.00000000\n","epoch 11: w = 2.000, loss = 0.00000000\n","epoch 13: w = 2.000, loss = 0.00000000\n","epoch 15: w = 2.000, loss = 0.00000000\n","epoch 17: w = 2.000, loss = 0.00000000\n","epoch 19: w = 2.000, loss = 0.00000000\n","Prediction after training: f(5) = 10.000\n"]}]},{"cell_type":"markdown","source":["## Using `PyTorch`\n","Here we replace the manually computed gradient with autograd."],"metadata":{"id":"u8IUuhfH5Z1x"}},{"cell_type":"markdown","source":["Step 2:\n","* Prediction: Manually\n","* Gradients computation: **Autograd**\n","* Loss computation: Manually\n","* Parameter updates: Manually"],"metadata":{"id":"Atx0q9ERrSrN"}},{"cell_type":"markdown","source":["Below codes have a difference from that of Numpy. The numpy arrays are changed to torch tensors. And, the initialized weight should get its type and since we are interested in the gradient of the loss w.r.t this parameter, we need to specify `requires_grad=True`."],"metadata":{"id":"S_iCxG1o6eZo"}},{"cell_type":"code","source":["import torch"],"metadata":{"id":"RXfSPqKuNuKZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n","Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n","\n","w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)"],"metadata":{"id":"0tAvRF9K5lUV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The prediction equation and loss function are similar to the case of Numpy. But, the manually computed gradient function is not needed here."],"metadata":{"id":"NdiTttj16klx"}},{"cell_type":"code","source":["def forward(x):\n","    return w * x\n","\n","def loss(y, y_pred):\n","    return ((y_pred - y)**2).mean()"],"metadata":{"id":"_Ycek9EH5lYl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In the training loop, we simply call `l.backward` to compute the gradient instead of `dw = gradient(X, Y, y_pred)`.\n","\n","Also, as said before, the weight update (`w -= learning_rate * dw`) should not be part of the gradient tracking graph (computational graph), hence, we need to wrap it `with torch.no_grad():`.\n","\n","One more thing, we should also know we must empty or zero the gradients again because whenever we call `.backward` it will ride our gradients and accumulate them in the `w.grad` attribute. So before the next iteration we want to make sure that our gradients are zero again. So we say `w.grad.zero_()`."],"metadata":{"id":"UO4LClma9EB7"}},{"cell_type":"code","source":["learning_rate = 0.01\n","n_iters = 20                 # 20 iterations\n","\n","for epoch in range(n_iters):\n","    # First we do the prediction = forward pass\n","    y_pred = forward(X)        \n","\n","    # Second caculate the loss\n","    l = loss(Y, y_pred)         \n","    \n","    # Third, get the gradients: dl/dw (backward pass)\n","    l.backward()    # dw = gradient(X, Y, y_pred)  \n","\n","    # Then we have to update the weights\n","    with torch.no_grad():\n","      w -= learning_rate * w.grad     \n","\n","    # zero the gradients after updating\n","    w.grad.zero_()       \n","\n","    # we may need to print every 2nd information\n","    if epoch % 2 == 0:          \n","        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n","     \n","print(f'Prediction after training: f(5) = {forward(5):.3f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_6vJ4Mbg5lb1","executionInfo":{"status":"ok","timestamp":1653788261280,"user_tz":-540,"elapsed":284,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"30078f99-a005-4133-e116-0518b8cb36d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 1: w = 0.300, loss = 30.00000000\n","epoch 3: w = 0.772, loss = 15.66018772\n","epoch 5: w = 1.113, loss = 8.17471695\n","epoch 7: w = 1.359, loss = 4.26725292\n","epoch 9: w = 1.537, loss = 2.22753215\n","epoch 11: w = 1.665, loss = 1.16278565\n","epoch 13: w = 1.758, loss = 0.60698116\n","epoch 15: w = 1.825, loss = 0.31684780\n","epoch 17: w = 1.874, loss = 0.16539653\n","epoch 19: w = 1.909, loss = 0.08633806\n","Prediction after training: f(5) = 9.612\n"]}]},{"cell_type":"markdown","source":["As usual, it increase our `w` and decrease our loss, but, `f(5)=9.924` is not completely correct. Let us try some more iterations, say 100, and print the every 10th information.\n"],"metadata":{"id":"u3r27cJCB0YE"}},{"cell_type":"code","source":["learning_rate = 0.01\n","n_iters = 100                 # 100 iterations\n","\n","for epoch in range(n_iters):\n","    # First we do the prediction = forward pass\n","    y_pred = forward(X)        \n","\n","    # Second caculate the loss\n","    l = loss(Y, y_pred)         \n","    \n","    # Third, get the gradients: dl/dw (backward pass)\n","    l.backward()    # dw = gradient(X, Y, y_pred)  \n","\n","    # Then we have to update the weights\n","    with torch.no_grad():\n","      w -= learning_rate * w.grad     \n","\n","    # zero the gradients after updating\n","    w.grad.zero_()       \n","\n","    # we may need to print every 2nd information\n","    if epoch % 10 == 0:          \n","        print(f'epoch {epoch+10}: w = {w:.3f}, loss = {l:.8f}')\n","     \n","print(f'Prediction after training: f(5) = {forward(5):.3f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fnnHgN1F5lfH","executionInfo":{"status":"ok","timestamp":1653788514556,"user_tz":-540,"elapsed":287,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"60d88a2a-7160-4045-89f3-c44e8cff6be6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 10: w = 2.000, loss = 0.00000000\n","epoch 20: w = 2.000, loss = 0.00000000\n","epoch 30: w = 2.000, loss = 0.00000000\n","epoch 40: w = 2.000, loss = 0.00000000\n","epoch 50: w = 2.000, loss = 0.00000000\n","epoch 60: w = 2.000, loss = 0.00000000\n","epoch 70: w = 2.000, loss = 0.00000000\n","epoch 80: w = 2.000, loss = 0.00000000\n","epoch 90: w = 2.000, loss = 0.00000000\n","epoch 100: w = 2.000, loss = 0.00000000\n","Prediction after training: f(5) = 10.000\n"]}]},{"cell_type":"markdown","source":["# Training Pipline\n","\n","Model/Loss/Optimizer "],"metadata":{"id":"NJrqeCsVC-ws"}},{"cell_type":"markdown","source":["Step 3:\n","* Prediction: Manually\n","* Gradients computation: Autograd\n","* Loss computation: **PyTorch Loss**\n","* Parameter updates: **PyTorch Optimizer**"],"metadata":{"id":"-QKycpJarSzr"}},{"cell_type":"markdown","source":["1. Design model (input size, output size, forward pass with different layers)\n","2. Construct loss and optimizer\n","3. Training loop\n"," > * Start with forward path= compute prediction and loss \\\\\n"," > * Next do the backward path= compute gradients \\\\\n"," > * Then, update weights\n"],"metadata":{"id":"gVbDBAA4hEn0"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn"],"metadata":{"id":"VF9q0MeaC4C6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Linear regression: $f = wx$. Here : $f = 2x$\n","\n","0. **Training samples**"],"metadata":{"id":"BQKxaZ3aqc0y"}},{"cell_type":"code","source":["X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n","Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)"],"metadata":{"id":"6DskRg_hir2r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1. **Design Model**: Weights to optimize and forward function"],"metadata":{"id":"XY_Wy1lpi94C"}},{"cell_type":"code","source":["w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n","\n","def forward(x):\n","    return w * x\n","\n","print(f'Prediction before training: f(5) = {forward(5).item():.3f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ucOsGQq6dQZq","executionInfo":{"status":"ok","timestamp":1653791771828,"user_tz":-540,"elapsed":837,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"0ea7aecb-97ad-43b8-b7ed-f33feb3057b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction before training: f(5) = 0.000\n"]}]},{"cell_type":"markdown","source":["2. **Define Loss and Optimizer**\n","* no need to define the loss *manually* any more."],"metadata":{"id":"7ory4vq5idIw"}},{"cell_type":"code","source":["learning_rate = 0.01\n","n_iters = 100\n","\n","loss = nn.MSELoss() # callable function\n","\n","optimizer = torch.optim.SGD([w], lr=learning_rate)  # The parameter in .SGD() \n","                                                    # should be a list.                                                  \n"],"metadata":{"id":"exljDFHEdQdN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3. **Training Loop**\n","* no need to manually update our weights."],"metadata":{"id":"WIJT4r9DkPjC"}},{"cell_type":"code","source":["for epoch in range(n_iters):\n","    # predict = forward pass\n","    y_predicted = forward(X)\n","\n","    # loss, the callable function\n","    l = loss(Y, y_predicted) \n","\n","    # calculate gradients = backward pass\n","    l.backward()\n","\n","    # update weights\n","    optimizer.step() \n","\n","    # zero the gradients after updating\n","    optimizer.zero_grad()\n","\n","    if epoch % 10 == 0:\n","        print('epoch ', epoch+10, ': w = ', w, ' loss = ', l)\n","\n","print(f'Prediction after training: f(5) = {forward(5).item():.3f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KpmTR7AedQf-","executionInfo":{"status":"ok","timestamp":1653794996804,"user_tz":-540,"elapsed":266,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"bd2bff2b-e59e-4490-9789-cbfa5326bd78"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch  10 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(8.9884e-13, grad_fn=<MseLossBackward0>)\n","epoch  20 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(8.9884e-13, grad_fn=<MseLossBackward0>)\n","epoch  30 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(8.9884e-13, grad_fn=<MseLossBackward0>)\n","epoch  40 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(8.9884e-13, grad_fn=<MseLossBackward0>)\n","epoch  50 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(8.9884e-13, grad_fn=<MseLossBackward0>)\n","epoch  60 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(8.9884e-13, grad_fn=<MseLossBackward0>)\n","epoch  70 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(8.9884e-13, grad_fn=<MseLossBackward0>)\n","epoch  80 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(8.9884e-13, grad_fn=<MseLossBackward0>)\n","epoch  90 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(8.9884e-13, grad_fn=<MseLossBackward0>)\n","epoch  100 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(8.9884e-13, grad_fn=<MseLossBackward0>)\n","Prediction after training: f(5) = 10.000\n"]}]},{"cell_type":"markdown","source":["# Step 4:\n","* Prediction: **PyTorch Model**\n","* Gradients computation: Autograd\n","* Loss computation: PyTorch Loss\n","* Parameter updates: PyTorch Optimizer"],"metadata":{"id":"OTFBaajYrS7j"}},{"cell_type":"markdown","source":["Now, we do not need to define the model manually. The same is true also for the weights, because, our PyTorch model knows the parameters. "],"metadata":{"id":"yHrlgDA3rLui"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn"],"metadata":{"id":"F8aqT9MMdQi9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["XX = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n","YY= torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n","print(XX.shape)\n","print(YY.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wxZypFKgvm1h","executionInfo":{"status":"ok","timestamp":1653795054536,"user_tz":-540,"elapsed":5,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"40c42ffb-51e6-4da9-d753-a664acd2c6fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4])\n","torch.Size([4])\n"]}]},{"cell_type":"markdown","source":["0. **Training Samples**\n","\n","So far XX and YY have all values in a row. Hence, now we have to convert to column vectors.  Hence, the shape of the input data should be modified as follows: **rows**: number of samples, **columns**: number of features."],"metadata":{"id":"zcSmzD7zuRUG"}},{"cell_type":"code","source":["X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n","Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)"],"metadata":{"id":"D14FyGssdQl-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let us observe the shape of our input data."],"metadata":{"id":"6JxsYnaAvM2B"}},{"cell_type":"code","source":["print(X, X.shape)\n","print(Y, Y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ALpQxpvvNmP","executionInfo":{"status":"ok","timestamp":1653795061062,"user_tz":-540,"elapsed":421,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"d8fe1934-b30b-4448-9a69-810424183230"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1.],\n","        [2.],\n","        [3.],\n","        [4.]]) torch.Size([4, 1])\n","tensor([[2.],\n","        [4.],\n","        [6.],\n","        [8.]]) torch.Size([4, 1])\n"]}]},{"cell_type":"code","source":["n_samples, n_features = X.shape\n","print(n_samples, n_features)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l-tF4Osvv3RV","executionInfo":{"status":"ok","timestamp":1653795063523,"user_tz":-540,"elapsed":6,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"630a5f70-ec6e-405b-d2d0-88db5f423018"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4 1\n"]}]},{"cell_type":"markdown","source":["0. **Test Sample**\n","\n","This is for the purpose of \"Prediction before (after) training: f(5)\". But, now the value cannot be float, it must be a tensor. So we created a test tensor below getting only one sample."],"metadata":{"id":"DIcvgtcMypvn"}},{"cell_type":"code","source":["X_test = torch.tensor([5], dtype=torch.float32)"],"metadata":{"id":"TkNTQK9RzYgj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1. **Design Model**\n","\n","Usually, we have to design the model by ourselve. But, since it is very trivial for linear regression, this is only one layer. This is already provided in PyTorch. And, this `torch.nn.Linear()` needs *input size* and *output size* of our features. Hence, for this we need to do some modification on the input data and X and Y need to have a different shape. X must be a 2D array and also Y. That is, why the X and Y data above is different from the previous formats."],"metadata":{"id":"Odtfkb5Lrz4B"}},{"cell_type":"code","source":["input_size = n_features # n_features = 1\n","output_size = n_features # output is also the same 1\n","\n","# The model needs these as inputs\n","model = nn.Linear(input_size, output_size)\n","\n","# we pass the test sample in the model, since one value, \n","# we can call the .item to get the actual float value then\n","print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UCgg0CE0ww40","executionInfo":{"status":"ok","timestamp":1653795070208,"user_tz":-540,"elapsed":271,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"f7ed8500-4fbc-4797-db99-efaad7f5c1eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction before training: f(5) = -4.075\n"]}]},{"cell_type":"markdown","source":["2. **Loss and Modify Optimizer**\n"," \n"," * we do not need the weights (parameters list, `[w]`), simply say `model.parameters()`. "],"metadata":{"id":"7YAspWio0h3f"}},{"cell_type":"code","source":["learning_rate = 0.01\n","n_iters = 100\n","\n","loss = nn.MSELoss() # callable function\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)    "],"metadata":{"id":"4SXkdXOldQo9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3. **Training Loop**\n"],"metadata":{"id":"MZss2SG51K8O"}},{"cell_type":"code","source":["for epoch in range(n_iters):\n","    # predict = forward pass\n","    y_predicted = model(X)   # forward is replaced by model\n","\n","    # loss, the callable function\n","    l = loss(Y, y_predicted) \n","\n","    # calculate gradients = backward pass\n","    l.backward()\n","\n","    # update weights\n","    optimizer.step() \n","\n","    # zero the gradients after updating\n","    optimizer.zero_grad()\n","\n","    # To print parameters, we have to unpack them: [w, b]=model.parameters()\n","    if epoch % 10 == 0:\n","      [w, b]=model.parameters() \n","      # This is a list of lists, not to see the tensor w[0][0].item() as below\n","      print('epoch ', epoch+10, ': w = ', w[0][0].item(), ' loss = ', l)\n","\n","print(f'Prediction after training: f(5) = {model(X_test).item():.3f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G1ugrc1DdQsB","executionInfo":{"status":"ok","timestamp":1653795082292,"user_tz":-540,"elapsed":285,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"f6798543-dc92-4fb9-ddd2-89b5c3674a81"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch  10 : w =  -0.2885587215423584  loss =  tensor(62.1590, grad_fn=<MseLossBackward0>)\n","epoch  20 : w =  1.5206629037857056  loss =  tensor(1.6333, grad_fn=<MseLossBackward0>)\n","epoch  30 : w =  1.8149597644805908  loss =  tensor(0.0659, grad_fn=<MseLossBackward0>)\n","epoch  40 : w =  1.865485429763794  loss =  tensor(0.0240, grad_fn=<MseLossBackward0>)\n","epoch  50 : w =  1.8767067193984985  loss =  tensor(0.0216, grad_fn=<MseLossBackward0>)\n","epoch  60 : w =  1.881514549255371  loss =  tensor(0.0203, grad_fn=<MseLossBackward0>)\n","epoch  70 : w =  1.8852020502090454  loss =  tensor(0.0191, grad_fn=<MseLossBackward0>)\n","epoch  80 : w =  1.8886231184005737  loss =  tensor(0.0180, grad_fn=<MseLossBackward0>)\n","epoch  90 : w =  1.8919180631637573  loss =  tensor(0.0170, grad_fn=<MseLossBackward0>)\n","epoch  100 : w =  1.895111322402954  loss =  tensor(0.0160, grad_fn=<MseLossBackward0>)\n","Prediction after training: f(5) = 9.790\n"]}]},{"cell_type":"markdown","source":["The final output is not perfect may be because of the random initialization of the parameter and also the optimization technique might be alittle different. \n","\n","We may want to play around the learning rate and number of iterations. But, basically, it works and get better and better with every step. Overall this is how we can construct the whole training pipline. "],"metadata":{"id":"1MIf860I3wzN"}},{"cell_type":"markdown","source":["## **Custom Model**\n","\n","One more thing, in the above case we did not have to come up with the model for ourselves. So we only had one layer and this is already provided in PyTorch (`torch.nn.linear()`).\n","\n","Let us say now we need a **custom model**:"],"metadata":{"id":"_qiiihZj5_tx"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn"],"metadata":{"id":"85HBpEHbcNqA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n","Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n","\n","n_samples, n_features = X.shape\n","\n","X_test = torch.tensor([5], dtype=torch.float32)"],"metadata":{"id":"U-aKTLK_dQu-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Define Model:\n","\n","We define a custom Linear Regression Model and we have to derive it from `torch.nn.Module`. This will get an `__init__` function with three parameters.\n"],"metadata":{"id":"moOaixf9cY8-"}},{"cell_type":"code","source":["input_size = n_features # n_features = 1\n","output_size = n_features # output is also the same 1\n","\n","# The model needs these as inputs\n","# model = nn.Linear(input_size, output_size) # It is replaced by the below code\n","\n","# Custom Linear Reg Model \n","class LinearRegression(nn.Module):\n","  def __init__(self, input_dim, output_dim):\n","    # we have to get the super construct\n","    super(LinearRegression, self).__init__()\n","    # here we have to define the different layers.\n","    self.lin = nn.Linear(input_dim, output_dim)\n","  \n","  # we also have to implement the forward pass\n","  def forward(self, x):\n","    return self.lin(x)\n","\n","#That is the whole thing. Now\n","model = LinearRegression(input_size, output_size)\n","\n","# we pass the test sample in the model, since one value, \n","# we can call the .item to get the actual float value then\n","print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"njvDuBatdQyR","executionInfo":{"status":"ok","timestamp":1653805562356,"user_tz":-540,"elapsed":250,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"cd0e1770-5928-45ab-9ff8-3f43ca7efe4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction before training: f(5) = -0.710\n"]}]},{"cell_type":"markdown","source":["Following cells are same as used before."],"metadata":{"id":"lnhJLDhMf60t"}},{"cell_type":"code","source":["learning_rate = 0.01\n","n_iters = 100\n","\n","loss = nn.MSELoss() # callable function\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)    "],"metadata":{"id":"3akRBnHZf_J4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for epoch in range(n_iters):\n","    # predict = forward pass\n","    y_predicted = model(X)   # forward is replaced by model\n","\n","    # loss, the callable function\n","    l = loss(Y, y_predicted) \n","\n","    # calculate gradients = backward pass\n","    l.backward()\n","\n","    # update weights\n","    optimizer.step() \n","\n","    # zero the gradients after updating\n","    optimizer.zero_grad()\n","\n","    # To print parameters, we have to unpack them: [w, b]=model.parameters()\n","    if epoch % 10 == 0:\n","      [w, b]=model.parameters() \n","      # This is a list of lists, not to see the tensor w[0][0].item() as below\n","      print('epoch ', epoch+10, ': w = ', w[0][0].item(), ' loss = ', l)\n","\n","print(f'Prediction after training: f(5) = {model(X_test).item():.3f}')"],"metadata":{"id":"d10I64F5NuNm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653805682513,"user_tz":-540,"elapsed":295,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"85d7e277-3605-4751-b376-91ad88976f21"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch  10 : w =  0.22057107090950012  loss =  tensor(35.2211, grad_fn=<MseLossBackward0>)\n","epoch  20 : w =  1.583726406097412  loss =  tensor(0.9456, grad_fn=<MseLossBackward0>)\n","epoch  30 : w =  1.8068301677703857  loss =  tensor(0.0568, grad_fn=<MseLossBackward0>)\n","epoch  40 : w =  1.8464443683624268  loss =  tensor(0.0319, grad_fn=<MseLossBackward0>)\n","epoch  50 : w =  1.8564343452453613  loss =  tensor(0.0295, grad_fn=<MseLossBackward0>)\n","epoch  60 : w =  1.861552357673645  loss =  tensor(0.0278, grad_fn=<MseLossBackward0>)\n","epoch  70 : w =  1.8657829761505127  loss =  tensor(0.0262, grad_fn=<MseLossBackward0>)\n","epoch  80 : w =  1.8697702884674072  loss =  tensor(0.0246, grad_fn=<MseLossBackward0>)\n","epoch  90 : w =  1.873620867729187  loss =  tensor(0.0232, grad_fn=<MseLossBackward0>)\n","epoch  100 : w =  1.877354621887207  loss =  tensor(0.0218, grad_fn=<MseLossBackward0>)\n","Prediction after training: f(5) = 9.754\n"]}]},{"cell_type":"markdown","source":["# **Linear Regression**"],"metadata":{"id":"52cIleJ7gXSo"}},{"cell_type":"markdown","source":["1. Design model (input size, output size, forward pass with different layers)\n","2. Construct loss and optimizer\n","3. Training loop\n"," > * Start with forward path= compute prediction and loss \\\\\n"," > * Next do the backward path= compute gradients \\\\\n"," > * Then, update weights\n"],"metadata":{"id":"NF3YtcKNhBqC"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np              # for data tansformation\n","from sklearn import datasets    # to generate a regression data set\n","import matplotlib.pyplot as plt # for plots"],"metadata":{"id":"2pukMZ7sgXeY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["0. **Prepare Data**"],"metadata":{"id":"CCa0ej3ChJc0"}},{"cell_type":"code","source":["X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, \n","                                            noise=20, random_state=4) \n","print(X_numpy.dtype) # double data type\n","print(y_numpy.dtype) # double data type\n","\n","# cast to float Tensor\n","X = torch.from_numpy(X_numpy.astype(np.float32)) # convert to float data type\n","                                  # otherwise we may run into some error later\n","y = torch.from_numpy(y_numpy.astype(np.float32))\n","\n","# reshaping = converting into column vector using the builtin .view\n","y = y.view(y.shape[0], 1)\n","\n","n_samples, n_features = X.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"en2hnN26gdER","executionInfo":{"status":"ok","timestamp":1653807782862,"user_tz":-540,"elapsed":367,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"f60997cc-d4a2-40e8-e038-a97e67cf02ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["float64\n","float64\n"]}]},{"cell_type":"markdown","source":["1. **Model**\n","\n","In linear regression case $f=wx+b$, it is just one layer, so we can use the built-in linear model."],"metadata":{"id":"_jDTGyoqkRlm"}},{"cell_type":"code","source":["input_size = n_features\n","output_size = 1\n","\n","# built-in linear model\n","model = nn.Linear(input_size, output_size)"],"metadata":{"id":"lXW-tjTLgdHP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2. **Loss and Optimizer**\n","\n","We use a built-in loss function and optimizer."],"metadata":{"id":"vGjV2hGVlNl4"}},{"cell_type":"code","source":["learning_rate = 0.01\n","\n","criterion = nn.MSELoss()  # callbel function\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  "],"metadata":{"id":"O11Ic_m8gdKP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3. **Training Loop**"],"metadata":{"id":"tQpBljamlvLn"}},{"cell_type":"code","source":["num_epochs = 100\n","\n","for epoch in range(num_epochs):\n","    # Forward pass and loss\n","    y_predicted = model(X)\n","    loss = criterion(y_predicted, y)\n","    \n","    # Backward pass and update\n","    loss.backward()\n","    optimizer.step()\n","\n","    # zero grad before new step\n","    optimizer.zero_grad()\n","\n","    if (epoch+1) % 10 == 0:\n","        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zd2ZnZ2mgdM_","executionInfo":{"status":"ok","timestamp":1653807791591,"user_tz":-540,"elapsed":264,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"15848dce-4c50-4c38-b275-4d52ac1bd6c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 10, loss = 4145.1733\n","epoch: 20, loss = 2919.4407\n","epoch: 30, loss = 2083.8037\n","epoch: 40, loss = 1513.9906\n","epoch: 50, loss = 1125.3604\n","epoch: 60, loss = 860.2488\n","epoch: 70, loss = 679.3615\n","epoch: 80, loss = 555.9175\n","epoch: 90, loss = 471.6583\n","epoch: 100, loss = 414.1351\n"]}]},{"cell_type":"markdown","source":["Now we are done."],"metadata":{"id":"bOxTyfN6mgwX"}},{"cell_type":"code","source":["# Plot\n","# get predicted values from our final model with all the data, model(X), and \n","# we want to convert it to numpy but before we do we want to detach our tensor\n","# Hence we want to prevent from being tracked in our computation graph\n","\n","predicted = model(X).detach().numpy()\n","\n","plt.plot(X_numpy, y_numpy, 'ro') # red dots\n","plt.plot(X_numpy, predicted, 'b') # blue\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"cKhKkGqVgdPx","executionInfo":{"status":"ok","timestamp":1653807801987,"user_tz":-540,"elapsed":292,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"055ea52f-af78-4b8e-bc07-5835aee496b8"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["# **Logistic Regression**\n","\n"],"metadata":{"id":"5kQXt_AgoPhG"}},{"cell_type":"markdown","source":["1. Design model (input size, output size, forward pass with different layers)\n","2. Construct loss and optimizer\n","3. Training loop\n"," > * Start with forward path= compute prediction and loss \\\\\n"," > * Next do the backward path= compute gradients \\\\\n"," > * Then, update weights\n"],"metadata":{"id":"kcfww1xjroEo"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","from sklearn import datasets\n","from sklearn.preprocessing import StandardScaler     # to scale our features\n","from sklearn.model_selection import train_test_split # to separate training and\n","                                                    # testing data"],"metadata":{"id":"aLDxMuNcgdSf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["0. **Prepare Data**"],"metadata":{"id":"YE4UQpMGsJNn"}},{"cell_type":"code","source":["# Load the breast cancer data set from sklearn\n","# It is a binary classification propblem to predict cancer\n","bc = datasets.load_breast_cancer()\n","\n","X, y = bc.data, bc.target\n","\n","n_samples, n_features = X.shape\n","# print(n_samples, n_features)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n","                                                    random_state=1234)\n","# scale : zero mean and unit variance\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)\n","\n","# convert our data to torch tensors\n","X_train = torch.from_numpy(X_train.astype(np.float32))\n","X_test = torch.from_numpy(X_test.astype(np.float32))\n","y_train = torch.from_numpy(y_train.astype(np.float32))\n","y_test = torch.from_numpy(y_test.astype(np.float32))\n","\n","# reshape our y tensors\n","y_train = y_train.view(y_train.shape[0], 1)\n","y_test = y_test.view(y_test.shape[0], 1)"],"metadata":{"id":"Hf23vgqMgdVc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1. **Model**\n","\n","Linear model $f=wx + b$. Then we apply a sigmoid function at the end."],"metadata":{"id":"3_0D_W2Qumwg"}},{"cell_type":"code","source":["class LogisticRegression(nn.Module):\n","    def __init__(self, n_input_features):\n","        super(LogisticRegression, self).__init__()\n","        self.linear = nn.Linear(n_input_features, 1) # built-in (single) layer\n","\n","    def forward(self, x):\n","        y_pred = torch.sigmoid(self.linear(x)) # our data x\n","        return y_pred\n","model = LogisticRegression(n_features) # our layers is of size 30 by 1"],"metadata":{"id":"TlAEEIbfgdYS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2. **Loss and Optimizer**\n","\n","The loss function is now different from that of the linear function."],"metadata":{"id":"eu7leouyv4Rj"}},{"cell_type":"code","source":["learning_rate = 0.01\n","criterion = nn.BCELoss()      # Binary cross entropy\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"],"metadata":{"id":"EQgnOZjpgdbC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3. **Training Loop**"],"metadata":{"id":"y6A8Tljpwgmw"}},{"cell_type":"code","source":["num_epochs = 100\n","for epoch in range(num_epochs):\n","    # Forward pass and loss\n","    y_pred = model(X_train)\n","    loss = criterion(y_pred, y_train)\n","\n","    # Backward pass and update\n","    loss.backward()\n","    optimizer.step()\n","\n","    # zero grad before new step\n","    optimizer.zero_grad()\n","\n","    if (epoch+1) % 10 == 0:\n","        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j5DjCKoGwB-i","executionInfo":{"status":"ok","timestamp":1653811052224,"user_tz":-540,"elapsed":401,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"2b12ef1c-de4e-4fc8-b9d4-64887f830bb3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 10, loss = 0.5840\n","epoch: 20, loss = 0.4863\n","epoch: 30, loss = 0.4238\n","epoch: 40, loss = 0.3802\n","epoch: 50, loss = 0.3476\n","epoch: 60, loss = 0.3222\n","epoch: 70, loss = 0.3017\n","epoch: 80, loss = 0.2846\n","epoch: 90, loss = 0.2702\n","epoch: 100, loss = 0.2577\n"]}]},{"cell_type":"markdown","source":["**Model Evaluation**: Let us evaluate our model. The evaluation should be not part of our compuation graph where we want to track the history. \n"],"metadata":{"id":"SVR02P2mxex-"}},{"cell_type":"code","source":["with torch.no_grad():\n","    # get all predicted classes from our test sample\n","    y_predicted = model(X_test) \n","    #print(y_predicted[:10,])\n","    # Sigmoid function return values b/n 0 and 1, convert to class labels\n","    # so if it is larger than 0.5, it is 1, otherwise 0.  \n","    y_predicted_class = y_predicted.round()\n","    #print(y_predicted_class[:10,])\n","\n","    # if predicted and actual are equal, it is True (1), otherwise False (0)\n","    # These are added (correct classifications) and divided by number of samples \n","    accuracy = y_predicted_class.eq(y_test).sum() / float(y_test.shape[0])\n","\n","    # I tried, the following one, and it is ok\n","    #accuracy = (y_predicted_class == y_test).sum() / float(y_test.shape[0])\n","    print(f'accuracy: {accuracy.item():.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f6Z3DBcSxfAe","executionInfo":{"status":"ok","timestamp":1653812936939,"user_tz":-540,"elapsed":317,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"a4e070f2-9f23-4ac8-ae94-bcb094cec1c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy: 0.9211\n"]}]},{"cell_type":"markdown","source":["We might want to play around the number of iterations, learning rate or also try out a different optimizer."],"metadata":{"id":"H97IlrvP2qZv"}},{"cell_type":"markdown","source":["# **Dataset and DataLoader**\n","\n","Now we are going to see the PyTorch Dataset and DataLoader classes. So far we had a training loop that loops over the number of epochs and then we optimize ur model based on the whole dataset. So this might be very time consuming if it did gradient calculations for the whole training data. So, a better way for a large data is to divide the samples into smaller sizes so called *batches*. So we loop over the epoches again and then we do another loop over all the batches. Then, we get the X and Y batch samples, and do the optimization based on only the batches.\n","\n","* 1 epoch = 1 forward and backward pas off ALL training samples.\n","* batch_size = number of training samples in one forward and backward pass\n","* number of iterations = number of passes, each pass using [batch_size] number of samples.\n","\n","Eg: 100 samples, batch size = 20 ==> 100/20=5 iterations for 1 epoch.\n","\n","DataLoader can do the batch size calculations and iterations."],"metadata":{"id":"Ye1DFxwe4wcy"}},{"cell_type":"code","source":["import torch\n","import torchvision\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","import math"],"metadata":{"id":"AhkOteb4wCJ-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["winedata = np.loadtxt('/content/drive/MyDrive/Colab Notebooks/wine.csv', \n","                        delimiter=',', dtype=np.float32, skiprows=1)\n","print(winedata)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S1Z_Wi1cDnk3","executionInfo":{"status":"ok","timestamp":1653816515924,"user_tz":-540,"elapsed":297,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"542d46a1-73a5-450b-bc46-3c8f8d7c464e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1.000e+00 1.423e+01 1.710e+00 ... 1.040e+00 3.920e+00 1.065e+03]\n"," [1.000e+00 1.320e+01 1.780e+00 ... 1.050e+00 3.400e+00 1.050e+03]\n"," [1.000e+00 1.316e+01 2.360e+00 ... 1.030e+00 3.170e+00 1.185e+03]\n"," ...\n"," [3.000e+00 1.327e+01 4.280e+00 ... 5.900e-01 1.560e+00 8.350e+02]\n"," [3.000e+00 1.317e+01 2.590e+00 ... 6.000e-01 1.620e+00 8.400e+02]\n"," [3.000e+00 1.413e+01 4.100e+00 ... 6.100e-01 1.600e+00 5.600e+02]]\n"]}]},{"cell_type":"code","source":["class WineDataset(Dataset):\n","    # Implement a custom Dataset\n","    # Have to implement 3 things: 1) __init__ , 2) __getitem__ , and 3) __len__\n","    \n","    def __init__(self):\n","        # Data loading\n","        # read with numpy or pandas\n","        xy = np.loadtxt('/content/drive/MyDrive/Colab Notebooks/wine.csv', \n","                        delimiter=',', dtype=np.float32, skiprows=1)\n","        # split the data\n","        # here the first column is the class label, the rest are the features\n","        self.x_data = torch.from_numpy(xy[:, 1:]) # size [n_samples, n_features]\n","        self.y_data = torch.from_numpy(xy[:, [0]]) # size [n_samples, 1]\n","\n","        # get the number of samples\n","        self.n_samples = xy.shape[0]\n","\n","    # support indexing such that dataset[i] can be used to get i-th sample\n","    def __getitem__(self, index):\n","        # allow for indexing latter, we can call dataset[0] for example\n","        return self.x_data[index], self.y_data[index] # return a tuple\n","\n","    # we can call len(dataset) to return the size\n","    def __len__(self):\n","        # allow for the length of our data set, len(dataset)\n","        return self.n_samples\n"],"metadata":{"id":"pFiEfaafwCMv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Let us create the dataset\n","dataset = WineDataset()\n","\n","# Let us look at this dataset, get first sample and unpack\n","first_data = dataset[0]\n","features, labels = first_data\n","print(features, labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wedQWTivwCPu","executionInfo":{"status":"ok","timestamp":1653815461268,"user_tz":-540,"elapsed":250,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"399640bf-cd66-435d-94ad-3f8e975b6f6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n","        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n","        1.0650e+03]) tensor([1.])\n"]}]},{"cell_type":"markdown","source":["Let us use the data loader"],"metadata":{"id":"oMeuCa61FdLt"}},{"cell_type":"code","source":["# Load whole dataset with DataLoader\n","# shuffle: shuffle data, good for training\n","# num_workers: faster loading with multiple subprocesses\n","# !!! IF YOU GET AN ERROR DURING LOADING, SET num_workers TO 0 !!!\n","train_loader = DataLoader(dataset=dataset, batch_size=4, shuffle=True,\n","                          num_workers=2)\n","\n","# convert to an iterator and look at one random sample\n","dataiter = iter(train_loader)\n","data = dataiter.next()\n","features, labels = data\n","print(features, labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sJpX9JZbwCSx","executionInfo":{"status":"ok","timestamp":1653815711343,"user_tz":-540,"elapsed":246,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"f210f8c3-e820-429c-adc5-4f9ac292d724"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1.2290e+01, 1.6100e+00, 2.2100e+00, 2.0400e+01, 1.0300e+02, 1.1000e+00,\n","         1.0200e+00, 3.7000e-01, 1.4600e+00, 3.0500e+00, 9.0600e-01, 1.8200e+00,\n","         8.7000e+02],\n","        [1.3730e+01, 4.3600e+00, 2.2600e+00, 2.2500e+01, 8.8000e+01, 1.2800e+00,\n","         4.7000e-01, 5.2000e-01, 1.1500e+00, 6.6200e+00, 7.8000e-01, 1.7500e+00,\n","         5.2000e+02],\n","        [1.2330e+01, 1.1000e+00, 2.2800e+00, 1.6000e+01, 1.0100e+02, 2.0500e+00,\n","         1.0900e+00, 6.3000e-01, 4.1000e-01, 3.2700e+00, 1.2500e+00, 1.6700e+00,\n","         6.8000e+02],\n","        [1.1760e+01, 2.6800e+00, 2.9200e+00, 2.0000e+01, 1.0300e+02, 1.7500e+00,\n","         2.0300e+00, 6.0000e-01, 1.0500e+00, 3.8000e+00, 1.2300e+00, 2.5000e+00,\n","         6.0700e+02]]) tensor([[2.],\n","        [3.],\n","        [2.],\n","        [2.]])\n"]}]},{"cell_type":"markdown","source":["We see that 4 different feature vectors because we specified a batch size of 4."],"metadata":{"id":"y20TRcjMGX_i"}},{"cell_type":"code","source":["# Dummy Training loop\n","num_epochs = 2\n","total_samples = len(dataset)\n","n_iterations = math.ceil(total_samples/4)\n","print(total_samples, n_iterations)\n","for epoch in range(num_epochs):\n","    for i, (inputs, labels) in enumerate(train_loader):\n","        \n","        # here: 178 samples, batch_size = 4, n_iters=178/4=44.5 -> 45 iterations\n","        # Run your training process, just print some info as it is a dummy loop\n","        if (i+1) % 5 == 0:\n","            print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_iterations}|Inputs {inputs.shape} | Labels {labels.shape}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UBpHv4z-wCVu","executionInfo":{"status":"ok","timestamp":1653816081726,"user_tz":-540,"elapsed":680,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"e5458ad9-f2c4-4da6-8bdc-96a0f88788f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["178 45\n","Epoch: 1/2, Step 5/45|Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n","Epoch: 1/2, Step 10/45|Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n","Epoch: 1/2, Step 15/45|Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n","Epoch: 1/2, Step 20/45|Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n","Epoch: 1/2, Step 25/45|Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n","Epoch: 1/2, Step 30/45|Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n","Epoch: 1/2, Step 35/45|Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n","Epoch: 1/2, Step 40/45|Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n","Epoch: 1/2, Step 45/45|Inputs torch.Size([2, 13]) | Labels torch.Size([2, 1])\n","Epoch: 2/2, Step 5/45|Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n","Epoch: 2/2, Step 10/45|Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n","Epoch: 2/2, Step 15/45|Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n","Epoch: 2/2, Step 20/45|Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n","Epoch: 2/2, Step 25/45|Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n","Epoch: 2/2, Step 30/45|Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n","Epoch: 2/2, Step 35/45|Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n","Epoch: 2/2, Step 40/45|Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n","Epoch: 2/2, Step 45/45|Inputs torch.Size([2, 13]) | Labels torch.Size([2, 1])\n"]}]},{"cell_type":"markdown","source":["Now we see that there are 2 epoches, and in every epoch there are 45 steps and every 5th step we print some information. Also, we see that our tensor is 4 by 13 (4 batch size and 13 different features), .."],"metadata":{"id":"dIfXOWiIHsn0"}},{"cell_type":"markdown","source":["**Built-in Datasets**: some famous datasets are available in `torchvision.datasets` e.g. MNIST, Fashion-MNIST, CIFAR10, COCO"],"metadata":{"id":"dAdmBhTgId3J"}},{"cell_type":"code","source":["train_dataset = torchvision.datasets.MNIST(root='./data', train=True, \n","                                           transform=torchvision.transforms.ToTensor(),  \n","                                           download=True)\n","\n","train_loader = DataLoader(dataset=train_dataset, batch_size=3, shuffle=True)\n","\n","# look at one random sample\n","dataiter = iter(train_loader)\n","data = dataiter.next()\n","inputs, targets = data\n","print(inputs.shape, targets.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":460,"referenced_widgets":["a03374b4b0c14ab9b46959ffc0e72886","d8c4ad63df5341e091d5510c30519ca9","c0cd5b7d04a041cb8381cecca50fac6f","05aa96eeb13448cdac4af1a75ec9b0f1","88d561ca8a354e9fb42ba38480407cac","38c3e88851824a1ebd39a186ce8180b3","af005a11fcac441bb634cb609fca5d97","b42abadbd6564831bc7df59dc8390a9e","852120de77a94062a8b8d40846c03921","c31f9af80386459f984dedc8aa011f93","8e9574f5561e4c5c8879cea2faa783d7","e108e139b0a841b2ad08c1f946d8372b","cbaf9e9e35da41f1bef39985e6e53663","49e335d8a53242d987d38aba36a4990b","12c7f6e8fe1e4463a3fcea184ead61a2","1d954e36bb254ac28865b23f9565c427","1d1500ae5cab4d108b1c431d90d41d25","d276040e87aa45969f39bd97224c1870","b8b2756875884849abdeeafdacf4b277","c7dc0f3f26fa44b3bb97c3552dc4a802","136bdab0aa584d0d875ff42364a6ec24","fae0e751da1f4e7d9cbbe4882cf80db2","7b115e6fd3f14a8794028f38864e4cd9","1ccb3c7dea29417d9b9342ad89fb68f1","9ae8ab5eed434c71881596ca83ccf5fc","3573252a8ee144e3a869b096b8629a4a","b5a6bc8837a2474da431288549e36efb","6ab27203173749c28c59afcbd20da860","774dd0765e734e73b9e4a7e8391f0db3","962600532bc54dd199cb7df5fd5691a2","8102a725b86a4beca5b54d7b05544c95","eca3a09520d8463a9da81f1a805a0957","2e3d420feee741a79d4791e19357892d","d640bed41c8c49048126b18fce032920","77054d034f5c43479d449438fcef1833","e11690fcc01941af8ab1a113fdd06a1c","e3398cd2f99447a5a5afb89db8290a7b","f0429acdd0434fa5b925622c3f521a74","20032fd32f9f4fec9635207d462b3312","eafc36b52ad64dde81e81009f8f27959","901841b26e54463d92959be9a00daf4e","bcdaf068e4204252b89eade551567408","0972bb7908c14843b7ede1805b8167bc","e75e3ed1d6474799ab09fc7729c5b915"]},"id":"7lZeskt9wCYw","executionInfo":{"status":"ok","timestamp":1653816409074,"user_tz":-540,"elapsed":1700,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"bbb9acae-758f-4236-c094-516c225cef20"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/9912422 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a03374b4b0c14ab9b46959ffc0e72886"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/28881 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e108e139b0a841b2ad08c1f946d8372b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1648877 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b115e6fd3f14a8794028f38864e4cd9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/4542 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d640bed41c8c49048126b18fce032920"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","torch.Size([3, 1, 28, 28]) torch.Size([3])\n"]}]},{"cell_type":"markdown","source":["# **Dataset Transforms**"],"metadata":{"id":"lPqtqsLVJ0_l"}},{"cell_type":"markdown","source":["Transforms can be applied to PIL images, tensors, ndarrays, or custom data during creation of the DataSet complete list of built-in transforms:[here](https://pytorch.org/docs/stable/torchvision/transforms.html).\n","\n","**On Images**: CenterCrop, Grayscale, Pad, RandomAffine RandomCrop, RandomHorizontalFlip, RandomRotation Resize, Scale.\n","\n","\n","**On Tensors**: LinearTransformation, Normalize, RandomErasing\n","\n","**Conversion**: **ToPILImage**: from tensor or ndrarray; **ToTensor**: from numpy.ndarray or PILImage\n","\n","\n","**Generic**: Use Lambda \n","\n","**Custom**: Write own class\n","\n","**Compose multiple Transforms**: composed = transforms.Compose([Rescale(256), RandomCrop(224)])"],"metadata":{"id":"nRcCamqD64Lh"}},{"cell_type":"code","source":["import torch\n","import torchvision\n","from torch.utils.data import Dataset\n","import numpy as np"],"metadata":{"id":"zxMG09oDwCbe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let us extend the previous code."],"metadata":{"id":"fwzf-DE282D6"}},{"cell_type":"code","source":["class WineDataset(Dataset):\n","  # Let us add \"transform\" which is option, by default \"None\" and store it.\n","    def __init__(self, transform=None):\n","        xy = np.loadtxt('/content/drive/MyDrive/Colab Notebooks/wine.csv', \n","                        delimiter=',', dtype=np.float32, skiprows=1)\n","        # we do not convert to tensor here\n","        self.x_data = xy[:, 1:]\n","        self.y_data = xy[:, [0]]\n","\n","        self.n_samples = xy.shape[0]\n","\n","        # store \"transform\" in the __init__\n","        self.transform = transform\n","    # also make some changes in the __getitem__ function if transform is avail\n","    def __getitem__(self, index):\n","        sample = self.x_data[index], self.y_data[index] \n","\n","        # if transform is not None\n","        if self.transform: \n","          sample = self.transform(sample)\n","\n","        return sample\n","\n","    def __len__(self):\n","        return self.n_samples"],"metadata":{"id":"sJHWrmCI8HOM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now let us create custom transform classes.\n","Previously, we have converted the X and y data to tensor as:\n","\n","`self.x_data = torch.from_numpy(xy[:, 1:])` \\\\\n","`self.y_data = torch.from_numpy(xy[:, [0]])` \n","\n","Hence, for example, we can write our own `ToTensor` class."],"metadata":{"id":"cu--9ZTC_odB"}},{"cell_type":"code","source":["class ToTensor:\n","    # Convert ndarrays to Tensors\n","    def __call__(self, sample):\n","      # unpack our samples\n","        inputs, targets = sample \n","        return torch.from_numpy(inputs), torch.from_numpy(targets)\n","\n","#Now we can pass ToTensor in to our wine dataset.\n","dataset = WineDataset(transform=ToTensor())\n","\n","#Look at the first item\n","first_data = dataset[0]\n","features, labels = first_data\n","print(type(features), type(labels))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cLvitcx68Hdq","executionInfo":{"status":"ok","timestamp":1653881836565,"user_tz":-540,"elapsed":681,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"446d2c05-446b-4862-8eb9-7a0a09caaa3c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'torch.Tensor'> <class 'torch.Tensor'>\n"]}]},{"cell_type":"markdown","source":["If `transform=None` in given, the data will not be tensor, rather in numpy.ndarray."],"metadata":{"id":"0BVmhojmBChx"}},{"cell_type":"code","source":["#Now we can pass ToTensor in to our wine dataset.\n","dataset = WineDataset(transform=None)\n","\n","#Look at the first item\n","first_data = dataset[0]\n","features, labels = first_data\n","print(type(features), type(labels))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7JsTcgBU8Hgq","executionInfo":{"status":"ok","timestamp":1653881896705,"user_tz":-540,"elapsed":270,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"d8de9c96-09e0-447f-e3d6-d7000b98cfd6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"]}]},{"cell_type":"code","source":["# another custom transform: multiplication transform\n","class MulTransform:\n","    # multiply inputs with a given factor\n","    def __init__(self, factor):\n","        self.factor = factor\n","\n","    def __call__(self, sample):\n","        inputs, targets = sample\n","        inputs *= self.factor\n","        return inputs, targets"],"metadata":{"id":"pZvrDiY18HjZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = WineDataset(transform=None)\n","\n","first_data = dataset[0]\n","features, labels = first_data\n","print(features)\n","print(type(features), type(labels))\n","\n","composed =torchvision.transforms.Compose([ToTensor(), MulTransform(2)])\n","\n","dataset = WineDataset(transform=composed)\n","first_data = dataset[0]\n","features, labels = first_data\n","print(features)\n","print(type(features), type(labels))\n","\n","# multiply by 4\n","composed =torchvision.transforms.Compose([ToTensor(), MulTransform(4)])\n","\n","dataset = WineDataset(transform=composed)\n","first_data = dataset[0]\n","features, labels = first_data\n","print(features)\n","print(type(features), type(labels))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hk3PJVhQEc9V","executionInfo":{"status":"ok","timestamp":1653882489042,"user_tz":-540,"elapsed":270,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"a0893364-dba6-430f-99ca-f2418002b8f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n"," 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n","<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n","tensor([2.8460e+01, 3.4200e+00, 4.8600e+00, 3.1200e+01, 2.5400e+02, 5.6000e+00,\n","        6.1200e+00, 5.6000e-01, 4.5800e+00, 1.1280e+01, 2.0800e+00, 7.8400e+00,\n","        2.1300e+03])\n","<class 'torch.Tensor'> <class 'torch.Tensor'>\n","tensor([5.6920e+01, 6.8400e+00, 9.7200e+00, 6.2400e+01, 5.0800e+02, 1.1200e+01,\n","        1.2240e+01, 1.1200e+00, 9.1600e+00, 2.2560e+01, 4.1600e+00, 1.5680e+01,\n","        4.2600e+03])\n","<class 'torch.Tensor'> <class 'torch.Tensor'>\n"]}]},{"cell_type":"markdown","source":["# Softmax and Crossentropy Loss"],"metadata":{"id":"tL5C8pouFK7A"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np"],"metadata":{"id":"80AsgETg8Hpq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Softmax** applies the exponential function to each element, and normalizes by dividing by the sum of all these exponentials\n","*squashes the output to be between 0 and 1 = probability, sum of all probabilities is 1. "],"metadata":{"id":"pl17hM0He_tz"}},{"cell_type":"code","source":["#\n","#        -> 2.0              -> 0.65  \n","# Linear -> 1.0  -> Softmax  -> 0.25   -> CrossEntropy(y, y_hat)\n","#        -> 0.1              -> 0.1                   \n","#\n","#     scores(logits)      probabilities\n","#                           sum = 1.0\n","#\n","def softmax(x):\n","    return np.exp(x) / np.sum(np.exp(x), axis=0) # along values along first axis\n"],"metadata":{"id":"UVd5MY-n8HsZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = np.array([2.0, 1.0, 0.1])\n","outputs = softmax(x)\n","print('softmax numpy:', outputs)\n","#print(outputs.sum())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MUQ67-Ul8HvZ","executionInfo":{"status":"ok","timestamp":1653889539004,"user_tz":-540,"elapsed":279,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"f41c257a-ff1c-4db5-f995-7b641eec194a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1.0\n","softmax numpy: [0.65900114 0.24243297 0.09856589]\n"]}]},{"cell_type":"markdown","source":["Difference between `axis` and `dim`?"],"metadata":{"id":"rwhB3Ausi002"}},{"cell_type":"code","source":["x = np.array([2.0, 1.0, 0.1])\n","print(x.sum())\n","x = np.array([2.0, 1.0, 0.1])\n","print(x.sum(axis=0)) # dim is not working\n","y = torch.tensor([2.0, 1.0, 0.1])\n","print(y.sum())\n","print(y.sum(dim=0)) # axis is also working"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y9gDQxjzhwFK","executionInfo":{"status":"ok","timestamp":1653890283813,"user_tz":-540,"elapsed":253,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"c05fdb92-c80c-4e4b-8514-bc624005f96d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3.1\n","3.1\n","tensor(3.1000)\n","tensor(3.1000)\n"]}]},{"cell_type":"code","source":["# we can also calculate using PyTorch\n","x = torch.tensor([2.0, 1.0, 0.1]) # get the same values as np.array\n","outputs = torch.softmax(x, dim=0) # along values along first axis\n","print('softmax torch:', outputs)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZC3rhDq_gtSQ","executionInfo":{"status":"ok","timestamp":1653890365573,"user_tz":-540,"elapsed":279,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"04e1efae-dfaa-4c14-d12f-51ff716394ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["softmax torch: tensor([0.6590, 0.2424, 0.0986])\n"]}]},{"cell_type":"markdown","source":["**Cross-entropy loss** or **log loss** measures the performance of a classification model whose output is a probability value between 0 and 1. \n","$$D(\\hat{p}, p)=-\\frac{1}{N}\\sum p_i \\log (\\hat{p})$$\n","\n","One-hot encoded class labels: $p=[1, 0, 0]$\n","\n","Given probabilities (softmax): \\\\\n","$\\hat{p}=[0.7, 0.2, 0.1] ⇒ D(\\hat{p}, p)=0.35$ \\\\\n","$\\hat{p}=[0.1, 0.3, 0.6] ⇒ D(\\hat{p}, p)=2.30$ \n","\n","* loss increases as the predicted probability diverges from the actual label"],"metadata":{"id":"Puvs1hTljznO"}},{"cell_type":"code","source":["def cross_entropy(actual, predicted):\n","    loss = -np.sum(actual * np.log(predicted))\n","\n","    # can also normalize it, but we dont do this here\n","    return loss # / float(predicted.shape[0])\n","# y must be one hot encoded\n","# if class 0: [1 0 0]\n","# if class 1: [0 1 0]\n","# if class 2: [0 0 1]\n","\n","Y = np.array([1, 0, 0])\n","\n","Y_pred_good = np.array([0.7, 0.2, 0.1])\n","Y_pred_bad = np.array([0.1, 0.3, 0.6])\n","\n","l1 = cross_entropy(Y, Y_pred_good)\n","l2 = cross_entropy(Y, Y_pred_bad)\n","print(f'Loss1 numpy: {l1:.4f}')\n","print(f'Loss2 numpy: {l2:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vqIivCjjl6e0","executionInfo":{"status":"ok","timestamp":1653892694364,"user_tz":-540,"elapsed":256,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"27e03a27-0990-44e8-a8f0-174fd80b21af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loss1 numpy: 0.3567\n","Loss2 numpy: 2.3026\n"]}]},{"cell_type":"markdown","source":["Let us do it in PyTorch. \n","\n","Carefull!!\n","\n","`nn.CrossEntropyLoss` in PyTorch alreay applies Softmax and  loglikelihood loss: `nn.LogSoftmax + nn.NLLLoss`\n","\n","* `LogSoftmax` = log softmax\n","* `NLLLoss` = negative log likelihood loss\n","\n","We must **not impliment the softmax** for ourselves (first thing we must know). Second, our Y must **not be one-Hot encoded**, we should put the correct class labels here. Third, the predicted Ys are **raw scores (logits)**, no Softmax here. \n","\n","So be carefull about these."],"metadata":{"id":"Wj7b1ZXkmza6"}},{"cell_type":"code","source":["\n","loss = nn.CrossEntropyLoss()\n","# loss(input, target)\n","\n","# target is of size nSamples = 1\n","# each element has class label: 0, 1, or 2\n","# Y (=target) contains class labels, not one-hot\n","Y = torch.tensor([0]) # correct class label, class 0\n","# input is of size nSamples x nClasses = 1 x 3\n","# y_pred (=input) must be raw, unnormalizes scores (logits) for each class, not softmax\n","Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]]) # inputs array of arrays\n","Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n","l1 = loss(Y_pred_good, Y)\n","l2 = loss(Y_pred_bad, Y)\n","\n","print(f'PyTorch Loss1: {l1.item():.4f}')\n","print(f'PyTorch Loss2: {l2.item():.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jE_JJBmrmXeY","executionInfo":{"status":"ok","timestamp":1653892697483,"user_tz":-540,"elapsed":261,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"8b0e32b0-a0f3-4ea3-c957-eb63b8b69883"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch Loss1: 0.4170\n","PyTorch Loss2: 1.8406\n"]}]},{"cell_type":"markdown","source":["Get Predictions"],"metadata":{"id":"8TCICYmHsHyT"}},{"cell_type":"code","source":["# get predictions\n","_, predictions1 = torch.max(Y_pred_good, 1) # 1 is to mean the 1st dimension\n","_, predictions2 = torch.max(Y_pred_bad, 1)\n","print(f'Actual class: {Y.item()}, Y_pred1: {predictions1.item()}, Y_pred2: {predictions2.item()}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8uWDMhIlsG5f","executionInfo":{"status":"ok","timestamp":1653892846602,"user_tz":-540,"elapsed":283,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"abf5a385-d46f-4215-b34c-06da99ff11d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Actual class: 0, Y_pred1: 0, Y_pred2: 1\n"]}]},{"cell_type":"markdown","source":["Batch loss for multiple samples"],"metadata":{"id":"rSm_vQ2Ss7xa"}},{"cell_type":"code","source":["# target is of size nBatch = 3, or 3 samples\n","# each element has class label: 0, 1, or 2\n","Y = torch.tensor([2, 0, 1])\n","\n","# input is of size nBatch x nClasses = 3 x 3\n","# Y_pred are logits (not softmax)\n","Y_pred_good = torch.tensor(\n","    [[0.1, 0.2, 3.9], # predict class 2\n","    [1.2, 0.1, 0.3], # predict class 0\n","    [0.3, 2.2, 0.2]]) # predict class 1\n","\n","Y_pred_bad = torch.tensor(\n","    [[0.9, 0.2, 0.1],\n","    [0.1, 0.3, 1.5],\n","    [1.2, 0.2, 0.5]])\n","\n","l1 = loss(Y_pred_good, Y)\n","l2 = loss(Y_pred_bad, Y)\n","print(f'Batch Loss1:  {l1.item():.4f}')\n","print(f'Batch Loss2: {l2.item():.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RLc8lfGmsG8u","executionInfo":{"status":"ok","timestamp":1653893178419,"user_tz":-540,"elapsed":262,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"cbd11f8a-bfd0-496d-d2f6-eb664e2aad49"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Batch Loss1:  0.2834\n","Batch Loss2: 1.6418\n"]}]},{"cell_type":"code","source":["# get predictions\n","_, predictions1 = torch.max(Y_pred_good, 1)\n","_, predictions2 = torch.max(Y_pred_bad, 1)\n","print(f'Actual class: {Y}, Y_pred1: {predictions1}, Y_pred2: {predictions2}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C34GLoGIt5b6","executionInfo":{"status":"ok","timestamp":1653893272221,"user_tz":-540,"elapsed":271,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"5d69d778-02a2-4e30-8b30-4cba41e76f19"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Actual class: tensor([2, 0, 1]), Y_pred1: tensor([2, 0, 1]), Y_pred2: tensor([0, 2, 0])\n"]}]},{"cell_type":"markdown","source":["Binary Classification"],"metadata":{"id":"NxarlPytuP5m"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn"],"metadata":{"id":"aubWK4kLu9h5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Binary classification\n","class NeuralNet1(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(NeuralNet1, self).__init__()\n","        # we define our 3 layers \n","        self.linear1 = nn.Linear(input_size, hidden_size) # first layer\n","        self.relu = nn.ReLU()                             # activation function\n","        self.linear2 = nn.Linear(hidden_size, 1)          # last layer\n","        #  output size 1 is fixed in Binary classification\n","    \n","    def forward(self, x):\n","        out = self.linear1(x)\n","        out = self.relu(out)\n","        out = self.linear2(out)\n","        # we must implement the sigmoid function at the end\n","        y_pred = torch.sigmoid(out)\n","        return y_pred\n","\n","model = NeuralNet1(input_size=28*28, hidden_size=5)\n","criterion = nn.BCELoss()\n"],"metadata":{"id":"YwO0VxvBsG_t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Multiclass problem"],"metadata":{"id":"r8E6JVomx2B2"}},{"cell_type":"code","source":["# Multiclass problem\n","class NeuralNet2(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super(NeuralNet2, self).__init__()\n","        self.linear1 = nn.Linear(input_size, hidden_size) \n","        self.relu = nn.ReLU()\n","        self.linear2 = nn.Linear(hidden_size, num_classes)  \n","    \n","    def forward(self, x):\n","        out = self.linear1(x)\n","        out = self.relu(out)\n","        out = self.linear2(out)\n","        # no softmax at the end\n","        return out\n","\n","model = NeuralNet2(input_size=28*28, hidden_size=5, num_classes=3)\n","criterion = nn.CrossEntropyLoss()  # (applies Softmax)"],"metadata":{"id":"KLM85qiSsHCu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Activation Functions**"],"metadata":{"id":"oEe8gP0Ex7u3"}},{"cell_type":"markdown","source":["Activation functions apply a non-linear transformation and decide whether a neuron should be activated or not.\n","\n","output = w*x + b\n","\n","output = activation_function(output)\n","\n","Without activation functions, our network is basically just a stacked linear regression model. With non-linear transformations, our network can learn better and perform more complex tasks. After each layer, we typically use an activation function.\n","\n","Most popular activation functions: \n","* Step function: $f(x)=1$ if $x\\ge \\theta$.  It not used in practice actually.  \n","* Sigmoid: $f(x)=\\frac{1}{1+e^{-x}}$.  It is typically used in the last layer of a binary classification problem.  \n","* TanH (hyperbollic tangent): $f(x)=\\frac{2}{1+e^{-2x}}-1$. It is a scaled sigmoid function and a little bit shifted. It is actually a good choice in hidden layers. But, when $x=0$, the gradient in the backpropagation is also zero which means the weights will never be updated. So these neurons will not learn anything and we say that these neurons are dead.\n","* ReLU: $f(x)=max(0,x)$. If you dont know what function to use, just use ReLU for hidden layers.\n","* Leakly ReLu: $f(x)=x$ if $x\\ge 0$, $f(x)=ax$ otherwise. $a$ is a very small value say 0.001. It is a slighly modified and improved version of ReLU. It tries to solve the vanishing gradient problem. So whenever noticing the weights are not updated, try to use Leakly ReLU.\n","* Softmax: $S(y_i)=\\frac{e^{y_i}}{\\sum e^{y_i}}$. Good in the last layer in multi-class classification problems."],"metadata":{"id":"LBMjkfXZ2o5l"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"metadata":{"id":"JB3utLI2ltFf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = torch.tensor([-1.0, 1.0, 2.0, 3.0])\n","\n","# sofmax\n","output = torch.softmax(x, dim=0)\n","print(output)\n","sm = nn.Softmax(dim=0)\n","output = sm(x)\n","print(output)\n","\n","# sigmoid \n","output = torch.sigmoid(x)\n","print(output)\n","s = nn.Sigmoid()\n","output = s(x)\n","print(output)\n","\n","#tanh\n","output = torch.tanh(x)\n","print(output)\n","t = nn.Tanh()\n","output = t(x)\n","print(output)\n","\n","# relu\n","output = torch.relu(x)\n","print(output)\n","relu = nn.ReLU()\n","output = relu(x)\n","print(output)\n","\n","# leaky relu\n","output = F.leaky_relu(x)\n","print(output)\n","lrelu = nn.LeakyReLU()\n","output = lrelu(x)\n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a09IAHLlltI-","executionInfo":{"status":"ok","timestamp":1653898736429,"user_tz":-540,"elapsed":273,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"2dac27fd-7eab-414a-9356-a3b9333cbf9c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.0120, 0.0889, 0.2418, 0.6572])\n","tensor([0.0120, 0.0889, 0.2418, 0.6572])\n","tensor([0.2689, 0.7311, 0.8808, 0.9526])\n","tensor([0.2689, 0.7311, 0.8808, 0.9526])\n","tensor([-0.7616,  0.7616,  0.9640,  0.9951])\n","tensor([-0.7616,  0.7616,  0.9640,  0.9951])\n","tensor([0., 1., 2., 3.])\n","tensor([0., 1., 2., 3.])\n","tensor([-0.0100,  1.0000,  2.0000,  3.0000])\n","tensor([-0.0100,  1.0000,  2.0000,  3.0000])\n"]}]},{"cell_type":"markdown","source":["**Two options**: creating an nn module or using the activation function directly in forward pass.\n","\n","* `nn.ReLU()` creates an `nn.Module` which you can add e.g. to an `nn.Sequential` model.\n","* `torch.relu` on the other side is just the functional API call to the relu function, so that you can add it e.g. in your forward method yourself."],"metadata":{"id":"YyKrZcLODDTi"}},{"cell_type":"code","source":["# option 1 (create nn modules)\n","class NeuralNet(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(NeuralNet, self).__init__()\n","        self.linear1 = nn.Linear(input_size, hidden_size)\n","        self.relu = nn.ReLU() # nn.Softmax, nn.Sigmoid, ... are available\n","        self.linear2 = nn.Linear(hidden_size, 1)\n","        self.sigmoid = nn.Sigmoid()\n","    # We define all layers in the __init__ function\n","\n","    # In the forward pass, we simply call all the functions\n","    def forward(self, x):\n","        out = self.linear1(x)\n","        out = self.relu(out) # inputs the first one\n","        out = self.linear2(out) # inputs the out of the relu\n","        out = self.sigmoid(out) # inputs the out of the previous\n","        return out"],"metadata":{"id":"VEQUhmRBltMA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# option 2 (use activation functions directly in forward pass)\n","class NeuralNet(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(NeuralNet, self).__init__()\n","        self.linear1 = nn.Linear(input_size, hidden_size)\n","        self.linear2 = nn.Linear(hidden_size, 1)\n","    \n","    def forward(self, x):\n","        out = torch.relu(self.linear1(x))\n","        out = torch.sigmoid(self.linear2(out))\n","        # torch.softmax, torch.tanh\n","        # F.leaky_relu(), not available in torch, rather in torch.nn.functional\n","        return out"],"metadata":{"id":"_b611h91ltO9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Feed-Forward Neural Net**\n"],"metadata":{"id":"N7BygoikG9af"}},{"cell_type":"markdown","source":["We implement our first MLNN model using the famous MINST dataset. We put all the things together:\n","* **DataLoader**: to load our dataset, apply data **transformation**,\n","* **Multilayer Neural Net**: apply NN with input layer, hidden layer and output layer; also apply activation functions\n","* **Loss** and **Optimizer**: \n","* **Training Loop (Batch Training)**: \n","* **Model Evaluation**: finally evaluate our model and calculate accuracy\n","* **GPU support**: additionally we will make sure that our whole code can also run on the GPU, if we have GPU support"],"metadata":{"id":"FAvkGjJDq7tR"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt"],"metadata":{"id":"ho2UlP6mltRu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"R7C9rPx_p0Fh"}},{"cell_type":"code","source":["# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","\n","# Latter we have to push our tensors to the device and this will gaurantee that\n","# will run on the GPU if this is supported"],"metadata":{"id":"mxuA-N0jltUd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653963549340,"user_tz":-540,"elapsed":17,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"3bb8fc7e-a4a2-4b84-b46b-a00fe13d4a3c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","source":["# Hyper-parameters \n","input_size = 784 # Later we will see that our images are of size 28x28\n","hidden_size = 100 \n","num_classes = 10 # because we have 10 different classes (0,1,...,9)\n","num_epochs = 2\n","batch_size = 100\n","learning_rate = 0.001"],"metadata":{"id":"9WiHLC01p00S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# MNIST dataset from the PyTorch library\n","train_dataset = torchvision.datasets.MNIST(root='./data', train=True, \n","                                           transform=transforms.ToTensor(),  \n","                                           download=True)\n","\n","test_dataset = torchvision.datasets.MNIST(root='./data', train=False, \n","                                          transform=transforms.ToTensor())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443,"referenced_widgets":["4a6bcbd3ab3f41118821f69485c118db","e47067ab7a0b412b84a1c28a6baa30b6","89147e9b34b14f8e847eb46902f352a0","12393f7c85394002807577bb5c1b567b","d3b2594c6bc940b294cfbdb285c2c33b","5a67c71d7a04496dbb93b03c920b9899","9f4a070ef50248e6849c03d85e499622","687408ebd1074b55b7ef727f6f7947c2","6664def685354a319889cd01ac396ada","165dd04570f34f2f8a2a8aa53c58e280","d3ed2c3e4bb247e291d9255bb4ba893b","c4eb35a7d1e74bc29e74f4490fffb54f","42fe5d01ae39459889b8c3dc37a8137a","214e350173e5426e82fcf267d39e09ae","a9ec39fdb41b4177a4b0c9ab979cf5e6","1be10f3694a14a4fb97a2fd520203f1f","445f70f47f9c4f40827cd3cc0d7aec46","f666a5d197c24b20980f2eb0ab7fdb23","8ab81e01dbe9445a9475b258a2eb50d6","02f58df0ee39458bb1c1993c1f8f1e2b","3e93fc104ba345dcab10117f2c8d093d","b920db6e7cac4be2ba6a4c524293d74b","e5f9dcb624764d05b9bbb8ac97c96552","831aa47cd1974775b630ef71ce32b830","68c50b7991f943a0a2075345478afee8","72673ffc65b54b54aea6e0d58f3d5082","9f10fe6b944a43e383282e6bd335167a","8562451600c34de1806c23c55854a40d","ae84fefc067142348fcfc9667961683f","9643f30849b940858ef64e26baf4b410","e754bf55528d4e499246959980b22de2","23b6f6023132458796cfbf547eb42e1e","9fb42f486b2c49baa5982f7a50fed6a8","5899e62a1058491bb36f536f2a125740","9ecbb16984c449f39571316b6a010737","848c150d08f942dfafe9c9152476c405","a88a020ca7f645749d0d56a75667b0b2","67161c6868844e638b7efa3077837299","43287a76ae4447d2b059132e400f973b","2932e992948b4d0ea8486fe91e4360f5","b0277f41bb924447aab51af6b3f38b70","3ea65e15897a484f84f830b0256fb650","7e781e8f1c4548b68979d7d398b624c7","8e3d291b32634c888cc3bf8a51c638d1"]},"id":"3l-N-FB1p03P","executionInfo":{"status":"ok","timestamp":1653963561938,"user_tz":-540,"elapsed":3221,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"f923610f-0b46-4698-ad35-b2aab2b2dd88"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/9912422 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a6bcbd3ab3f41118821f69485c118db"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/28881 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4eb35a7d1e74bc29e74f4490fffb54f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1648877 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5f9dcb624764d05b9bbb8ac97c96552"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/4542 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5899e62a1058491bb36f536f2a125740"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n"]}]},{"cell_type":"code","source":["# Data loader\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size, \n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n","                                          batch_size=batch_size, \n","                                          shuffle=False)"],"metadata":{"id":"YF4wXY4Jp06A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Let us look at one batch of this data\n","examples = iter(test_loader) # convert to iter object and then unpack\n","example_data, example_targets = examples.next()\n","\n","#print the size of this data\n","print(example_data.shape, example_targets.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WJh8apSXp09k","executionInfo":{"status":"ok","timestamp":1653963570073,"user_tz":-540,"elapsed":437,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"8a1de4bd-d94e-4d61-95d6-fbdaad7ab244"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([100, 1, 28, 28]) torch.Size([100])\n"]}]},{"cell_type":"markdown","source":["100x1x28x28 = 100 samples in our batch (batch sie is 100), 1 channel, 28x28 the actual images \\\\\n","\n","Our labels is a tensor of size 100"],"metadata":{"id":"ZONOvN3qxBzZ"}},{"cell_type":"code","source":["# plot how this is looking\n","for i in range(6):\n","    plt.subplot(2, 3, i+1) # 2 rows, 3 columns and in the index i+1\n","    plt.imshow(example_data[i][0], cmap='gray') # want to show the actual data\n","                           # example_data[i] and want to access 1st channel, [0]\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":267},"id":"iX493vxBp1AF","executionInfo":{"status":"ok","timestamp":1653963574873,"user_tz":-540,"elapsed":728,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"750b86dd-d065-438b-e56f-1bf22514a58c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 6 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["# Fully connected neural network with one hidden layer\n","class NeuralNet(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super(NeuralNet, self).__init__()\n","        #self.input_size = input_size\n","        self.linear1 = nn.Linear(input_size, hidden_size) \n","        self.relu = nn.ReLU()\n","        self.linear2 = nn.Linear(hidden_size, num_classes)  \n","    \n","    # apply all the layers in the forward method\n","    def forward(self, x):\n","        out = self.linear1(x)\n","        out = self.relu(out)\n","        out = self.linear2(out)\n","        # no activation and no softmax at the end\n","        return out\n","\n","model = NeuralNet(input_size, hidden_size, num_classes).to(device) \n","      # Here, .to(device) if for pushing to the GPU if available\n"],"metadata":{"id":"Ppd-PAEwp1Dk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n","                                                        # Adam optimizer  \n"],"metadata":{"id":"tDW_BOgG0NRz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train loop\n","n_total_steps = len(train_loader)\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):  \n","        # (images, labels) = tuple\n","        # origin shape: [100, 1, 28, 28]\n","        # resized: [100, 784]\n","        # reshape our tensors first\n","        images = images.reshape(-1, 28*28).to(device)\n","        labels = labels.to(device)\n","            # Here, .to(device) if for pushing to the GPU if available\n","        \n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        \n","        # Backward and optimize\n","        optimizer.zero_grad() # to empty the values in the gradient attribute\n","        loss.backward() # calls the back propagation\n","        optimizer.step() # does update the parameters\n","        \n","        if (i+1) % 100 == 0:\n","            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M2xPfbqWp1Gn","executionInfo":{"status":"ok","timestamp":1653963617137,"user_tz":-540,"elapsed":10809,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"9c73b814-c5bc-41ee-98f1-5e3d5ede2258"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/2], Step [100/600], Loss: 0.3849\n","Epoch [1/2], Step [200/600], Loss: 0.3708\n","Epoch [1/2], Step [300/600], Loss: 0.2297\n","Epoch [1/2], Step [400/600], Loss: 0.2880\n","Epoch [1/2], Step [500/600], Loss: 0.3104\n","Epoch [1/2], Step [600/600], Loss: 0.2931\n","Epoch [2/2], Step [100/600], Loss: 0.1977\n","Epoch [2/2], Step [200/600], Loss: 0.2539\n","Epoch [2/2], Step [300/600], Loss: 0.0955\n","Epoch [2/2], Step [400/600], Loss: 0.2193\n","Epoch [2/2], Step [500/600], Loss: 0.2170\n","Epoch [2/2], Step [600/600], Loss: 0.1062\n"]}]},{"cell_type":"markdown","source":["Sometimes, the loss may increase but finally it will decrease."],"metadata":{"id":"n5w3QEjb5pfF"}},{"cell_type":"code","source":["# Test the model\n","# In test phase, we don't need to compute gradients (for memory efficiency)\n","with torch.no_grad():\n","    n_correct = 0 # number of correct prediction\n","    n_samples = 0 # number of samples\n","\n","    #Loop over the test batches\n","    for images, labels in test_loader:\n","        images = images.reshape(-1, 28*28).to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        # max returns (value ,index)\n","        _, predicted = torch.max(outputs.data, 1) # along the dimension 1\n","        n_samples += labels.size(0)  # labels.shape(0)\n","        n_correct += (predicted == labels).sum().item()\n","\n","    # accuracy\n","    acc = 100.0 * n_correct / n_samples\n","    print(f'Accuracy of the network on the 10000 test images: {acc} %')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"16V_hkFQp1Jq","executionInfo":{"status":"ok","timestamp":1653963622229,"user_tz":-540,"elapsed":1207,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"f521d543-78bc-41c5-f1c6-4aa27b840ad1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the network on the 10000 test images: 95.02 %\n"]}]},{"cell_type":"markdown","source":["# **TensorBoard**"],"metadata":{"id":"T7rL062m8rAd"}},{"cell_type":"markdown","source":["**TensorBoard** is a visualization toolkit:\n","* Tracking and visualizing metrics such as loss and accuracy, \n","* Visualizing the model graph (ops and layers),* Viewing histograms of weights, biases, or other tensors as they change over time,\n","* Projecting embeddings to a lower dimensional space.\n","* Displaying images, text, and audio data,\n","* Profiling TensorFlow programs\n","* and much more."],"metadata":{"id":"PMDDcX1e87Ee"}},{"cell_type":"markdown","source":["Now let us use the TensorBoard for analyzing the previous CNN example a little bit more."],"metadata":{"id":"0qZloZB5Fddd"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n"],"metadata":{"id":"3VtxwWfW6kOT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let us install TensorBoard first. No need of importing the whole tensorflow library, tensor board is enough."],"metadata":{"id":"jwskzSMEGXqe"}},{"cell_type":"code","source":["############## TENSORBOARD ########################\n","import sys\n","import torch.nn.functional as F\n","from torch.utils.tensorboard import SummaryWriter\n","# default `log_dir` is \"runs\" - we'll be more specific here\n","writer = SummaryWriter('/content/drive/MyDrive/Colab Notebooks/mnist')\n","###################################################"],"metadata":{"id":"DoPiHv7V6kRy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"FaFLMrGA6kU1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Hyper-parameters \n","input_size = 784 # 28x28\n","hidden_size = 500 \n","num_classes = 10\n","num_epochs = 1\n","batch_size = 64\n","learning_rate = 0.001\n"],"metadata":{"id":"VpgDgmRQ6kYC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# MNIST dataset \n","train_dataset = torchvision.datasets.MNIST(root='./data', \n","                                           train=True, \n","                                           transform=transforms.ToTensor(),  \n","                                           download=True)\n","\n","test_dataset = torchvision.datasets.MNIST(root='./data', \n","                                          train=False, \n","                                          transform=transforms.ToTensor())\n","\n","# Data loader\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n","                                           batch_size=batch_size, \n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n","                                          batch_size=batch_size, \n","                                          shuffle=False)\n","\n","examples = iter(test_loader)\n","example_data, example_targets = examples.next()\n","\n","for i in range(6):\n","    plt.subplot(2,3, i+1)\n","    plt.imshow(example_data[i][0], cmap='gray')\n","#plt.show() \n","\n","# Instead of plotting, we add the images in the tensorboard.\n","############## TENSORBOARD ########################\n","img_grid = torchvision.utils.make_grid(example_data)\n","writer.add_image('mnist_images', img_grid)\n","#writer.close() # all the outputs are flashed here\n","#sys.exit() # not to run the whole training pipline\n","###################################################"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":267},"id":"qHRenx7-6kbV","executionInfo":{"status":"ok","timestamp":1653967711077,"user_tz":-540,"elapsed":1840,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"480a18e9-d229-472e-b7bf-2b7a46f06f5e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 6 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["# Fully connected neural network with one hidden layer\n","class NeuralNet(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super(NeuralNet, self).__init__()\n","        self.input_size = input_size\n","        self.l1 = nn.Linear(input_size, hidden_size) \n","        self.relu = nn.ReLU()\n","        self.l2 = nn.Linear(hidden_size, num_classes)  \n","    \n","    def forward(self, x):\n","        out = self.l1(x)\n","        out = self.relu(out)\n","        out = self.l2(out)\n","        # no activation and no softmax at the end\n","        return out\n","\n","model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n"],"metadata":{"id":"TElaHIQO6kei"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["############## TENSORBOARD ########################\n","writer.add_graph(model, example_data.reshape(-1, 28*28))\n","#writer.close()\n","#sys.exit()\n","###################################################"],"metadata":{"id":"Kc7DDL8B6kh6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","running_loss = 0.0 # this initialization is for poltting the loss\n","running_correct = 0\n","n_total_steps = len(train_loader)\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):  \n","        # origin shape: [100, 1, 28, 28]\n","        # resized: [100, 784]\n","        images = images.reshape(-1, 28*28).to(device)\n","        labels = labels.to(device)\n","        \n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        \n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        running_loss += loss.item()\n","\n","        _, predicted = torch.max(outputs.data, 1)\n","        running_correct += (predicted == labels).sum().item()\n","        if (i+1) % 100 == 0:\n","            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n","            ############## TENSORBOARD ########################\n","            # mean for every 100 steps\n","            writer.add_scalar('training loss', running_loss / 100, epoch * n_total_steps + i)\n","            running_accuracy = running_correct / 100 / predicted.size(0)\n","            writer.add_scalar('accuracy', running_accuracy, epoch * n_total_steps + i)\n","            running_correct = 0\n","            running_loss = 0.0\n","            ###################################################"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1eNY0ers6kle","executionInfo":{"status":"ok","timestamp":1653968361225,"user_tz":-540,"elapsed":20089,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"8b5f43ca-d039-4006-b8e5-391155e67234"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/1], Step [100/938], Loss: 0.4670\n","Epoch [1/1], Step [200/938], Loss: 0.2942\n","Epoch [1/1], Step [300/938], Loss: 0.2117\n","Epoch [1/1], Step [400/938], Loss: 0.1756\n","Epoch [1/1], Step [500/938], Loss: 0.1380\n","Epoch [1/1], Step [600/938], Loss: 0.1464\n","Epoch [1/1], Step [700/938], Loss: 0.1141\n","Epoch [1/1], Step [800/938], Loss: 0.0712\n","Epoch [1/1], Step [900/938], Loss: 0.1896\n"]}]},{"cell_type":"code","source":["# Test the model\n","# In test phase, we don't need to compute gradients (for memory efficiency)\n","class_labels = [] # for calculating precision accuracy\n","class_preds = []\n","with torch.no_grad():\n","    n_correct = 0\n","    n_samples = 0\n","    for images, labels1 in test_loader:\n","        images = images.reshape(-1, 28*28).to(device)\n","        labels = labels1.to(device)\n","        outputs = model(images)\n","        # max returns (value ,index)\n","        values, predicted = torch.max(outputs.data, 1)\n","        n_samples += labels1.size(0)\n","        n_correct += (predicted == labels1).sum().item()\n","\n","        class_probs_batch = [F.softmax(output, dim=0) for output in outputs]\n","\n","        class_preds.append(class_probs_batch)\n","        class_labels.append(predicted)\n","\n","    # 10000, 10, and 10000, 1\n","    # stack concatenates tensors along a new dimension\n","    # cat concatenates tensors in the given dimension\n","    class_preds = torch.cat([torch.stack(batch) for batch in class_preds])\n","    class_labels = torch.cat(class_labels)\n","\n","    acc = 100.0 * n_correct / n_samples\n","    print(f'Accuracy of the network on the 10000 test images: {acc} %')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kx6ycOa76koq","executionInfo":{"status":"ok","timestamp":1653969148842,"user_tz":-540,"elapsed":1507,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"35ae9506-992c-46ac-b4eb-52681cba46cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the network on the 10000 test images: 96.16 %\n"]}]},{"cell_type":"code","source":["    ############## TENSORBOARD ########################\n","    # adding a precision recall curve for each class\n","    classes = range(10)\n","    for i in classes:\n","        labels_i = class_labels == i\n","        preds_i = class_preds[:, i]\n","        writer.add_pr_curve(str(i), labels_i, preds_i, global_step=0)\n","        writer.close()\n","    ###################################################"],"metadata":{"id":"UIHZvF-G6ksa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"He3ch44XltaN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Convolutional Neural Net (CNN)**"],"metadata":{"id":"89gUjt2m546Z"}},{"cell_type":"markdown","source":["Using the Cifar-10 dataset: 60000 32x32 color images in 10 completely mutually-exclusive classes (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck), with 6000 images per class. There are 50000 training images and 10000 test images."],"metadata":{"id":"n0TSY-zx61iE"}},{"cell_type":"code","source":[],"metadata":{"id":"tP_0VDFPltXe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Transfer Learning**"],"metadata":{"id":"3GOqlYSv8WR7"}},{"cell_type":"code","source":[],"metadata":{"id":"RpmbAq_u6kK_"},"execution_count":null,"outputs":[]}]}