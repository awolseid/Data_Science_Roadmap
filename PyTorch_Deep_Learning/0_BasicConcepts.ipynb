{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1sQb7ir7tvtzCEXKEWEbq0cIXh2cVTtbm","timestamp":1718817207891}],"toc_visible":true,"mount_file_id":"1q6LpgsXf8mQsy_Cg1hA6LTDnn5JGsEhf","authorship_tag":"ABX9TyOScR+EZ82y527R042vS/4t"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":[],"metadata":{"id":"531f4_Dd1Lwx"}},{"cell_type":"markdown","source":["# **Data in ML/DL**\n","\n","- \"**Data**\" in ML (Machine Learning) or DL (Deep Learning) can be **almost any information** such as\n","    - **table of values**: 2-dimensional, consisting of rows and columns.\n","    - **images**: 3-dimensional arrays (tensors); Height x Width x Channels = `256x256x3`.\n","    - **videos**: Sequences of images (frames), adding a time dimension to the 3-dimensional structure of images.\n","      - Time x Height x Width x Channels = `300x256x256x3`\n","        - 30 frames of 256x256 color image per second, and 10 seconds long.\n","    - **audio** files: 1-dimensional arrays for **mono audio** (time) or 2-dimensional arrays for **stereo audio** (Time x Channels).\n","      - `441000x2` = a stereo audio file with a sampling rate of 44.1 kHz (44100 samples per second) and 10 seconds long.\n","    - **text**: Often represented as sequences of tokens (words, characters).\n","      - Number of Tokens (for a single sentence) or Number of Documents x Number of Tokens (for a corpus)\n","      - A sentence can be represented as a 1-dimensional array of word indices. A collection of sentences can be represented as a 2-dimensional array, with each row representing a sentence and each column representing a word index.\n","    - **protein structures**: Often involving 3D coordinates.\n","      - A protein with 1000 atoms can be represented as a 1000x3 array where each row represents the x, y, z coordinates of an atom."],"metadata":{"id":"BolHamYbgbLs"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Example of a 256x256 RGB image\n","image = np.random.rand(256, 256, 3)\n","image.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aE8Cc7j_f0Nw","executionInfo":{"status":"ok","timestamp":1721535283150,"user_tz":-540,"elapsed":345,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"cebead3b-dff3-4722-cb5b-236f06f009f3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(256, 256, 3)"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["# Example of a 10-second video with 30 FPS and 256x256 RGB frames\n","video = np.random.rand(300, 256, 256, 3)\n","video.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SJIiy2wkf8lX","executionInfo":{"status":"ok","timestamp":1721535310567,"user_tz":-540,"elapsed":2480,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"03294596-98df-4c31-c570-78ce00208b67"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(300, 256, 256, 3)"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# Example of a 10-second stereo audio file at 44.1 kHz\n","audio = np.random.rand(441000, 2)\n","audio.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8FYbkEsBgCQ8","executionInfo":{"status":"ok","timestamp":1721535323587,"user_tz":-540,"elapsed":366,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"3beceaa6-c6f9-4a95-8f78-0319e1b74552"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(441000, 2)"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["# Example of a protein structure with 1000 atoms\n","protein_structure = np.random.rand(1000, 3)\n","protein_structure.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BQQUglO2gF6L","executionInfo":{"status":"ok","timestamp":1721535348918,"user_tz":-540,"elapsed":342,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"b277fce0-7112-40c9-e71d-2f9a0a58b76d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1000, 3)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# Example of a document represented as sequences of word indices\n","document = [1, 5, 23, 56, 78]  # A single sentence\n","corpus = [[1, 5, 23], [56, 78, 92], [3, 14, 15, 92]]  # A collection of sentences"],"metadata":{"id":"LwL60LlEgMKz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ci_-geIdec0w"},"source":["- The goal of ML/DL is to:\n","    - Turn the data into a **representative set of numerical values** and\n","    - Then build a model to **learn the numerical representation** of the data as best as possible.\n","\n","<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20230413105611/Maachine-Learning.webp\" alt=\"Scope of data science\" width=\"500\">"]},{"cell_type":"markdown","source":["# **PyTorch**\n","\n","- PyTorch was released in January 2017 by Facebook AI Research (FAIR) lab.\n","- It is an open-source project and has contributions from many developers worldwide.\n","- **NVIDIA** has been known for its design and manufacture of graphics processing units (GPUs).\n","- It has been a significant contributor to the PyTorch ecosystem.\n","    - Especially in terms of providing support for CUDA (Compute Unified Device Architecture).\n","    - CUDA is a parallel computing platform developed by NVIDIA for general computing on GPUs.\n","    - This ensures that PyTorch can leverage NVIDIA GPUs for accelerated computing."],"metadata":{"id":"ZW6wmWVhb0wi"}},{"cell_type":"code","source":["import torch\n","\n","torch.__version__"],"metadata":{"id":"Z6V0m54sa5UM","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1721130998908,"user_tz":-540,"elapsed":9512,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"5f3d8c05-5079-498d-dc52-2da39eba93df"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.3.0+cu121'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["- The suffix `cu121` in  `2.3.0+cu121` indicates the version of CUDA that the PyTorch build is compatible with.\n","- This means that this version of PyTorch (2.3.0) is compatible with NVIDIA GPUs that support CUDA 12.1."],"metadata":{"id":"1XXTSdyPcBf6"}},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"0Que7JXOQ52T","executionInfo":{"status":"ok","timestamp":1721130998909,"user_tz":-540,"elapsed":58,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"15921858-5b6e-4b23-dae4-bb537e3f1d9f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cpu'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import random\n","\n","def set_seed(seed=42):\n","    torch.manual_seed(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","\n","    # torch.backends.cudnn.deterministic = True\n","    # torch.backends.cudnn.benchmark = False\n","\n","set_seed()\n"],"metadata":{"id":"xarsBiV-LNIR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **1. [Tensors](https://pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html)**\n","\n","* Tensor is the primary data structure in PyTorch.\n","* Everything in pytorch is based on **tensor** operations.\n","* A tensor can have **different dimensions**.\n","* So it can be scalar (**0D**), vector (**1D**), matrix (**2D**), or **3D** and higher.\n","\n","\\\\\n","\n","<img src=\"https://github.com/awolseid/tutorial_figures/blob/main/TensorNumbers.jpg?raw=true\" alt=\"Tensors\" width=\"400\">\n","\n","\\\\\n","\n","<img src=\"https://github.com/awolseid/tutorial_figures/blob/main/TensorsFig.png?raw=true\" alt=\"Tensors\" width=\"600\">\n","\n","\n","\n","\n","\n"],"metadata":{"id":"E4bBGDYSTi4i"}},{"cell_type":"markdown","metadata":{"id":"JXqdRH8h4uZc"},"source":["## **1.01. Creating Tensors: `torch.tensor()` and `torch.Tensor()`**\n","\n","- The PyTorch documentation indicates that `torch.Tensor` is an alias for `torch.FloatTensor`.\n","    - It happens to be very similar in name to `torch.tensor`, but, it has a very different behaviour.\n","    - On the other hand, `torch.tensor` infers the` dtype` automatically, while `torch.Tensor` returns a `torch.FloatTensor`.\n","- For example, `print(torch.Tensor([1, 3]))` gives the output `tensor([1., 3.])` (data type = `torch.float32`) whereas `print(torch.tensor([1, 3]))` gives the output `tensor([1, 3])` (data type = `torch.int64`).\n"]},{"cell_type":"code","source":["x1 = torch.tensor([1])\n","x1, x1.ndim, x1.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9xMEamW8D6nX","executionInfo":{"status":"ok","timestamp":1721130998915,"user_tz":-540,"elapsed":48,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"dfaf398b-e109-4b19-8eec-772364337692"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([1]), 1, torch.int64)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["x2 = torch.tensor([1, 2])\n","x2, x2.ndim, x2.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nG-FjBSxD6uj","executionInfo":{"status":"ok","timestamp":1721130998916,"user_tz":-540,"elapsed":44,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"c229c7df-b636-4268-f559-66c2b5a6d35a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([1, 2]), 1, torch.int64)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["x3 = torch.tensor([[1, 2], [3, 4]])\n","x3, x3.ndim, x3.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bcMqEed3D61L","executionInfo":{"status":"ok","timestamp":1721130998916,"user_tz":-540,"elapsed":32,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"a3128b91-1cd4-4290-d02d-3f95c6899bbe"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[1, 2],\n","         [3, 4]]),\n"," 2,\n"," torch.int64)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["x4 = torch.tensor([[[1, 2], [3, 2]], [[1, 7], [5, 4]]])\n","x4, x4.ndim, x4.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sOWmBgpMFMmL","executionInfo":{"status":"ok","timestamp":1721130999513,"user_tz":-540,"elapsed":620,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"4536dacb-04b2-44fe-cada-0f5e36558950"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[[1, 2],\n","          [3, 2]],\n"," \n","         [[1, 7],\n","          [5, 4]]]),\n"," 3,\n"," torch.int64)"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["## **1.02. Constant fills**"],"metadata":{"id":"bSMJaNS-Asz7"}},{"cell_type":"code","source":["x = torch.zeros(2, 3)\n","x, x.ndim, x.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V4qpPBSxP0pS","executionInfo":{"status":"ok","timestamp":1721130999583,"user_tz":-540,"elapsed":95,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"825c3a0f-e8db-4150-d554-bd6df227aa4e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[0., 0., 0.],\n","         [0., 0., 0.]]),\n"," 2,\n"," torch.float32)"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["x = torch.ones(2, 3)\n","x, x.ndim, x.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pxYJn6vWP0sB","executionInfo":{"status":"ok","timestamp":1721130999584,"user_tz":-540,"elapsed":91,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"be37ff9e-a397-400b-c406-2f159c113f49"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[1., 1., 1.],\n","         [1., 1., 1.]]),\n"," 2,\n"," torch.float32)"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["## **1.03. Tensor data types**"],"metadata":{"id":"hfNDi8lzA1Dt"}},{"cell_type":"code","source":["x = torch.tensor([2.5, 0.1])\n","x, x.ndim, x.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_LxfnTk7P09z","executionInfo":{"status":"ok","timestamp":1721130999584,"user_tz":-540,"elapsed":85,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"486745a4-befe-4595-81fe-d8082719068b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([2.5000, 0.1000]), 1, torch.float32)"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["x = torch.ones(2, 3)\n","x, x.ndim, x.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"id1va3WCP0vS","executionInfo":{"status":"ok","timestamp":1721130999983,"user_tz":-540,"elapsed":479,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"8280277f-efab-410d-d29b-2086627f429c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[1., 1., 1.],\n","         [1., 1., 1.]]),\n"," 2,\n"," torch.float32)"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["x = torch.ones(2, 3, dtype=torch.int)\n","x, x.ndim, x.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mVdqApqqP0yB","executionInfo":{"status":"ok","timestamp":1721130999983,"user_tz":-540,"elapsed":40,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"4af2068c-6bf5-4d44-d0d1-c1332c20a697"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[1, 1, 1],\n","         [1, 1, 1]], dtype=torch.int32),\n"," 2,\n"," torch.int32)"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["x = torch.ones(2, 3, dtype=torch.double)\n","x, x.ndim, x.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xJ0y6L2mP00x","executionInfo":{"status":"ok","timestamp":1721130999983,"user_tz":-540,"elapsed":36,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"0d3a13e7-76ed-4fea-8239-9d4d96d15995"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[1., 1., 1.],\n","         [1., 1., 1.]], dtype=torch.float64),\n"," 2,\n"," torch.float64)"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["x = torch.ones(2, 3, dtype=torch.float16)\n","x, x.ndim, x.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aQzGv07BP03y","executionInfo":{"status":"ok","timestamp":1721130999983,"user_tz":-540,"elapsed":34,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"adcf494d-da34-4a03-f76b-0ea6a247dd2a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[1., 1., 1.],\n","         [1., 1., 1.]], dtype=torch.float16),\n"," 2,\n"," torch.float16)"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["x = torch.ones(2, 3, dtype=torch.float16)\n","x, x.ndim, x.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lb9ThaOEP06i","executionInfo":{"status":"ok","timestamp":1721130999983,"user_tz":-540,"elapsed":31,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"a4e3d5f3-8c73-407b-cec4-1fad76d58223"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[1., 1., 1.],\n","         [1., 1., 1.]], dtype=torch.float16),\n"," 2,\n"," torch.float16)"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":["## **1.04. Tensor operations**"],"metadata":{"id":"uTIaWwp__W2q"}},{"cell_type":"markdown","metadata":{"id":"VBC_HD024zT7"},"source":["##### **Pointwise** Ops"]},{"cell_type":"markdown","metadata":{"id":"YQDWkg-S4zT9"},"source":["  - [`torch.abs()`](https://pytorch.org/docs/stable/generated/torch.abs.html#torch.abs): returns the abosolute value of each element of a tensor.\n","  - [`torch.ceil()`](https://pytorch.org/docs/stable/generated/torch.ceil.html#torch.ceil): Returns the ceil of the elements of a tensor, the smallest integer greater than or equal to each element.\n","  - [`torch.exp()`](https://pytorch.org/docs/stable/generated/torch.exp.html#torch.exp): Returns the exponential of the elements of a tensor."]},{"cell_type":"code","source":["a = torch.tensor([-1.9, -2.3, 3])\n","print(torch.abs(a))\n","print(torch.ceil(a))\n","print(torch.exp(a))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PdoboJgthxfF","executionInfo":{"status":"ok","timestamp":1721381204748,"user_tz":-540,"elapsed":376,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"c6cbe67b-7d4a-496c-f475-45d449c5c56d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1.9000, 2.3000, 3.0000])\n","tensor([-1., -2.,  3.])\n","tensor([ 0.1496,  0.1003, 20.0855])\n"]}]},{"cell_type":"markdown","metadata":{"id":"zLFA5jeb7dcB"},"source":["##### **Reduction** Ops\n"]},{"cell_type":"markdown","metadata":{"id":"poy8CCOC7dcC"},"source":["  - [`torch.argmax()`](https://pytorch.org/docs/stable/generated/torch.argmax.html#torch.argmax): returns the indices of the max value of all the elements of a tensor.\n","  - [`torch.mean()`](https://pytorch.org/docs/stable/generated/torch.mean.html#torch.mean): returns the mean value of all the elements of a tensor.\n","  - [`torch.unique()`](https://pytorch.org/docs/stable/generated/torch.exp.html#torch.exp): returns the unique elements of a tensor.\n"]},{"cell_type":"code","source":["a = torch.tensor([1, 2.3, 0.9])\n","print(torch.argmax(a))\n","print(torch.mean(a))\n","\n","a = torch.tensor ([-1, 2, -1, 0, 0.1, 0.1, 1, 0.1])\n","print(torch.unique(a))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iqQUF5Uuh4kf","executionInfo":{"status":"ok","timestamp":1654941066659,"user_tz":-540,"elapsed":167,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"a65edde4-bc70-4821-ec8b-75cd17e5dfd8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(1)\n","tensor(1.4000)\n","tensor([-1.0000,  0.0000,  0.1000,  1.0000,  2.0000])\n"]}]},{"cell_type":"markdown","source":["##### **Elementwise** Ops\n","\n","- `+` : [`torch.add()`](https://pytorch.org/docs/stable/generated/torch.add.html?highlight=add#torch.add)\n","- `-` : [`torch.sub()`](https://pytorch.org/docs/stable/generated/torch.sub.html)\n","- `*` : [`torch.mul()`](https://pytorch.org/docs/stable/generated/torch.mul.html)\n","- `/` : [`torch.div()`](https://pytorch.org/docs/stable/generated/torch.div.html)"],"metadata":{"id":"jYaFKhZC_kLZ"}},{"cell_type":"code","source":["x = torch.rand(2, 2)\n","y = torch.rand(2, 2)\n","x, y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9botrJqlP1Ai","executionInfo":{"status":"ok","timestamp":1721130999983,"user_tz":-540,"elapsed":29,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"ae8074c7-139c-448a-a0d9-9e8800284a65"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[0.9147, 0.2036],\n","         [0.2018, 0.2018]]),\n"," tensor([[0.9497, 0.6666],\n","         [0.9811, 0.0874]]))"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["z = x + y\n","print(z)\n","z=torch.add(x, y)\n","print(z)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7s3OfN2WVcnU","executionInfo":{"status":"ok","timestamp":1721130999983,"user_tz":-540,"elapsed":26,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"59497192-da64-4239-d624-fa806e175408"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1.8644, 0.8703],\n","        [1.1829, 0.2891]])\n","tensor([[1.8644, 0.8703],\n","        [1.1829, 0.2891]])\n"]}]},{"cell_type":"markdown","source":["- **Inplace Operations**"],"metadata":{"id":"9CaMw_KNiBMw"}},{"cell_type":"code","source":["y.add_(x)\n","print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fqKj3hw0Vcqi","executionInfo":{"status":"ok","timestamp":1721130999984,"user_tz":-540,"elapsed":23,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"b15fefa9-c664-4aa1-f4e3-e00f137ccbcb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1.8644, 0.8703],\n","        [1.1829, 0.2891]])\n"]}]},{"cell_type":"code","source":["z = x - y\n","print(z)\n","z = torch.sub(x, y)\n","print(z)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l8RnH-BjVcth","executionInfo":{"status":"ok","timestamp":1721130999984,"user_tz":-540,"elapsed":20,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"dca6fe82-7af7-4a0f-94b9-df3d2ce585bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-0.9497, -0.6666],\n","        [-0.9811, -0.0874]])\n","tensor([[-0.9497, -0.6666],\n","        [-0.9811, -0.0874]])\n"]}]},{"cell_type":"code","source":["z = x * y\n","print(z)\n","z = torch.mul(x,y)\n","print(z)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"USE6-y3fVcwR","executionInfo":{"status":"ok","timestamp":1721130999984,"user_tz":-540,"elapsed":18,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"482f0581-9901-4b3b-f85a-5fa7d478c638"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1.7054, 0.1772],\n","        [0.2387, 0.0583]])\n","tensor([[1.7054, 0.1772],\n","        [0.2387, 0.0583]])\n"]}]},{"cell_type":"code","source":["z = x / y\n","print(z)\n","z = torch.div(x,y)\n","print(z)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yohIVvHIVczT","executionInfo":{"status":"ok","timestamp":1721130999984,"user_tz":-540,"elapsed":16,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"0691a2b2-0a57-4eeb-fedf-16155fd214ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.4906, 0.2340],\n","        [0.1706, 0.6979]])\n","tensor([[0.4906, 0.2340],\n","        [0.1706, 0.6979]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"IJNyfmll_h_o"},"source":["##### **Comparison** Ops"]},{"cell_type":"markdown","metadata":{"id":"rOStUYzm_h_p"},"source":["  - [`torch.eq()`](https://pytorch.org/docs/stable/generated/torch.eq.html#torch.eq): computes element-wise equality between two tensors.\n","  - [`torch.equal()`](https://pytorch.org/docs/stable/generated/torch.equal.html#torch.equal): returns 'True' if two tensors have the same size and elements.\n","  - [`torch.sort()`](https://pytorch.org/docs/stable/generated/torch.sort.html#torch.sort): sorts the elements of the tensor along a given dimension in an increasing order of values."]},{"cell_type":"code","source":["a = torch.tensor([[1, 5], [5, 4]])\n","b = torch.tensor([[1, 2], [3, 3]])\n","\n","print(torch.eq(a, b))\n","print(torch.equal(a, b))\n","\n","print(torch.sort(a, 0)) # sort by row\n","print(torch.sort(a, 1)) # sort by column"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EFIwFjIOo84t","executionInfo":{"status":"ok","timestamp":1721381398503,"user_tz":-540,"elapsed":332,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"06917fc4-25e7-4ae1-e2ff-16d1a123476a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ True, False],\n","        [False, False]])\n","False\n","torch.return_types.sort(\n","values=tensor([[1, 4],\n","        [5, 5]]),\n","indices=tensor([[0, 1],\n","        [1, 0]]))\n","torch.return_types.sort(\n","values=tensor([[1, 5],\n","        [4, 5]]),\n","indices=tensor([[0, 1],\n","        [1, 0]]))\n"]}]},{"cell_type":"markdown","source":["## **1.05. Slicing**\n"],"metadata":{"id":"gOeCswav_2v6"}},{"cell_type":"code","source":["set_seed()\n","x = torch.rand(5,3)\n","print(x)\n","print(x[:, 0])\n","print(x[1, :])\n","print(x[1,1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"10aE7JvmVc2h","executionInfo":{"status":"ok","timestamp":1721130999984,"user_tz":-540,"elapsed":13,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"30587fa9-696f-4514-a451-a952b6ddc3e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.8823, 0.9150, 0.3829],\n","        [0.9593, 0.3904, 0.6009],\n","        [0.2566, 0.7936, 0.9408],\n","        [0.1332, 0.9346, 0.5936],\n","        [0.8694, 0.5677, 0.7411]])\n","tensor([0.8823, 0.9593, 0.2566, 0.1332, 0.8694])\n","tensor([0.9593, 0.3904, 0.6009])\n","tensor(0.3904)\n"]}]},{"cell_type":"markdown","source":["- Getting a value if there is only 1 element in the tensor"],"metadata":{"id":"ebfrBUoaADm6"}},{"cell_type":"code","source":["print(x[1, 1].item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qYIr5IRdVc52","executionInfo":{"status":"ok","timestamp":1721130999984,"user_tz":-540,"elapsed":8,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"c8bfbfc8-6bc7-4cf8-d0bd-c4099678a408"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.3904482126235962\n"]}]},{"cell_type":"markdown","metadata":{"id":"LZ0zV31lX6zN"},"source":["**index_select**\n","\n","\n","``` python\n","[[1 2]\n"," [3 4]\n","```\n","I want to get `[1 3]` from a 2D tensor!\n","\n","- [`torch.index_select()`](https://pytorch.org/docs/stable/generated/torch.index_select.html?highlight=index#torch.index_select)\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wIDKrXzXZs07","executionInfo":{"status":"ok","timestamp":1721372503694,"user_tz":-540,"elapsed":369,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"09070010-6a8a-4f5e-be39-181f09947158"},"source":["import torch\n","\n","A = torch.Tensor([[1, 2],\n","                  [3, 4]])\n","indices = torch.tensor([0])\n","output1 = torch.index_select(A, 1, indices).reshape([1, -1])\n","output2 = torch.index_select(A, 1, indices).view(-1,)\n","\n","output1, output2"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[1., 3.]]), tensor([1., 3.]))"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["Do it in a similar way to Python List Indexing!"],"metadata":{"id":"UkKCLSxgzM69"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Co8YFuVtaVZr","executionInfo":{"status":"ok","timestamp":1721372587646,"user_tz":-540,"elapsed":374,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"9750dab7-be87-474a-fd86-557f2934e086"},"source":["output = A[:, 0]\n","output"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1., 3.])"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"TwdiREr_YLEa"},"source":["**Import diagonal elements from 2D sensor - 2D daughter**\n","\n","``` python\n","[[1 2]\n"," [3 4]]\n","```\n","I want to make a 1D tensor by taking **only diagonal elements** from a 2D tensor\n","\n","- [`torch.gather()`](https://pytorch.org/docs/stable/generated/torch.gather.html#torch.gather)\n"]},{"cell_type":"code","source":["import torch\n","matrix = torch.arange(0,100).reshape(10,10)\n","print(matrix)\n","indices = torch.arange(0,10)\n","print(indices)\n","indices = indices.unsqueeze(axis=1)\n","print(indices)\n","\n","output = torch.gather(matrix, 1, indices).reshape([1, -1])\n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D5OC-STDIPB_","executionInfo":{"status":"ok","timestamp":1721373285159,"user_tz":-540,"elapsed":350,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"b1b4b238-b25d-40f4-df34-1bd3190bf299"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n","        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n","        [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n","        [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n","        [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n","        [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n","        [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n","        [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],\n","        [80, 81, 82, 83, 84, 85, 86, 87, 88, 89],\n","        [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]])\n","tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n","tensor([[0],\n","        [1],\n","        [2],\n","        [3],\n","        [4],\n","        [5],\n","        [6],\n","        [7],\n","        [8],\n","        [9]])\n","tensor([[ 0, 11, 22, 33, 44, 55, 66, 77, 88, 99]])\n"]}]},{"cell_type":"code","source":["torch.arange(0,10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"__4o-X-F07g0","executionInfo":{"status":"ok","timestamp":1721373063369,"user_tz":-540,"elapsed":349,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"9e3bf8f5-39e6-469f-814f-ec56730c28ef"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kwx3LEqKbU9M","executionInfo":{"status":"ok","timestamp":1721374105117,"user_tz":-540,"elapsed":377,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"b19ac84b-afdf-4d32-8a66-7b180b159ac7"},"source":["import torch\n","\n","A = torch.Tensor([[1, 2],\n","                  [3, 4]])\n","\n","indices = torch.tensor([0, 1]).unsqueeze(axis=1)\n","output = torch.gather(A, 1, indices).reshape([1, -1])\n","output"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 4.]])"]},"metadata":{},"execution_count":38}]},{"cell_type":"markdown","metadata":{"id":"SHpq-zKFdQ8j"},"source":["-Consider\n","\n","``` python\n","[[[1 2]\n","  [3 4]]\n"," [[5 6]\n","  [7 8]\n","```\n","I want to make a two-dimensional tensor called\n","\n","```\n","  [[1 4]\n","   [5 8]]\n","```\n","\n","\n","   \n","   by taking only diagonal elements from the three-dimensional tensor\n","- [`torch.gather()`](https://pytorch.org/docs/stable/generated/torch.gather.html#torch.gather)\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N7_WCGcpdQ81","executionInfo":{"status":"ok","timestamp":1721374502468,"user_tz":-540,"elapsed":364,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"4ad0b100-8ad1-4be3-ff16-31fb13faa21c"},"source":["import torch\n","\n","A = torch.Tensor([[[1, 2],\n","                   [3, 4]],\n","                  [[5, 6],\n","                   [7, 8]]])\n","\n","indices = torch.tensor([\n","                        [[0],[1]],\n","                        [[0],[1]]\n","                        ])\n","output = torch.gather(A, 2, indices).reshape([2, 2])  #.view(2, 2)\n","output"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 4.],\n","        [5., 8.]])"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"VfmnV6cRuYf5"},"source":["So far, we've taken diagonal elements from inputs of a given size.\n","Can a 3D tensor of any size take diagonal elements and make a 2D tensor as well?\n","\n","- to make the desired size of the [`torch.Tensor.expand()`](https://pytorch.org/docs/stable/generated/torch.Tensor.expand.html?highlight=expand) is available!"]},{"cell_type":"code","metadata":{"id":"yg_byIzJxoPC"},"source":["import torch\n","\n","def get_diag_element_3D(A):\n","  C, H, W = A.size()\n","  diag_size = min(H,W)\n","\n","  gather_index = torch.arange(diag_size).view(diag_size, -1).expand(C, diag_size, 1)\n","  output = torch.gather(A, 2, gather_index)\n","  output = output.view(C, diag_size)\n","  return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7q9gz0d5rYiG","executionInfo":{"status":"ok","timestamp":1721376213240,"user_tz":-540,"elapsed":3,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"3747508f-7e21-4b72-8077-1cb72ccec50c"},"source":["C = 1\n","H = 2\n","W = 3\n","\n","A = torch.tensor([i for i in range(1, C*H*W + 1)])\n","A = A.view(C, H, W)\n","\n","get_diag_element_3D(A)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 5]])"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ORBb-HPcJnCg","executionInfo":{"status":"ok","timestamp":1721376314147,"user_tz":-540,"elapsed":394,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"10967c11-3de4-4341-a7ec-697ceb9ccd5a"},"source":["A = torch.tensor([[[1]]])\n","\n","torch.all(get_diag_element_3D(A) == torch.Tensor([[1]]))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(True)"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pSbNIk3tyj8U","executionInfo":{"status":"ok","timestamp":1721376289622,"user_tz":-540,"elapsed":603,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"9d9deae8-7bb3-447a-f84b-09b38fd0f815"},"source":["A = torch.Tensor([[[1, 2],\n","                   [3, 4]],\n","                  [[5, 6],\n","                   [7, 8]]])\n","\n","torch.all(get_diag_element_3D(A) == torch.Tensor([[1, 4], [5, 8]]))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(True)"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H3ewV_sBJ-nm","executionInfo":{"status":"ok","timestamp":1721376351791,"user_tz":-540,"elapsed":378,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"4059f1f8-cf56-424b-accc-8b2d55919bc1"},"source":["A = torch.Tensor([[[1, 2, 3],\n","                   [4, 5, 6]]])\n","\n","torch.all(get_diag_element_3D(A) == torch.Tensor([[1, 5]]))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(True)"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fueU_tOgIzDC","executionInfo":{"status":"ok","timestamp":1721376420281,"user_tz":-540,"elapsed":384,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"6835e268-ebf3-42e3-e5ef-cf9c55aa8f43"},"source":["A = torch.tensor([[[ 1,  2,  3,  4,  5],\n","                   [ 6,  7,  8,  9, 10],\n","                   [11, 12, 13, 14, 15]],\n","\n","                  [[16, 17, 18, 19, 20],\n","                   [21, 22, 23, 24, 25],\n","                   [26, 27, 28, 29, 30]]])\n","\n","torch.all(get_diag_element_3D(A) == torch.Tensor([[ 1,  7, 13],\n","                                                     [16, 22, 28]]))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(True)"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1MKSgAWOJWvb","executionInfo":{"status":"ok","timestamp":1721376439814,"user_tz":-540,"elapsed":387,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"048a7482-50b2-4e32-fca2-a176d11c63d2"},"source":["A = torch.tensor([[[ 1,  2,  3],\n","                   [ 4,  5,  6],\n","                   [ 7,  8,  9],\n","                   [10, 11, 12],\n","                   [13, 14, 15]],\n","\n","                  [[16, 17, 18],\n","                   [19, 20, 21],\n","                   [22, 23, 24],\n","                   [25, 26, 27],\n","                   [28, 29, 30]],\n","\n","                  [[31, 32, 33],\n","                   [34, 35, 36],\n","                   [37, 38, 39],\n","                   [40, 41, 42],\n","                   [43, 44, 45]]])\n","\n","torch.all(get_diag_element_3D(A) == torch.Tensor([[ 1,  5,  9],\n","                                                     [16, 20, 24],\n","                                                     [31, 35, 39]]))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(True)"]},"metadata":{},"execution_count":51}]},{"cell_type":"markdown","metadata":{"id":"5b6lTFnCjQwc"},"source":["- [`torch.zeros()`](https://pytorch.org/docs/stable/generated/torch.zeros.html#torch.zeros)\n","- [`torch.zeros_like()`](https://pytorch.org/docs/stable/generated/torch.zeros_like.html#torch.zeros_like)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vhp7vsgE8FY4","executionInfo":{"status":"ok","timestamp":1721379204795,"user_tz":-540,"elapsed":334,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"530aec02-d7e4-45dd-a648-2569484a6470"},"source":["import torch\n","\n","t = torch.tensor([1,2,3])\n","t"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1, 2, 3])"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1mzqAJDGm9Hd","executionInfo":{"status":"ok","timestamp":1721379212597,"user_tz":-540,"elapsed":363,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"d3f9e58f-34d4-4f64-c856-357c73059355"},"source":["torch.zeros(2, 3)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0., 0., 0.],\n","        [0., 0., 0.]])"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BA2pv3pFiu3M","executionInfo":{"status":"ok","timestamp":1721379220977,"user_tz":-540,"elapsed":479,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"cfc12c15-fe5e-4509-ece3-323c958fc284"},"source":["torch.zeros_like(t)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0, 0, 0])"]},"metadata":{},"execution_count":58}]},{"cell_type":"markdown","metadata":{"id":"h4iVxzyHnqR-"},"source":["- [torch.chunk()](https://pytorch.org/docs/stable/generated/torch.chunk.html#torch.chunk)\n","- [torch.swapdims()](https://pytorch.org/docs/stable/generated/torch.swapdims.html#torch.swapdims)\n","- [torch.Tensor.scatter_()](https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_.html#torch.Tensor.scatter_)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nq9zOgoznqR_","executionInfo":{"status":"ok","timestamp":1721380162510,"user_tz":-540,"elapsed":376,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"3c3bf880-b818-4e01-9f09-4a53c7d6f98d"},"source":["import torch\n","import numpy as np\n","\n","t = torch.tensor([[1, 2, 3],\n","                  [4, 5, 6]])\n","\n","print(torch.chunk(t, 2, 0))\n","print(torch.chunk(t, 2, 1))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(tensor([[1, 2, 3]]), tensor([[4, 5, 6]]))\n","(tensor([[1, 2],\n","        [4, 5]]), tensor([[3],\n","        [6]]))\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t7Qy8zEPnqSA","executionInfo":{"status":"ok","timestamp":1721380170928,"user_tz":-540,"elapsed":369,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"d1701501-97bc-44ec-8ad5-21fcd4c13733"},"source":["x = torch.tensor([[[0,1],[2,3]],[[4,5],[6,7]]])\n","x"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[0, 1],\n","         [2, 3]],\n","\n","        [[4, 5],\n","         [6, 7]]])"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8o6mHeHeutTh","executionInfo":{"status":"ok","timestamp":1721380174939,"user_tz":-540,"elapsed":355,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"d86a106f-7568-4c03-d550-547e7d37ff9f"},"source":["torch.swapdims(x, 0, 1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[0, 1],\n","         [4, 5]],\n","\n","        [[2, 3],\n","         [6, 7]]])"]},"metadata":{},"execution_count":61}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8TBo37wDu4xW","executionInfo":{"status":"ok","timestamp":1721380189509,"user_tz":-540,"elapsed":385,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"ec349026-7c43-4447-c985-6c862b07bf78"},"source":["torch.swapdims(x, 0, 2)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[0, 4],\n","         [2, 6]],\n","\n","        [[1, 5],\n","         [3, 7]]])"]},"metadata":{},"execution_count":62}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M08dZW2fnqSB","executionInfo":{"status":"ok","timestamp":1721380207863,"user_tz":-540,"elapsed":432,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"47b3c7fd-c7a1-4065-bad0-fa505b57e77b"},"source":["src = torch.arange(1, 11).reshape((2, 5))\n","src"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1,  2,  3,  4,  5],\n","        [ 6,  7,  8,  9, 10]])"]},"metadata":{},"execution_count":63}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z6WstSp-wLU4","executionInfo":{"status":"ok","timestamp":1721380209235,"user_tz":-540,"elapsed":4,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"c94560e9-3b25-43c4-db8a-78edae338d04"},"source":["index = torch.tensor([[0, 1, 2, 0]])\n","torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 0, 0, 4, 0],\n","        [0, 2, 0, 0, 0],\n","        [0, 0, 3, 0, 0]])"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R0yIEAw-xAdV","executionInfo":{"status":"ok","timestamp":1721380213685,"user_tz":-540,"elapsed":428,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"5a8aed2e-bcca-46e1-9941-35072f32ab66"},"source":["index = torch.tensor([[0, 1, 2], [0, 1, 4]])\n","torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 2, 3, 0, 0],\n","        [6, 7, 0, 0, 8],\n","        [0, 0, 0, 0, 0]])"]},"metadata":{},"execution_count":65}]},{"cell_type":"markdown","source":["## **1.06. Changing shapes**"],"metadata":{"id":"IcO-b4amBk_l"}},{"cell_type":"code","source":["x = torch.randn(4, 4)\n","print(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z690WmwrPJ5n","executionInfo":{"status":"ok","timestamp":1721131000549,"user_tz":-540,"elapsed":571,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"01cbf6a5-6232-4e2f-d7d6-ddfa45c7a133"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.5201,  1.6423, -0.1596, -0.4974],\n","        [ 0.4396, -0.7581,  1.0783,  0.8008],\n","        [-0.9228,  1.2791,  1.2964,  0.6105],\n","        [ 1.3347, -0.2316,  0.0418, -0.2516]])\n"]}]},{"cell_type":"markdown","source":["- Reshape with `torch.view()`"],"metadata":{"id":"NcV3NOScPPQq"}},{"cell_type":"code","source":["y = x.view(16)\n","print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8UygduFoPWgV","executionInfo":{"status":"ok","timestamp":1721131000549,"user_tz":-540,"elapsed":17,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"20187c3c-faad-4305-da59-9c37dac04eae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 0.5201,  1.6423, -0.1596, -0.4974,  0.4396, -0.7581,  1.0783,  0.8008,\n","        -0.9228,  1.2791,  1.2964,  0.6105,  1.3347, -0.2316,  0.0418, -0.2516])\n"]}]},{"cell_type":"markdown","source":["- The above is **1D** tensor.\n","- 16=4*4, no of items should be equal."],"metadata":{"id":"mWPxOXOHPaj9"}},{"cell_type":"markdown","source":["- Say `a` by `8` tensor, (-1, 8) makes the rows to be determined by default."],"metadata":{"id":"5tmLhbCsPsP5"}},{"cell_type":"code","source":["z = x.view(-1, 8)\n","print(z)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BM5KgOvyPmBk","executionInfo":{"status":"ok","timestamp":1721131000550,"user_tz":-540,"elapsed":15,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"b057c1e2-9f6f-43f8-e6ba-423e1ab0fbb4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.5201,  1.6423, -0.1596, -0.4974,  0.4396, -0.7581,  1.0783,  0.8008],\n","        [-0.9228,  1.2791,  1.2964,  0.6105,  1.3347, -0.2316,  0.0418, -0.2516]])\n"]}]},{"cell_type":"code","source":["print(x.size(), y.size(), z.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uycBfkyEVc81","executionInfo":{"status":"ok","timestamp":1721131000550,"user_tz":-540,"elapsed":12,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"8a0f784b-f101-46f3-ffe4-b2beaefd8094"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"]}]},{"cell_type":"markdown","source":["## **1.07. Squeezing and Unsqueezing**\n","\n","- \"**Squeezing**\" and \"**unsqueezing**\" are operations that modify the dimensions of a tensor.\n","- **Squeezing** a tensor removes, by default, all dimensions of size 1 from the tensor's shape.\n"],"metadata":{"id":"UzNEbKNpFxjt"}},{"cell_type":"code","source":["x = torch.tensor([[[1, 2], [3, 4], [5, 6]]])\n","x, x.ndim, x.shape"],"metadata":{"id":"p9i9kG3NF5H0","executionInfo":{"status":"ok","timestamp":1721131013337,"user_tz":-540,"elapsed":3,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6de7e9aa-af8b-4eab-8b8f-b5a658ff729a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[[1, 2],\n","          [3, 4],\n","          [5, 6]]]),\n"," 3,\n"," torch.Size([1, 3, 2]))"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["squeezed_x = x.squeeze()\n","squeezed_x, squeezed_x.ndim, squeezed_x.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wuw_CFEbZy8r","executionInfo":{"status":"ok","timestamp":1721131034367,"user_tz":-540,"elapsed":321,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"ad7841d8-8161-4d5e-c2ca-c6f649b815ba"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[1, 2],\n","         [3, 4],\n","         [5, 6]]),\n"," 2,\n"," torch.Size([3, 2]))"]},"metadata":{},"execution_count":41}]},{"cell_type":"markdown","source":["- The dimension of size 1 is removed."],"metadata":{"id":"0mEJzHRKZ4AS"}},{"cell_type":"code","source":["x = torch.randn(1, 3, 1, 5)\n","squeezed_x = torch.squeeze(x)\n","x.shape, squeezed_x.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fwx9cB6YaB3z","executionInfo":{"status":"ok","timestamp":1721131134097,"user_tz":-540,"elapsed":357,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"903cd34e-5a2c-4c1c-8c42-59af2f4b2986"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([1, 3, 1, 5]), torch.Size([3, 5]))"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","source":["- Both dimensions of size 1 are removed.\n","- To remove a specific dimension of size 1, that dimension can be passed as an argument to `torch.squeeze()`."],"metadata":{"id":"pGo86_uVaPp6"}},{"cell_type":"code","source":["x = torch.randn(1, 3, 1, 5)\n","squeezed_x = torch.squeeze(x, dim=0)\n","x.shape, squeezed_x.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pvkj7SjsaffH","executionInfo":{"status":"ok","timestamp":1721131216737,"user_tz":-540,"elapsed":328,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"6b4a992f-b8f0-489e-cfc3-c70f2aefb461"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([1, 3, 1, 5]), torch.Size([3, 1, 5]))"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["x = torch.randn(1, 3, 1, 5)\n","squeezed_x = torch.squeeze(x, dim=2)\n","x.shape, squeezed_x.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oDH9gmmsakDJ","executionInfo":{"status":"ok","timestamp":1721131235658,"user_tz":-540,"elapsed":360,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"509cf6da-a030-4e5a-f1eb-81e4fa5f7189"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([1, 3, 1, 5]), torch.Size([1, 3, 5]))"]},"metadata":{},"execution_count":45}]},{"cell_type":"markdown","source":["- **Unsqueezing** a tensor adds a dimension of size 1 at a **specified position**."],"metadata":{"id":"jJTe-nnVavVa"}},{"cell_type":"code","source":["x = torch.tensor([[[1, 2], [3, 4], [5, 6]]])\n","unsqueezed_x = x.unsqueeze(dim=0)\n","x, x.ndim, x.shape, unsqueezed_x, unsqueezed_x.ndim, unsqueezed_x.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NhsjikzEaxYI","executionInfo":{"status":"ok","timestamp":1721131358434,"user_tz":-540,"elapsed":354,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"ced6b2e7-8937-423d-9067-5f4475334b02"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[[1, 2],\n","          [3, 4],\n","          [5, 6]]]),\n"," 3,\n"," torch.Size([1, 3, 2]),\n"," tensor([[[[1, 2],\n","           [3, 4],\n","           [5, 6]]]]),\n"," 4,\n"," torch.Size([1, 1, 3, 2]))"]},"metadata":{},"execution_count":47}]},{"cell_type":"markdown","source":["- In this example, a new dimension of size 1 is added at position 0.\n","- We can add a dimension at any position by changing the `dim` argument:"],"metadata":{"id":"Wwy6DVjEbmvI"}},{"cell_type":"code","source":["x = torch.randn(3, 5)\n","unsqueezed_x = torch.unsqueeze(x, dim=0)\n","x, x.ndim, x.shape, unsqueezed_x, unsqueezed_x.ndim, unsqueezed_x.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w5wFa3mkbXrm","executionInfo":{"status":"ok","timestamp":1721131469036,"user_tz":-540,"elapsed":349,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"4625f961-2d2f-4d5e-c747-030ae4e80584"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[-0.0203,  0.1082,  0.9384,  0.4005,  1.0729],\n","         [-1.7529, -0.9982,  0.1582, -1.6172,  0.6904],\n","         [ 0.9998, -2.5733, -0.7208, -0.7698,  0.0366]]),\n"," 2,\n"," torch.Size([3, 5]),\n"," tensor([[[-0.0203,  0.1082,  0.9384,  0.4005,  1.0729],\n","          [-1.7529, -0.9982,  0.1582, -1.6172,  0.6904],\n","          [ 0.9998, -2.5733, -0.7208, -0.7698,  0.0366]]]),\n"," 3,\n"," torch.Size([1, 3, 5]))"]},"metadata":{},"execution_count":48}]},{"cell_type":"markdown","source":["## **1.08. Numpy Array to Torch Tensor: [`torch.from_numpy()`](https://pytorch.org/docs/stable/generated/torch.from_numpy.html#torch.from_numpy)**"],"metadata":{"id":"GAEodPucBy7U"}},{"cell_type":"code","source":["a = np.ones(5)\n","a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OeN1fks1RQ92","executionInfo":{"status":"ok","timestamp":1721114520075,"user_tz":-540,"elapsed":26,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"3aaa260c-f69b-4622-87e8-98db195f6629"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1., 1., 1., 1., 1.])"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["b = torch.from_numpy(a)\n","b"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C9VkxOcbVdGW","executionInfo":{"status":"ok","timestamp":1721114520075,"user_tz":-540,"elapsed":23,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"91ae6418-9099-4647-fecd-f370a4b4d791"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1., 1., 1., 1., 1.], dtype=torch.float64)"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","source":["- **Note**:\n","    - By default **all tensors are created on the CPU**, (but can be moved them to the GPU if available)\n","    - If the tensor is on the CPU (not the GPU), both objects will share the same memory location.\n","    - So changing one will also change the other"],"metadata":{"id":"T1jIfQY5M02X"}},{"cell_type":"code","source":["a += 1\n","a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XH1BlAD7Nlk2","executionInfo":{"status":"ok","timestamp":1721114520075,"user_tz":-540,"elapsed":21,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"e819d1f4-4084-4afb-cb56-57642be1c4c1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2., 2., 2., 2., 2.])"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["b"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UbeP3FmlRahr","executionInfo":{"status":"ok","timestamp":1721114520075,"user_tz":-540,"elapsed":18,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"5ec28221-b485-4406-c37c-bcb6fdaa8d50"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([2., 2., 2., 2., 2.], dtype=torch.float64)"]},"metadata":{},"execution_count":45}]},{"cell_type":"markdown","source":["## **1.09. Torch Tensor to Numpy Array: [`tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html#torch-tensor-numpy)**"],"metadata":{"id":"3OgQfMrDHHRa"}},{"cell_type":"code","source":["a = torch.ones(5)\n","a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8XOt7hSbQNYU","executionInfo":{"status":"ok","timestamp":1721546098512,"user_tz":-540,"elapsed":29,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"ac1ae680-ccd3-4000-99db-1d272384d9f6"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1., 1., 1., 1., 1.])"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["b = a.numpy()\n","b"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G0Svfy9PVdAG","executionInfo":{"status":"ok","timestamp":1721546098957,"user_tz":-540,"elapsed":4,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"e353ef6b-a945-439e-816c-90ef8da94ac9"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1., 1., 1., 1., 1.], dtype=float32)"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["print(type(a), type(b))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qvQG4et-QXaj","executionInfo":{"status":"ok","timestamp":1721546102762,"user_tz":-540,"elapsed":364,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"6aebedd7-8163-4aff-822c-751a61e84b32"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'torch.Tensor'> <class 'numpy.ndarray'>\n"]}]},{"cell_type":"markdown","source":["- [`torch.is_tensor()`](https://pytorch.org/docs/stable/generated/torch.is_tensor.html#torch.is_tensor)"],"metadata":{"id":"_n6n6YbmJivg"}},{"cell_type":"code","source":["torch.is_tensor(a), torch.is_tensor(b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_DYlU7kGJJn4","executionInfo":{"status":"ok","timestamp":1721546209367,"user_tz":-540,"elapsed":390,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"49fa58fc-4e0c-444e-fd87-85be72b0dd2d"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(True, False)"]},"metadata":{},"execution_count":36}]},{"cell_type":"markdown","source":["## **1.10. Moving Tensors to GPU if available**"],"metadata":{"id":"m1_rxbONR2mK"}},{"cell_type":"code","source":["torch.cuda.is_available()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3XnI1KSiJ17e","executionInfo":{"status":"ok","timestamp":1721546272124,"user_tz":-540,"elapsed":381,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"175b719c-9c49-4d6f-d6be-74162b332829"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"SOehnbyKJvZ-","executionInfo":{"status":"ok","timestamp":1721546286975,"user_tz":-540,"elapsed":345,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"1896c542-eb39-4688-a3ff-05f55fdff097"},"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cpu'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["x = torch.ones(5).to(device)\n","x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pvFEa2h0R8Ha","executionInfo":{"status":"ok","timestamp":1721546294239,"user_tz":-540,"elapsed":368,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"e57f7596-d493-4a50-edca-35c03c994b06"},"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1., 1., 1., 1., 1.])"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["y = torch.ones(5)\n","y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jPs0-WRFSHBt","executionInfo":{"status":"ok","timestamp":1721546297930,"user_tz":-540,"elapsed":620,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"29031d9a-89fe-48b8-ab9c-3b3fc42ef8d8"},"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1., 1., 1., 1., 1.])"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["y = y.to(device)\n","y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hbYwxadjSKAN","executionInfo":{"status":"ok","timestamp":1721546299803,"user_tz":-540,"elapsed":4,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"907bcac7-616c-4343-f3eb-545a4a30fba3"},"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1., 1., 1., 1., 1.])"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["z = x + y\n","z"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iOm3TuGaNtpE","executionInfo":{"status":"ok","timestamp":1721546301228,"user_tz":-540,"elapsed":4,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"a9dd66a9-1e1b-4bc6-d652-95f18a48c531"},"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([2., 2., 2., 2., 2.])"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","source":["- **Notes**:\n","    - `z = z.numpy()` provides error if numpy array `z` is on the GPU.\n","    - **Numpy** only handles **CPU tensors**, not GPU's."],"metadata":{"id":"xE7byQlGDBE0"}},{"cell_type":"code","source":["# z = torch.ones(5).to(device)\n","# z = z.numpy()"],"metadata":{"id":"BKV6JVqpEHsF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["z = z.to(\"cpu\")\n","z"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1sQ8X4tIC-n8","executionInfo":{"status":"ok","timestamp":1721114520723,"user_tz":-540,"elapsed":654,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"bcd359fb-e95f-464a-ef2f-7f91b0590e02"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([2., 2., 2., 2., 2.])"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["z = z.numpy()\n","z"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QaxgIy_pSsBt","executionInfo":{"status":"ok","timestamp":1721114520723,"user_tz":-540,"elapsed":53,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"a19bb21f-a69f-4605-c0b2-ce42a028d390"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2., 2., 2., 2., 2.], dtype=float32)"]},"metadata":{},"execution_count":52}]},{"cell_type":"markdown","metadata":{"id":"jPvOek5YxfRg"},"source":["## **1.11. Random Sampling**"]},{"cell_type":"markdown","metadata":{"id":"LAcT0HckxfR7"},"source":["-  [torch.bernoulli](https://pytorch.org/docs/stable/generated/torch.bernoulli.html#torch.bernoulli): It returns a tensor of either 0 or 1 for a given probability value. Specifically, if the probability is 0, it will return 0. On the other hand if the probability is 1, it will return 1."]},{"cell_type":"code","source":["import torch\n","# Assuming all probabilities are 1\n","a = torch.ones(3, 3) # 3x3 tensor of 1\n","print(a)\n","success = torch.bernoulli(a)\n","print(success) # 3x3 tensor of 1\n","\n","# Assuming all probabilities are 1\n","a = torch.zeros(3, 3)  # 3x3 tensor of 0\n","print(a)\n","success = torch.bernoulli(a)\n","print(success) # 3x3 tensor of 0\n","\n","# Now generate a 3x3 tensor of random probabilities\n","a = torch.empty(3, 3).uniform_(0, 1)\n","print(a) # 3x3 tensor of random numbers between 0 and 1\n","success = torch.bernoulli(a)\n","print(success) # returns 3x3 tensor of either 0 or 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X5umU1PhMaIW","executionInfo":{"status":"ok","timestamp":1654941066657,"user_tz":-540,"elapsed":197,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"0224bfad-b027-4cc7-e3fd-cab756397182"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 1., 1.],\n","        [1., 1., 1.],\n","        [1., 1., 1.]])\n","tensor([[1., 1., 1.],\n","        [1., 1., 1.],\n","        [1., 1., 1.]])\n","tensor([[0., 0., 0.],\n","        [0., 0., 0.],\n","        [0., 0., 0.]])\n","tensor([[0., 0., 0.],\n","        [0., 0., 0.],\n","        [0., 0., 0.]])\n","tensor([[0.3696, 0.9752, 0.3903],\n","        [0.8095, 0.7564, 0.1095],\n","        [0.5581, 0.3121, 0.1206]])\n","tensor([[0., 0., 0.],\n","        [1., 1., 0.],\n","        [1., 0., 0.]])\n"]}]},{"cell_type":"markdown","source":["- [torch.normal](https://pytorch.org/docs/stable/generated/torch.normal.html#torch.normal): It returns a tensor of random numbers drawn from a distribution whose mean and standard deviation are given."],"metadata":{"id":"bvKDFzp7fpEP"}},{"cell_type":"code","source":["a = torch.normal(mean=torch.arange(1., 11.), std=torch.arange(1, 0, -0.1))\n","print(a)\n","b = torch.normal(mean=0.5, std=torch.arange(1., 6.))\n","print(b)\n","c = torch.normal(2, 3, size=(1, 4))\n","print(c)"],"metadata":{"id":"45Y7uu7nRR9N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654941066658,"user_tz":-540,"elapsed":190,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"510ec7ea-43df-49f0-ac97-c53499d3cf12"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 1.1483,  2.5431,  4.0992,  3.8410,  4.5530,  6.4675,  6.9869,  8.3658,\n","         8.8022, 10.0226])\n","tensor([ 2.0470,  3.6903,  2.1376, -2.0723, -7.6739])\n","tensor([[5.6841, 6.6300, 5.3605, 1.6692]])\n"]}]},{"cell_type":"markdown","source":["- [torch.poisson](https://pytorch.org/docs/stable/generated/torch.poisson.html#torch.poisson): It gives a tensor of discrete (whole numbers) values from a Poisson distribution for a given mean rate parameter."],"metadata":{"id":"y5PTEnLufrm-"}},{"cell_type":"code","source":["rates = torch.rand(4, 4) * 5  # rate parameter between 0 and 5\n","torch.poisson(rates)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BA71zIq3g5o8","executionInfo":{"status":"ok","timestamp":1654941066658,"user_tz":-540,"elapsed":181,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"f1d058ff-f9d8-4d6d-e04f-325ef5e0332c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[2., 4., 0., 1.],\n","        [3., 2., 1., 4.],\n","        [2., 2., 1., 2.],\n","        [1., 0., 1., 0.]])"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["size = 4\n","x = torch.rand(size)\n","x, x.ndim, x.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G4mAJ7R0-895","executionInfo":{"status":"ok","timestamp":1721130999583,"user_tz":-540,"elapsed":123,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"66ae96c8-ec51-4847-cb1e-f69a6ca6ba93"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([0.8823, 0.9150, 0.3829, 0.9593]), 1, torch.float32)"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["x = torch.rand(5,3)\n","x, x.ndim, x.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ooLNJ7N0KQYK","executionInfo":{"status":"ok","timestamp":1721130999583,"user_tz":-540,"elapsed":113,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"f68d3bdb-b87d-402b-a192-ded5fe9a7b2e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[0.3904, 0.6009, 0.2566],\n","         [0.7936, 0.9408, 0.1332],\n","         [0.9346, 0.5936, 0.8694],\n","         [0.5677, 0.7411, 0.4294],\n","         [0.8854, 0.5739, 0.2666]]),\n"," 2,\n"," torch.float32)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["x = torch.rand(5, 3)\n","x, x.ndim, x.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QRoKjYYZP0mS","executionInfo":{"status":"ok","timestamp":1721130999583,"user_tz":-540,"elapsed":109,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"be4e1413-9051-44c4-827b-0cb376118735"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[0.6274, 0.2696, 0.4414],\n","         [0.2969, 0.8317, 0.1053],\n","         [0.2695, 0.3588, 0.1994],\n","         [0.5472, 0.0062, 0.9516],\n","         [0.0753, 0.8860, 0.5832]]),\n"," 2,\n"," torch.float32)"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["- Random normal (0, 1) => `torch.randn`"],"metadata":{"id":"vJrgkm09AjvL"}},{"cell_type":"code","source":["x = torch.randn(5,3)\n","x, x.ndim, x.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DYD47AykAmSc","executionInfo":{"status":"ok","timestamp":1721130999583,"user_tz":-540,"elapsed":101,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"a408b312-1a07-4a35-ca6b-b88ae3cb9571"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[-0.4220, -1.3323, -0.3639],\n","         [ 0.1513, -0.3514, -0.7906],\n","         [-0.0915,  0.2352,  2.2440],\n","         [ 0.5817,  0.4528,  0.6410],\n","         [ 0.5200,  0.5567,  0.0744]]),\n"," 2,\n"," torch.float32)"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["# **3. Building Blocks of NN**"],"metadata":{"id":"oEe8gP0Ex7u3"}},{"cell_type":"markdown","source":["- PyTorch has **several essential modules**, of which one is:\n","    - [`torch.nn`](https://pytorch.org/docs/stable/nn.html): Contains all of the **building blocks for computational graphs**.\n","        - [layers]()\n","        - [activation functions](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)\n","        - [loss functions](https://pytorch.org/docs/stable/nn.html#loss-functions)\n","    - All `nn` modules function as a model (or can do a forward pass).\n","      - The functions from `torch.nn` are classes.\n","      - Hence, there is a need to create an instance before using."],"metadata":{"id":"BRbm9blRiOPQ"}},{"cell_type":"markdown","source":["## **3.1. Layers**"],"metadata":{"id":"X6-PIeE1s9Wy"}},{"cell_type":"markdown","metadata":{"id":"eU_nhb1vKTi-"},"source":["### **3.1.1. Identity Layer**: [`nn.Identity()`](https://pytorch.org/docs/stable/generated/torch.nn.Identity.html#torch.nn.Identity)\n"]},{"cell_type":"code","metadata":{"id":"Om5zRqyvKTjA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721537736126,"user_tz":-540,"elapsed":391,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"6c7609d7-a6cd-42cb-dce7-146e710d9da4"},"source":["import torch\n","from torch import nn\n","\n","X = torch.Tensor([[1, 2],\n","                  [3, 4]])\n","\n","identity = nn.Identity()\n","print(identity(X))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 2.],\n","        [3., 4.]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"CzVfoZdX1Tqk"},"source":["### **3.1.2. Flatten Layer**: [`nn.Flatteny()`](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html#flatten)\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721541314629,"user_tz":-540,"elapsed":502,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"a4218a20-5a68-42dc-94de-12b0d2681e0d","id":"HzEe0Uxz1Tq-"},"source":["X = torch.Tensor([[[1, 2],\n","                  [3, 4]]])\n","print(X)\n","print(X.shape)\n","\n","flatten = nn.Flatten()\n","flatten_X = flatten(X)\n","print(flatten_X)\n","print(flatten_X.size())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[1., 2.],\n","         [3., 4.]]])\n","torch.Size([1, 2, 2])\n","tensor([[1., 2., 3., 4.]])\n","torch.Size([1, 4])\n"]}]},{"cell_type":"code","source":["flatten"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pZhEnT9j1ukL","executionInfo":{"status":"ok","timestamp":1721541001125,"user_tz":-540,"elapsed":357,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"a586800b-1ccb-477e-a14a-ca9174fae643"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Flatten(start_dim=1, end_dim=-1)"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"R68OFoe8BzbF"},"source":["### **3.1.3. Linear Layer: [`nn.linear()`](https://pytorch.org/docs/stable/nn.html#linear-layers)**\n","\n","- A linear regression $ y=w_0+w_1x_1+\\cdots+w_kx_k $ is a single linear layer NN.\n","- An instance of a linear regression model can be created using the built-in PyTorch (**linear layer**) function:  \n","      `torch.nn.Linear(in_features, out_features, bias = True)`\n","    - `in_features` is for the number of input features,\n","    - `out_features` is for the number of features,\n","    - `bias = True` is for including the bias in the model by default.\n","- Implementation of the linear layer of `nn.Linear()` internally calls the following equation:\n","\n","$$\\mathbf{y} = \\mathbf{x}\\mathbf{W}^T  + \\mathbf{b}.$$\n","\n","- A linear neural network applies a **linear transformation** to the input data.\n","- The learnable weights and bias are iniitalized from a uniform distribution $U(-\\sqrt{k}, \\sqrt{k})$ where $k$ is the inverse of the number of input features."]},{"cell_type":"code","metadata":{"id":"tjHTIZdrGzXd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721537409882,"user_tz":-540,"elapsed":349,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"a727871e-b022-47b1-9151-e040cf826d8e"},"source":["import torch\n","from torch import nn\n","\n","X = torch.Tensor([[1, 2],\n","                  [3, 4]])\n","\n","linear = nn.Linear(2, 1)\n","print(linear)\n","y = linear(X)\n","print(y)\n","print(y.size())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Linear(in_features=2, out_features=1, bias=True)\n","tensor([[-0.8228],\n","        [-0.3424]], grad_fn=<AddmmBackward0>)\n","torch.Size([2, 1])\n"]}]},{"cell_type":"code","source":["X = torch.Tensor([[1, 2],\n","                  [3, 4]])\n","\n","linear = nn.Linear(2, 5)\n","print(linear)\n","Y = linear(X)\n","print(Y)\n","print(Y.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BwpU1PAen98D","executionInfo":{"status":"ok","timestamp":1721537415862,"user_tz":-540,"elapsed":379,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"70b1c9cb-35f4-407d-d178-4495b04c41bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Linear(in_features=2, out_features=5, bias=True)\n","tensor([[-0.2860, -0.1708, -1.5111,  1.2856, -0.0767],\n","        [-0.5479, -0.2990, -2.7886,  3.1073, -0.3075]],\n","       grad_fn=<AddmmBackward0>)\n","torch.Size([2, 5])\n"]}]},{"cell_type":"markdown","metadata":{"id":"ZRWBmAYkOYgy"},"source":["### **3.1.4. Lazy Linear Layer: [`nn.LazyLinear()`](https://pytorch.org/docs/stable/generated/torch.nn.LazyLinear.html#torch.nn.LazyLinear)**\n","\n","- Unlike linear layers, the parameters are not initialized in a lazy linear neural network.\n","- Rather, the parameters will be iniitalized after the first forward pass.\n","- Once the first forward pass is completed, the lazy linear neural network becomes the usuall linear neural network."]},{"cell_type":"code","source":["X = torch.Tensor([[1, 2],\n","                  [3, 4]])\n","\n","lazy_linear = nn.LazyLinear(2, 5)\n","print(lazy_linear)\n","Y = lazy_linear(X)\n","print(Y)\n","print(Y.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d0vIjxRnovmJ","executionInfo":{"status":"ok","timestamp":1721537674015,"user_tz":-540,"elapsed":371,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"83310f3c-2fb8-4032-f921-c1d97f1c2325"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["LazyLinear(in_features=0, out_features=2, bias=True)\n","tensor([[-0.4300, -1.4548],\n","        [-0.6128, -2.4430]], grad_fn=<AddmmBackward0>)\n","torch.Size([2, 2])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n","  warnings.warn('Lazy modules are a new feature under heavy development '\n"]}]},{"cell_type":"markdown","source":["- **Activation functions** apply a non-linear transformation:\n","\n","$$y_{pred} = f(x)$$\n","\n","  - $f$ is an activation funciton.\n"],"metadata":{"id":"LBMjkfXZ2o5l"}},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F"],"metadata":{"id":"JB3utLI2ltFf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = torch.tensor([-1.0, 1.0, 2.0, 3.0])"],"metadata":{"id":"5UAsa_5cjT39"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **3.2. (Non-Linear) Activation Functions**"],"metadata":{"id":"Mw78T6LH8TN3"}},{"cell_type":"markdown","source":["### **3.2.1. Sigmoid: `torch.sigmoid()`, `nn.Sigmoid()`**\n","\n","- Sigmoid (logistic) function\n","    - Squashes input between 0 and 1.\n","    - Suitable for binary classification problems.\n","\n","$$f(x)=\\frac{1}{1+e^{-x}}$$\n","\n","\n","<img src=\"https://github.com/awolseid/tutorial_figures/blob/main/sigmoid.png?raw=true\" alt=\"Sigmoid\" width=\"400\">"],"metadata":{"id":"XtyA2AQQkM0U"}},{"cell_type":"code","source":["y_pred1 = torch.sigmoid(x)\n","y_pred1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yzFZkaupJJhB","executionInfo":{"status":"ok","timestamp":1721114520724,"user_tz":-540,"elapsed":51,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"53ad44d9-94a6-44c6-eb84-49f740411ce8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.2689, 0.7311, 0.8808, 0.9526])"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["sigmoid_fun = nn.Sigmoid()\n","y_pred2 = sigmoid_fun(x)\n","y_pred2"],"metadata":{"id":"qvGRGgp4ja8E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721114520724,"user_tz":-540,"elapsed":49,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"2a04ca74-8b51-46ae-f9a7-adfc1187d06f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.2689, 0.7311, 0.8808, 0.9526])"]},"metadata":{},"execution_count":56}]},{"cell_type":"markdown","source":["### **3.2.2. TanH (Hyperbollic Tangent): `torch.tanh()`, `nn.Tanh()`**\n","\n","- TanH function is a **scaled sigmoid function** and a little bit shifted.\n","  - Squashes input between -1 and 1\n","  - Suitable for classification tasks.\n","\n","$$f(x)=\\frac{2}{1+e^{-2x}}-1$$.\n","\n","<img src=\"https://github.com/awolseid/tutorial_figures/blob/main/tanh.png?raw=true\" alt=\"Tanh\" width=\"400\">\n","\n","- When $x=0$, the gradient in the backpropagation is also zero.\n","    - This means the weights will never be updated.\n","    - So these neurons will not learn anything (the neurons are dead)."],"metadata":{"id":"CPmbumdYkVOa"}},{"cell_type":"code","source":["y_pred1 = torch.tanh(x)\n","y_pred1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HoSAN0t5KiJ0","executionInfo":{"status":"ok","timestamp":1721114520724,"user_tz":-540,"elapsed":47,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"3fb083f3-0643-48d5-aeab-c24d0ad87fff"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-0.7616,  0.7616,  0.9640,  0.9951])"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["tanh_fun = nn.Tanh()\n","y_pred2 = tanh_fun(x)\n","y_pred2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A3IG1eK5Kvh6","executionInfo":{"status":"ok","timestamp":1721114520724,"user_tz":-540,"elapsed":45,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"6e67f4f6-048e-4571-dbda-5eb6ea778544"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-0.7616,  0.7616,  0.9640,  0.9951])"]},"metadata":{},"execution_count":58}]},{"cell_type":"markdown","source":["### **3.2.3. ReLU (Rectified Linear Unit): `F.relu()`, `nn.ReLU()`**\n","\n","* ReLU function:\n","    - It returns the input if it is positive, and 0 otherwise.\n","    - Popular due to its ability to address the **vanishing gradient** problem.\n","\n","\n","$$f(x)=max(0,x)$$\n","\n","\n","- **Two options**: creating an nn module or using the activation function directly in forward pass.\n","    * `nn.ReLU()` creates an `nn.Module` which we can add.\n","    * `torch.relu` is just a functional API call to the relu function.\n","\n","\n","<img src=\"https://github.com/awolseid/tutorial_figures/blob/main/relu.png?raw=true\" alt=\"ReLU and Other\" width=\"500\">"],"metadata":{"id":"YyKrZcLODDTi"}},{"cell_type":"code","source":["y_pred1 = F.relu(x)\n","y_pred1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BIvUwVoEMEok","executionInfo":{"status":"ok","timestamp":1721114520724,"user_tz":-540,"elapsed":43,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"e8338a15-046b-4f07-d939-6e829aeae9a2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0., 1., 2., 3.])"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["relu = nn.ReLU()\n","y_pred2 = relu(x)\n","y_pred2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ET2eQ8v4Mpeb","executionInfo":{"status":"ok","timestamp":1721114520724,"user_tz":-540,"elapsed":40,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"c1c3b0a5-6e6c-44e1-e70f-1983c3dafb76"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0., 1., 2., 3.])"]},"metadata":{},"execution_count":60}]},{"cell_type":"markdown","source":["### **3.2.4. Leakly ReLU: `F.leaky_relu()`, `nn.LeakyReLU()`**\n","\n","- If $x\\ge 0$, $f(x)=x$ else $f(x)=ax$\n","where $a$ is a very small value, say 0.001.\n","\n","- It is a slighly modified and improved version of ReLU.\n","- It tries to solve the vanishing gradient problem."],"metadata":{"id":"e0Az3i2Mkwex"}},{"cell_type":"code","source":["y_pred1 = F.leaky_relu(x)\n","y_pred1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FjTjwUAWN9G3","executionInfo":{"status":"ok","timestamp":1721114520724,"user_tz":-540,"elapsed":38,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"a5031b48-2ad1-4b8a-e1f9-879b6c672c45"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-0.0100,  1.0000,  2.0000,  3.0000])"]},"metadata":{},"execution_count":61}]},{"cell_type":"code","source":["lrelu = nn.LeakyReLU()\n","y_pred2 = lrelu(x)\n","y_pred2"],"metadata":{"id":"_4zyrtrAjgTY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721114520724,"user_tz":-540,"elapsed":36,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"555ab684-3e03-4e4f-fc43-f6a5c99f7136"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-0.0100,  1.0000,  2.0000,  3.0000])"]},"metadata":{},"execution_count":62}]},{"cell_type":"markdown","source":["### **3.2.5. Softmax: `torch.softmax()`, `nn.Softmax()`**\n","\n","- **Softmax** normalizes each element in a set of elements using an exponential function.\n","- It squashes the inputs into a **probability distribution over multiple classes**.\n","\n","$$f(x_i)=\\frac{e^{x_i}}{\\sum e^{x_i}}; i=1,2,..,k.$$\n","\n","- It is applicable for multi-class classification problems.\n","\n","<img src=\"https://github.com/awolseid/tutorial_figures/blob/main/softmax.jpg?raw=true\" alt=\"Softmax\" width=\"400\">"],"metadata":{"id":"5NMVqxHqiUym"}},{"cell_type":"code","source":["#\n","#        -> 2.0              -> 0.65\n","# Linear -> 1.0  -> Softmax  -> 0.25   -> CrossEntropy(y, y_hat)\n","#        -> 0.1              -> 0.1\n","#\n","#     scores(logits)      probabilities\n","#                           sum = 1.0\n","#\n","def softmax(x):\n","    return np.exp(x) / np.sum(np.exp(x), axis=0)"],"metadata":{"id":"aUxxzLgEiUyn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","x = np.array([2.0, 1.0, 0.1])\n","y_pred = softmax(x)\n","y_pred, y_pred.sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721114520725,"user_tz":-540,"elapsed":34,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"2e41fda7-9402-4511-db9f-83c8e8dbab98","id":"lD7WUqZriUyn"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([0.65900114, 0.24243297, 0.09856589]), 1.0)"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["x = torch.tensor([2.0, 1.0, 0.1])\n","y_pred1 = torch.softmax(x, dim=0)\n","y_pred1, y_pred.sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lmdgV95JVTwj","executionInfo":{"status":"ok","timestamp":1721114520725,"user_tz":-540,"elapsed":32,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"0d489cf0-1f79-4127-dd6f-36f259defc1c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([0.6590, 0.2424, 0.0986]), 1.0)"]},"metadata":{},"execution_count":65}]},{"cell_type":"code","source":["softmax_fun = nn.Softmax(dim=0)\n","y_pred2 = softmax_fun(x)\n","y_pred2, sum(y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XwrzFQirSqdN","executionInfo":{"status":"ok","timestamp":1721114520725,"user_tz":-540,"elapsed":30,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"6ab2fefe-24d1-43f7-ff27-6e24db97e71c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([0.6590, 0.2424, 0.0986]), 1.0)"]},"metadata":{},"execution_count":66}]},{"cell_type":"markdown","source":["# **4. Loss Functions**\n","\n","- Loss functions are used to evaluate the performance of ML models by comparing the predicted outputs to the true labels.\n","- The **loss** function is the **difference between the predicted output and the actual target value (label)**."],"metadata":{"id":"tL5C8pouFK7A"}},{"cell_type":"markdown","source":["## **4.1. Mean Absolute Error - MAE: [`nn.L1Loss()`](https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html)**\n","\n","$$MAE=\\frac{\\sum|y_{predicted}-y_{actual}|}{n}$$"],"metadata":{"id":"K9stIFv-hsM0"}},{"cell_type":"code","source":["criterion = nn.L1Loss()\n","criterion"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UdPPcb-9lsHy","executionInfo":{"status":"ok","timestamp":1721114520725,"user_tz":-540,"elapsed":28,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"5b2c6cb2-717f-4c40-ea77-6f744f4824ce"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["L1Loss()"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":["y_predicted = torch.randn(5)\n","y_predicted"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SXlSGaXqqgMz","executionInfo":{"status":"ok","timestamp":1721114520725,"user_tz":-540,"elapsed":26,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"0a9b58dd-21ac-4742-8d1e-4492a9ff43ac"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-1.1859, -0.8860, -0.7150,  0.1280, -0.1603])"]},"metadata":{},"execution_count":68}]},{"cell_type":"code","source":["y_actual = torch.randn(5)\n","y_actual"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LayEmEe3l2mr","executionInfo":{"status":"ok","timestamp":1721114520725,"user_tz":-540,"elapsed":23,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"fa2a64e8-69c5-4931-9ad1-c4bcb8014c2f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-2.2161, -0.6858, -0.3295, -0.2747, -1.2552])"]},"metadata":{},"execution_count":69}]},{"cell_type":"code","source":["loss = criterion(y_predicted, y_actual)\n","loss"],"metadata":{"id":"G7sHnCOvhzuj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721114520725,"user_tz":-540,"elapsed":21,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"1373466b-beaf-467e-9df9-0f2a416bdd82"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.6227)"]},"metadata":{},"execution_count":70}]},{"cell_type":"markdown","source":["## **4.2. Mean Squared Error - MSE: [`nn.MSELoss()`](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html)**\n","\n","$$MSE=\\frac{\\sum(y_{predicted}-y_{actual})^2}{n}$$"],"metadata":{"id":"KsqP75_YmGzm"}},{"cell_type":"code","source":["criterion = nn.MSELoss()\n","criterion"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721114520725,"user_tz":-540,"elapsed":19,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"eb7b545f-fec6-4605-c2c7-eca2a87ec879","id":"A44r49INmiXo"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MSELoss()"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":["y_predicted = torch.randn(5)\n","y_actual = torch.randn(5)"],"metadata":{"id":"Mz42ZCPVmiXq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss = criterion(y_predicted, y_actual)\n","loss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721114520726,"user_tz":-540,"elapsed":17,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"dd5a02a4-1d32-4c35-8b95-d8d8bbb61190","id":"hX75MpGqmiXr"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(1.2538)"]},"metadata":{},"execution_count":73}]},{"cell_type":"markdown","source":["## **4.3. Binary Cross-Entropy Loss: [`nn.BCELoss()`](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#bceloss)**\n","\n","- `BCELoss` is used for binary classification problems where the target labels are binary (0 or 1).\n","- It is the **negative log likelihood of the predicted probabilities**.\n","\n","$$BCE=-\\frac{1}{n}\\sum [y_i \\log (p_i)+ (1-y_i) \\log (1-p_i)]$$\n","\n","* The loss increases as the difference between the predicted and actual probabilities increases."],"metadata":{"id":"uuhRG-9UnMpx"}},{"cell_type":"code","source":["def bce_loss(y_pred_probs, y_actual):\n","    return -torch.mean(y_actual * torch.log(y_pred_probs) +\n","                      (1 - y_actual) * torch.log(1 - y_pred_probs))"],"metadata":{"id":"TsPhQOFJT293"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_actual = torch.tensor([1.0, 0.0, 0.0, 1.0, 0.0])\n","y_pred_probs = torch.tensor([0.9, 0.2, 0.1, 0.2, 0.1])\n","\n","bce_loss(y_pred_probs, y_actual)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IZM627VnUKDu","executionInfo":{"status":"ok","timestamp":1721114520726,"user_tz":-540,"elapsed":15,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"9e03ced5-373b-4061-d637-668926ca1b1f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.4297)"]},"metadata":{},"execution_count":75}]},{"cell_type":"code","source":["criterion = nn.BCELoss()\n","loss = criterion(y_pred_probs, y_actual)\n","loss, loss.item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PeJmSDPvHD_M","executionInfo":{"status":"ok","timestamp":1721114520726,"user_tz":-540,"elapsed":12,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"1babc8ac-cdc3-439e-8cc7-b8629d0de1c9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(0.4297), 0.42973262071609497)"]},"metadata":{},"execution_count":76}]},{"cell_type":"markdown","source":["## **4.5. Binary Cross-Entropy With Logits: [`nn.BCEWithLogitsLoss()`](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html#bcewithlogitsloss)**\n","\n","- `BCEWithLogits` combines a **sigmoid function** and the **binary cross-entropy** loss in one single class.\n","- This is more numerically stable than using a plain Sigmoid followed by a BCELoss.\n","\n","$$BCEWL=max(y_{logits}, 0)-y_{logits}y_{actual}+log(1+e^{-|y_{logits}|})$$\n"],"metadata":{"id":"dLETZsUMICMh"}},{"cell_type":"code","source":["def bce_with_logits_loss(y_pred_logits, y_actual):\n","    max_logits = torch.clamp(y_pred_logits, min=0)\n","    log_sum_exp = torch.log(1 + torch.exp(-torch.abs(y_pred_logits)))\n","    loss = max_logits - (y_pred_logits * y_actual) + log_sum_exp\n","    return torch.mean(loss)"],"metadata":{"id":"VQJ0o6sUUgnu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_actual = torch.tensor([1.0, 0.0, 0.0, 1.0, 0.0])\n","y_pred_logits = torch.tensor([5.9, -3.2, 4.1, 8.2, -6.1])\n","bce_with_logits_loss(y_pred_logits, y_actual)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nB5dEoRWUtez","executionInfo":{"status":"ok","timestamp":1721114520726,"user_tz":-540,"elapsed":9,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"909bcc42-1404-40df-9876-3fc6ce7ea1bc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.8323)"]},"metadata":{},"execution_count":78}]},{"cell_type":"code","source":["criterion = nn.BCEWithLogitsLoss()\n","loss = criterion(y_pred_logits, y_actual)\n","loss, loss.item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721114521138,"user_tz":-540,"elapsed":419,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"df9df77d-a10e-4262-d171-ebd8757f14f8","id":"Ic2IfeWfICMm"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(0.8323), 0.8323281407356262)"]},"metadata":{},"execution_count":79}]},{"cell_type":"markdown","source":["## **4.6. Cross-Entropy Loss: [`nn.CrossEntropyLoss()`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#crossentropyloss)**\n","\n","- **CrossEntropyLoss** (called **LogSoftmax**) is used for multi-class classification problems.\n","\n","$$CEL=-log\\left(\\frac{e^{y_{logits}}}{\\sum e^{y_{logits}}}\\right)$$"],"metadata":{"id":"i8WiwYPhGoj6"}},{"cell_type":"code","source":["def cross_entropy_loss(pred_logits, targets):\n","    log_probs = F.log_softmax(pred_logits, dim=1)\n","    class_log_probs = log_probs[range(pred_logits.shape[0]), targets]\n","    loss = -class_log_probs.mean()\n","    return loss"],"metadata":{"id":"Jw7jT7VbZ7s7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred_logits = torch.tensor([[ 2.0, 1.0,  0.1],\n","                              [ 0.1, 2.0,  1.0],\n","                              [-2.0, 1.0,  0.1],\n","                              [ 0.1, 0.0, -1.0]])\n","y_actual = torch.tensor([0, 1, 1, 0])\n","cross_entropy_loss(y_pred_logits, y_actual)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k-9oAG3FaLo0","executionInfo":{"status":"ok","timestamp":1721114521138,"user_tz":-540,"elapsed":9,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"48956e41-0c99-4dd8-ce29-a50adea8e576"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.5039)"]},"metadata":{},"execution_count":81}]},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","loss = criterion(y_pred_logits, y_actual)\n","loss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ioBhBvSKkOC","executionInfo":{"status":"ok","timestamp":1721114521138,"user_tz":-540,"elapsed":7,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"7839f6ad-504f-4daa-e4ab-bfb15e1f5ca4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.5039)"]},"metadata":{},"execution_count":82}]},{"cell_type":"markdown","source":["# **5. [Gradient Computation](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)**\n","\n","- The `autograd` package provides **automatic differentiation** for all operations on Tensors\n","\n","    * `requires_grad = True` -> tracks all operations on the tensor.\n","    - It tells pytorch that it will need to calculate the gradients for the tensor."],"metadata":{"id":"Oslw7g_US1sI"}},{"cell_type":"markdown","source":["## **5.1. Computing Gradients**"],"metadata":{"id":"ML-jIpg1iSqS"}},{"cell_type":"code","source":["!pip install torchviz -q # for plotting computational graph\n","!apt-get install graphviz -q"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fYswh-CtvkCt","executionInfo":{"status":"ok","timestamp":1721114607069,"user_tz":-540,"elapsed":85936,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"1d70504c-5206-440e-9c3e-f4ad92adbff9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Reading package lists...\n","Building dependency tree...\n","Reading state information...\n","graphviz is already the newest version (2.42.2-6).\n","0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n"]}]},{"cell_type":"code","source":["from torchviz import make_dot"],"metadata":{"id":"Bmy0bljmwVFR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = torch.tensor(7.0,requires_grad=True)\n","x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QqK88SGQs8b-","executionInfo":{"status":"ok","timestamp":1721114607069,"user_tz":-540,"elapsed":17,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"70391c3c-1210-4666-a704-d1910f934f46"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(7., requires_grad=True)"]},"metadata":{},"execution_count":85}]},{"cell_type":"code","source":["f = x**2 + 3\n","f"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AtKAlulxtDe4","executionInfo":{"status":"ok","timestamp":1721114607069,"user_tz":-540,"elapsed":14,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"8ae0744b-e5ec-441c-b464-b5bc21f1f86e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(52., grad_fn=<AddBackward0>)"]},"metadata":{},"execution_count":86}]},{"cell_type":"markdown","source":["- `f` is a function of `x`, whose gradient is to , so it has a `grad_fn` attribute.\n","\n","    * `grad_fn`: references a function that has created the tensor."],"metadata":{"id":"-Rbovrb6UGZt"}},{"cell_type":"code","source":["f.grad_fn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oDf9oBH_s8gX","executionInfo":{"status":"ok","timestamp":1721114607069,"user_tz":-540,"elapsed":10,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"4407b49f-c94e-4fd9-e4ce-1538c6e6c2fd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<AddBackward0 at 0x7d1cf218cdc0>"]},"metadata":{},"execution_count":87}]},{"cell_type":"code","source":["make_dot(f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":383},"id":"vFGJvBzrwRUW","executionInfo":{"status":"ok","timestamp":1721114607511,"user_tz":-540,"elapsed":449,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"21648272-939e-4007-90a5-20855a304449"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"image/svg+xml":"<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"109pt\" height=\"271pt\"\n viewBox=\"0.00 0.00 109.00 271.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 267)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-267 105,-267 105,4 -4,4\"/>\n<!-- 137563274147168 -->\n<g id=\"node1\" class=\"node\">\n<title>137563274147168</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"77.5,-31 23.5,-31 23.5,0 77.5,0 77.5,-31\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 137563274268096 -->\n<g id=\"node2\" class=\"node\">\n<title>137563274268096</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-86 6,-86 6,-67 95,-67 95,-86\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 137563274268096&#45;&gt;137563274147168 -->\n<g id=\"edge4\" class=\"edge\">\n<title>137563274268096&#45;&gt;137563274147168</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-66.79C50.5,-60.07 50.5,-50.4 50.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-41.19 50.5,-31.19 47,-41.19 54,-41.19\"/>\n</g>\n<!-- 137563274271024 -->\n<g id=\"node3\" class=\"node\">\n<title>137563274271024</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-141 6,-141 6,-122 95,-122 95,-141\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n</g>\n<!-- 137563274271024&#45;&gt;137563274268096 -->\n<g id=\"edge1\" class=\"edge\">\n<title>137563274271024&#45;&gt;137563274268096</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-121.75C50.5,-114.8 50.5,-104.85 50.5,-96.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-96.09 50.5,-86.09 47,-96.09 54,-96.09\"/>\n</g>\n<!-- 137563274271168 -->\n<g id=\"node4\" class=\"node\">\n<title>137563274271168</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-196 0,-196 0,-177 101,-177 101,-196\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 137563274271168&#45;&gt;137563274271024 -->\n<g id=\"edge2\" class=\"edge\">\n<title>137563274271168&#45;&gt;137563274271024</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-176.75C50.5,-169.8 50.5,-159.85 50.5,-151.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-151.09 50.5,-141.09 47,-151.09 54,-151.09\"/>\n</g>\n<!-- 137563273851376 -->\n<g id=\"node5\" class=\"node\">\n<title>137563273851376</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-263 23.5,-263 23.5,-232 77.5,-232 77.5,-263\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 137563273851376&#45;&gt;137563274271168 -->\n<g id=\"edge3\" class=\"edge\">\n<title>137563273851376&#45;&gt;137563274271168</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-231.92C50.5,-224.22 50.5,-214.69 50.5,-206.43\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-206.25 50.5,-196.25 47,-206.25 54,-206.25\"/>\n</g>\n</g>\n</svg>\n","text/plain":["<graphviz.graphs.Digraph at 0x7d1cf218d8a0>"]},"metadata":{},"execution_count":88}]},{"cell_type":"markdown","source":["- When finishing gradient computations, the `.backward()` function can be called.\n","    - This function accumulates **all gradients** computed automatically into `.grad` attribute.\n","    - It is the **partial derivate** of the function w.r.t. the tensor."],"metadata":{"id":"ovWpeqPRt4LJ"}},{"cell_type":"code","source":["x = torch.tensor([2.3, 2.1, 2.4], requires_grad = True)\n","x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8DC8nKVtNtsG","executionInfo":{"status":"ok","timestamp":1721114607511,"user_tz":-540,"elapsed":23,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"74c94eed-ffee-40bd-ab7a-74d167c9f94c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([2.3000, 2.1000, 2.4000], requires_grad=True)"]},"metadata":{},"execution_count":89}]},{"cell_type":"code","source":["def f(x):\n","  return x**2 + x"],"metadata":{"id":"VHZZaeTxyZvF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y = f(x).mean()\n","y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HVMllBOaTrlL","executionInfo":{"status":"ok","timestamp":1721114607513,"user_tz":-540,"elapsed":21,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"c3e761fe-9b78-41d4-dec0-0c3c1dd5d803"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(7.4200, grad_fn=<MeanBackward0>)"]},"metadata":{},"execution_count":91}]},{"cell_type":"code","source":["y.grad_fn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vd6X919RTroJ","executionInfo":{"status":"ok","timestamp":1721114607513,"user_tz":-540,"elapsed":18,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"2e73fd1f-b727-4795-c81d-bc64c8402bed"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<MeanBackward0 at 0x7d1cf218d360>"]},"metadata":{},"execution_count":92}]},{"cell_type":"code","source":["make_dot(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":456},"id":"yVajcAcaymoa","executionInfo":{"status":"ok","timestamp":1721114607513,"user_tz":-540,"elapsed":16,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"08bb60fa-227c-44a1-814b-32bdaeb47bea"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"image/svg+xml":"<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"140pt\" height=\"326pt\"\n viewBox=\"0.00 0.00 140.00 326.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 322)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-322 136,-322 136,4 -4,4\"/>\n<!-- 137563275417200 -->\n<g id=\"node1\" class=\"node\">\n<title>137563275417200</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"77.5,-31 23.5,-31 23.5,0 77.5,0 77.5,-31\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 137563274269536 -->\n<g id=\"node2\" class=\"node\">\n<title>137563274269536</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"98,-86 3,-86 3,-67 98,-67 98,-86\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">MeanBackward0</text>\n</g>\n<!-- 137563274269536&#45;&gt;137563275417200 -->\n<g id=\"edge6\" class=\"edge\">\n<title>137563274269536&#45;&gt;137563275417200</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-66.79C50.5,-60.07 50.5,-50.4 50.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-41.19 50.5,-31.19 47,-41.19 54,-41.19\"/>\n</g>\n<!-- 137563274272320 -->\n<g id=\"node3\" class=\"node\">\n<title>137563274272320</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-141 6,-141 6,-122 95,-122 95,-141\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 137563274272320&#45;&gt;137563274269536 -->\n<g id=\"edge1\" class=\"edge\">\n<title>137563274272320&#45;&gt;137563274269536</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-121.75C50.5,-114.8 50.5,-104.85 50.5,-96.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-96.09 50.5,-86.09 47,-96.09 54,-96.09\"/>\n</g>\n<!-- 137563274272560 -->\n<g id=\"node4\" class=\"node\">\n<title>137563274272560</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"132,-196 43,-196 43,-177 132,-177 132,-196\"/>\n<text text-anchor=\"middle\" x=\"87.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n</g>\n<!-- 137563274272560&#45;&gt;137563274272320 -->\n<g id=\"edge2\" class=\"edge\">\n<title>137563274272560&#45;&gt;137563274272320</title>\n<path fill=\"none\" stroke=\"black\" d=\"M81.39,-176.75C76.22,-169.34 68.65,-158.5 62.31,-149.41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"65.09,-147.29 56.5,-141.09 59.35,-151.29 65.09,-147.29\"/>\n</g>\n<!-- 137563274272608 -->\n<g id=\"node5\" class=\"node\">\n<title>137563274272608</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-251 0,-251 0,-232 101,-232 101,-251\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 137563274272608&#45;&gt;137563274272320 -->\n<g id=\"edge5\" class=\"edge\">\n<title>137563274272608&#45;&gt;137563274272320</title>\n<path fill=\"none\" stroke=\"black\" d=\"M46.39,-231.88C42.44,-223.09 36.76,-208.94 34.5,-196 31.79,-180.43 36.74,-163.03 41.84,-150.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"45.13,-151.6 45.98,-141.04 38.73,-148.76 45.13,-151.6\"/>\n</g>\n<!-- 137563274272608&#45;&gt;137563274272560 -->\n<g id=\"edge3\" class=\"edge\">\n<title>137563274272608&#45;&gt;137563274272560</title>\n<path fill=\"none\" stroke=\"black\" d=\"M56.61,-231.75C61.78,-224.34 69.35,-213.5 75.69,-204.41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"78.65,-206.29 81.5,-196.09 72.91,-202.29 78.65,-206.29\"/>\n</g>\n<!-- 137563273913232 -->\n<g id=\"node6\" class=\"node\">\n<title>137563273913232</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-318 23.5,-318 23.5,-287 77.5,-287 77.5,-318\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\"> (3)</text>\n</g>\n<!-- 137563273913232&#45;&gt;137563274272608 -->\n<g id=\"edge4\" class=\"edge\">\n<title>137563273913232&#45;&gt;137563274272608</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-286.92C50.5,-279.22 50.5,-269.69 50.5,-261.43\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-261.25 50.5,-251.25 47,-261.25 54,-261.25\"/>\n</g>\n</g>\n</svg>\n","text/plain":["<graphviz.graphs.Digraph at 0x7d1cf218ded0>"]},"metadata":{},"execution_count":93}]},{"cell_type":"code","source":["y.backward()\n","x.grad"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A5cThJAeT0Pa","executionInfo":{"status":"ok","timestamp":1721114608075,"user_tz":-540,"elapsed":577,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"a785a14a-d208-43cc-822b-083e66a85a58"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1.8667, 1.7333, 1.9333])"]},"metadata":{},"execution_count":94}]},{"cell_type":"code","source":["x = torch_input=torch.tensor([[ 1.0,  2.0,  3.0],\n","                              [ 4.0,  5.0,  6.0],\n","                              [ 7.0,  8.0,  9.0],\n","                              [10.0, 11.0, 12.0]], requires_grad=True)\n","x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xyDHIqtfs8pX","executionInfo":{"status":"ok","timestamp":1721114608076,"user_tz":-540,"elapsed":87,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"ae23df21-807b-4141-b1d1-9776fb6eff94"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1.,  2.,  3.],\n","        [ 4.,  5.,  6.],\n","        [ 7.,  8.,  9.],\n","        [10., 11., 12.]], requires_grad=True)"]},"metadata":{},"execution_count":95}]},{"cell_type":"code","source":["def f(x):\n","  return (x**3) + 3*(x**2) + 2*x + 4"],"metadata":{"id":"t_HkDjP3s8tc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- Note that `grad` can be implicitly created only for **scalar** outputs."],"metadata":{"id":"yNKZxTya6K2x"}},{"cell_type":"code","source":["y = f(x).sum()\n","y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"npX2rrA2s8xG","executionInfo":{"status":"ok","timestamp":1721114608076,"user_tz":-540,"elapsed":78,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"e71e9f35-81df-4f7b-90fc-111e3ef80bb9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(8238., grad_fn=<SumBackward0>)"]},"metadata":{},"execution_count":97}]},{"cell_type":"code","source":["make_dot(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":676},"id":"5i5GWpq9wkws","executionInfo":{"status":"ok","timestamp":1721114608076,"user_tz":-540,"elapsed":72,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"0950158c-7989-464f-bff7-9d3882de3fe5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"image/svg+xml":"<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"277pt\" height=\"491pt\"\n viewBox=\"0.00 0.00 277.00 491.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 487)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-487 273,-487 273,4 -4,4\"/>\n<!-- 137563275076576 -->\n<g id=\"node1\" class=\"node\">\n<title>137563275076576</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"197.5,-31 143.5,-31 143.5,0 197.5,0 197.5,-31\"/>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 137563274274144 -->\n<g id=\"node2\" class=\"node\">\n<title>137563274274144</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"215,-86 126,-86 126,-67 215,-67 215,-86\"/>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">SumBackward0</text>\n</g>\n<!-- 137563274274144&#45;&gt;137563275076576 -->\n<g id=\"edge12\" class=\"edge\">\n<title>137563274274144&#45;&gt;137563275076576</title>\n<path fill=\"none\" stroke=\"black\" d=\"M170.5,-66.79C170.5,-60.07 170.5,-50.4 170.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"174,-41.19 170.5,-31.19 167,-41.19 174,-41.19\"/>\n</g>\n<!-- 137563274271456 -->\n<g id=\"node3\" class=\"node\">\n<title>137563274271456</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"215,-141 126,-141 126,-122 215,-122 215,-141\"/>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 137563274271456&#45;&gt;137563274274144 -->\n<g id=\"edge1\" class=\"edge\">\n<title>137563274271456&#45;&gt;137563274274144</title>\n<path fill=\"none\" stroke=\"black\" d=\"M170.5,-121.75C170.5,-114.8 170.5,-104.85 170.5,-96.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"174,-96.09 170.5,-86.09 167,-96.09 174,-96.09\"/>\n</g>\n<!-- 137563274268240 -->\n<g id=\"node4\" class=\"node\">\n<title>137563274268240</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"215,-196 126,-196 126,-177 215,-177 215,-196\"/>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 137563274268240&#45;&gt;137563274271456 -->\n<g id=\"edge2\" class=\"edge\">\n<title>137563274268240&#45;&gt;137563274271456</title>\n<path fill=\"none\" stroke=\"black\" d=\"M170.5,-176.75C170.5,-169.8 170.5,-159.85 170.5,-151.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"174,-151.09 170.5,-141.09 167,-151.09 174,-151.09\"/>\n</g>\n<!-- 137563274273904 -->\n<g id=\"node5\" class=\"node\">\n<title>137563274273904</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"162,-251 73,-251 73,-232 162,-232 162,-251\"/>\n<text text-anchor=\"middle\" x=\"117.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 137563274273904&#45;&gt;137563274268240 -->\n<g id=\"edge3\" class=\"edge\">\n<title>137563274273904&#45;&gt;137563274268240</title>\n<path fill=\"none\" stroke=\"black\" d=\"M126.25,-231.75C133.97,-224.03 145.4,-212.6 154.72,-203.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"157.31,-205.64 161.91,-196.09 152.36,-200.69 157.31,-205.64\"/>\n</g>\n<!-- 137563274273328 -->\n<g id=\"node6\" class=\"node\">\n<title>137563274273328</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"89,-306 0,-306 0,-287 89,-287 89,-306\"/>\n<text text-anchor=\"middle\" x=\"44.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n</g>\n<!-- 137563274273328&#45;&gt;137563274273904 -->\n<g id=\"edge4\" class=\"edge\">\n<title>137563274273328&#45;&gt;137563274273904</title>\n<path fill=\"none\" stroke=\"black\" d=\"M56.23,-286.98C67.23,-279 83.92,-266.88 97.1,-257.31\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"99.52,-259.88 105.56,-251.17 95.41,-254.21 99.52,-259.88\"/>\n</g>\n<!-- 137563274269440 -->\n<g id=\"node7\" class=\"node\">\n<title>137563274269440</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"202,-416 101,-416 101,-397 202,-397 202,-416\"/>\n<text text-anchor=\"middle\" x=\"151.5\" y=\"-404\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 137563274269440&#45;&gt;137563274273328 -->\n<g id=\"edge5\" class=\"edge\">\n<title>137563274269440&#45;&gt;137563274273328</title>\n<path fill=\"none\" stroke=\"black\" d=\"M139.8,-396.88C128.49,-388.31 111.11,-374.53 97.5,-361 82.6,-346.2 67.43,-327.58 57.16,-314.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"59.75,-311.97 50.89,-306.15 54.19,-316.22 59.75,-311.97\"/>\n</g>\n<!-- 137563274273856 -->\n<g id=\"node10\" class=\"node\">\n<title>137563274273856</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"196,-361 107,-361 107,-342 196,-342 196,-361\"/>\n<text text-anchor=\"middle\" x=\"151.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n</g>\n<!-- 137563274269440&#45;&gt;137563274273856 -->\n<g id=\"edge9\" class=\"edge\">\n<title>137563274269440&#45;&gt;137563274273856</title>\n<path fill=\"none\" stroke=\"black\" d=\"M151.5,-396.75C151.5,-389.8 151.5,-379.85 151.5,-371.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"155,-371.09 151.5,-361.09 148,-371.09 155,-371.09\"/>\n</g>\n<!-- 137563274273952 -->\n<g id=\"node11\" class=\"node\">\n<title>137563274273952</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"269,-251 180,-251 180,-232 269,-232 269,-251\"/>\n<text text-anchor=\"middle\" x=\"224.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n</g>\n<!-- 137563274269440&#45;&gt;137563274273952 -->\n<g id=\"edge11\" class=\"edge\">\n<title>137563274269440&#45;&gt;137563274273952</title>\n<path fill=\"none\" stroke=\"black\" d=\"M166.63,-396.98C178.89,-389.23 195.55,-376.64 204.5,-361 222.57,-329.42 225.3,-285.88 225.21,-261.33\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"228.7,-261.14 225,-251.21 221.71,-261.28 228.7,-261.14\"/>\n</g>\n<!-- 137563274371984 -->\n<g id=\"node8\" class=\"node\">\n<title>137563274371984</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"181,-483 122,-483 122,-452 181,-452 181,-483\"/>\n<text text-anchor=\"middle\" x=\"151.5\" y=\"-459\" font-family=\"monospace\" font-size=\"10.00\"> (4, 3)</text>\n</g>\n<!-- 137563274371984&#45;&gt;137563274269440 -->\n<g id=\"edge6\" class=\"edge\">\n<title>137563274371984&#45;&gt;137563274269440</title>\n<path fill=\"none\" stroke=\"black\" d=\"M151.5,-451.92C151.5,-444.22 151.5,-434.69 151.5,-426.43\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"155,-426.25 151.5,-416.25 148,-426.25 155,-426.25\"/>\n</g>\n<!-- 137563274273616 -->\n<g id=\"node9\" class=\"node\">\n<title>137563274273616</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"196,-306 107,-306 107,-287 196,-287 196,-306\"/>\n<text text-anchor=\"middle\" x=\"151.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n</g>\n<!-- 137563274273616&#45;&gt;137563274273904 -->\n<g id=\"edge7\" class=\"edge\">\n<title>137563274273616&#45;&gt;137563274273904</title>\n<path fill=\"none\" stroke=\"black\" d=\"M145.89,-286.75C141.18,-279.42 134.33,-268.73 128.53,-259.7\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"131.36,-257.62 123.01,-251.09 125.46,-261.4 131.36,-257.62\"/>\n</g>\n<!-- 137563274273856&#45;&gt;137563274273616 -->\n<g id=\"edge8\" class=\"edge\">\n<title>137563274273856&#45;&gt;137563274273616</title>\n<path fill=\"none\" stroke=\"black\" d=\"M151.5,-341.75C151.5,-334.8 151.5,-324.85 151.5,-316.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"155,-316.09 151.5,-306.09 148,-316.09 155,-316.09\"/>\n</g>\n<!-- 137563274273952&#45;&gt;137563274268240 -->\n<g id=\"edge10\" class=\"edge\">\n<title>137563274273952&#45;&gt;137563274268240</title>\n<path fill=\"none\" stroke=\"black\" d=\"M215.58,-231.75C207.72,-224.03 196.07,-212.6 186.58,-203.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"188.84,-200.6 179.25,-196.09 183.94,-205.59 188.84,-200.6\"/>\n</g>\n</g>\n</svg>\n","text/plain":["<graphviz.graphs.Digraph at 0x7d1cf218e260>"]},"metadata":{},"execution_count":98}]},{"cell_type":"code","source":["y.backward()\n","x.grad"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ykzl4nStuzlK","executionInfo":{"status":"ok","timestamp":1721114608076,"user_tz":-540,"elapsed":70,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"54f4f2ab-b62e-4a3d-a764-0756f359f993"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 11.,  26.,  47.],\n","        [ 74., 107., 146.],\n","        [191., 242., 299.],\n","        [362., 431., 506.]])"]},"metadata":{},"execution_count":99}]},{"cell_type":"markdown","source":["## **5.2. Detaching Gradient Tracking: `.grad.zero_()`**"],"metadata":{"id":"IIrPdlC2eAOC"}},{"cell_type":"markdown","source":["- By default, whenever `.backward()` is called, the [**gradients are accumulated into `.grad` attribute**](https://pytorch.org/tutorials/recipes/recipes/zeroing_out_gradients.html#zeroing-out-gradients-in-pytorch) (i.e, **not overwritten**)."],"metadata":{"id":"4DZlO-Aqkdx1"}},{"cell_type":"markdown","source":["- Let us compute the gradients of $f(x)=2x^2+x$"],"metadata":{"id":"UTBqFcTE04AB"}},{"cell_type":"code","source":["x = torch.tensor(3.0, requires_grad=True)\n","\n","for _ in range(5):\n","  f = 2 * x**2 + x\n","  f.backward()\n","  print(x.grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ryK2aOzy0fD1","executionInfo":{"status":"ok","timestamp":1721114608077,"user_tz":-540,"elapsed":66,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"0ba6f855-8c0f-47ed-e985-3e40c9e9b860"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(13.)\n","tensor(26.)\n","tensor(39.)\n","tensor(52.)\n","tensor(65.)\n"]}]},{"cell_type":"code","source":["params = torch.ones(4, requires_grad=True)\n","\n","for _ in range(5):\n","    model_output = (params*3).sum()\n","    model_output.backward()\n","    print(params.grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xYv98Iv--CN0","executionInfo":{"status":"ok","timestamp":1721114608077,"user_tz":-540,"elapsed":61,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"862995a3-6c0c-45ec-c74c-ce82244b16d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([3., 3., 3., 3.])\n","tensor([6., 6., 6., 6.])\n","tensor([9., 9., 9., 9.])\n","tensor([12., 12., 12., 12.])\n","tensor([15., 15., 15., 15.])\n"]}]},{"cell_type":"markdown","source":["- It is beneficial to **zero out gradients** when building a neural network.\n","- Now,  `.grad.zero_()` can be used for this purpose."],"metadata":{"id":"F5F4vATv7Wii"}},{"cell_type":"code","source":["x = torch.tensor(3.0, requires_grad=True)\n","\n","for _ in range(5):\n","  f = 2 * x**2 + x\n","  f.backward()\n","  print(x.grad)\n","  x.grad.zero_()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VD67__g87jAA","executionInfo":{"status":"ok","timestamp":1721114608077,"user_tz":-540,"elapsed":56,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"53393fa3-17da-4f7a-9462-893c13193da9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(13.)\n","tensor(13.)\n","tensor(13.)\n","tensor(13.)\n","tensor(13.)\n"]}]},{"cell_type":"code","source":["params = torch.ones(4, requires_grad=True)\n","\n","for _ in range(5):\n","    model_output = (params*3).sum()\n","    model_output.backward()\n","    print(params.grad)\n","    params.grad.zero_()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"maNxLvBK-T9F","executionInfo":{"status":"ok","timestamp":1721114608077,"user_tz":-540,"elapsed":49,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"ad1322c2-1560-4f16-9d10-e3bf39916808"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([3., 3., 3., 3.])\n","tensor([3., 3., 3., 3.])\n","tensor([3., 3., 3., 3.])\n","tensor([3., 3., 3., 3.])\n","tensor([3., 3., 3., 3.])\n"]}]},{"cell_type":"markdown","source":["- The gradients above are correct."],"metadata":{"id":"d2XUl8RqmnsT"}},{"cell_type":"markdown","source":["# **6. Gradient Descent**\n","\n","\n","- Gradient descent is an **iterative optimization algorithm** commonly used in machine learning and neural networks.\n","- Adjusting the **parameters** in the direction of the steepest descent of the **objective** (**loss** or **error** in ML and DL) function.\n","\n","\n","- Given $\\mathbf{X}_{n\\times j}=(-\\mathbf{x}_1-,-\\mathbf{x}_2-,\\cdots,-\\mathbf{x}_n-)'$, $\\mathbf{y}_{n\\times 1}=(y_1,y_2,\\cdots,y_n)'$.\n","- For $\\mathbf{w}=(w_1,w_2,\\cdots,w_j)'$:\n","$$\\hat{y}\\leftarrow\\mathbf{X}\\mathbf{w}$$\n","\n","\n","\n","\n","\n","- Steps of GD Optimization Algorithm:\n","\n","  * **0. Initialization**: $$w_j\\sim \\cal{N}(0,1), \\forall j$$\n","\n","  * **1. Forward Pass (Prediction)**: $$\\hat{y}\\leftarrow\\mathbf{X}\\mathbf{w}$$\n","\n","  * **2. Loss (Cost) Calculation**: $$\\ell_1=\\ell(\\mathbf{w})=\\frac{1}{n}\\sum|\\hat{y}-y|\\text{ or } \\ell_2=\\ell(\\mathbf{w})=\\frac{1}{n}\\sum(\\hat{y}-y)^2 $$\n","\n","  * **3. Backward Pass (Gradient Computation)**: $$\\nabla \\mathbf{w}\\leftarrow\\frac{\\partial \\ell(\\mathbf{w})}{\\partial \\mathbf{w}}$$\n","\n","  * **4. Update Parameters**: in the opposite direction of the gradients to minimize the loss (called **gradient descent** optimizer).\n","  $$\\mathbf{w}\\leftarrow \\mathbf{w} - \\alpha \\times \\nabla \\mathbf{w}$$\n","    - $\\alpha$ is learning rate hyperparameter (common values are 0.01, 0.001, 0.0001):\n","      - Larger **learning rate** ($\\alpha$) means the optimizer will try larger updates (if too large and the optimizer will fail to work).\n","      - Lower $\\alpha$ value means the optimizer will try smaller updates (if too small and the optimizer will take too long).\n","    - GD is often implemented with additional techniques like momentum, adaptive learning rates, and regularization.\n","      - **SGD with Momentum**: Includes a term to accelerate gradients vectors in the right directions.\n","      - **AdaGrad**: Adapts the learning rate based on the frequency of updates.\n","      - **RMSprop**: Adapts the learning rate based on a moving average of squared gradients.\n","      - **Adam** (Adaptive Moment Estimation): Combines the ideas of momentum and RMSprop.\n","\n","- **Notes**:\n","    - The steps 1-4 are repeated for a **specified number of iterations (called epochs)** or until the loss is minimized to a satisfactory level.\n","    - Step 4 (Update Parameters) should not be part of the computational graph.\n"],"metadata":{"id":"-E3jJcReSfQm"}},{"cell_type":"markdown","source":["## **6.1. Single Point Approximation**\n","- Let's start small begining with a point, given $x=1$ and $y=2$.\n","\n","- Linear regression: $y = w * x $. Here consider : $ 2 = w * 1 $.\n","\n","- Let find the optimal value of $w$ such that it can approximate $y=2$ for $x=1$.\n","\n"],"metadata":{"id":"IBwIngABAbu2"}},{"cell_type":"markdown","source":["#### **Using Numpy**"],"metadata":{"id":"tF6FmLCl-aO3"}},{"cell_type":"markdown","source":["**Initialization**: $x=1,y=2$, $lr=0.1$; initial $w=1$"],"metadata":{"id":"vIBQW10s8c-3"}},{"cell_type":"code","source":["x = np.array(1.0)\n","y = np.array(2.0)\n","w = np.array(1.0)\n","lr = 0.1"],"metadata":{"id":"_3x3HU-J8c-3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**1. Forward pass**: $\\hat{y} \\leftarrow \\mathbf{x}'\\mathbf{w}$"],"metadata":{"id":"zTK_x62-8c-4"}},{"cell_type":"code","source":["y_hat= w * x\n","y_hat"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721114608078,"user_tz":-540,"elapsed":46,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"296f5fba-77c9-4bff-a5f1-9d2934228f01","id":"wVrtoPID8c-4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0"]},"metadata":{},"execution_count":105}]},{"cell_type":"markdown","source":["**2. Calculate loss**: $loss\\leftarrow\\ell(\\mathbf{w})=(\\hat{y}-y)^2 $"],"metadata":{"id":"QLUoiXfG8c-4"}},{"cell_type":"code","source":["loss = (y_hat - y)**2\n","loss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721114608078,"user_tz":-540,"elapsed":41,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"e35d8ba3-47bc-44f5-d1b6-089857462b05","id":"iFENlPuB8c-4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0"]},"metadata":{},"execution_count":106}]},{"cell_type":"markdown","source":["**3. Backward pass**: $\\Delta \\mathbf{w}\\leftarrow \\frac{\\partial loss}{\\partial \\mathbf{w}}$"],"metadata":{"id":"X3MgqmTe8c-4"}},{"cell_type":"code","source":["dw = 2*(y_hat - y)\n","dw"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721114608078,"user_tz":-540,"elapsed":38,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"067946ba-fa59-4686-ea8f-bb0468c00dfd","id":"M0caz_tn8c-4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-2.0"]},"metadata":{},"execution_count":107}]},{"cell_type":"markdown","source":["**4. Update parameters**: $\\mathbf{w}\\leftarrow \\mathbf{w} - \\alpha \\times \\Delta \\mathbf{w}$"],"metadata":{"id":"NPjzp2V18c-4"}},{"cell_type":"code","source":["w = w - lr * dw\n","w"],"metadata":{"id":"3dtmjwFR8c-4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721114608078,"user_tz":-540,"elapsed":35,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"a1208a4a-e52f-4e87-f0c6-33c77d610e79"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.2"]},"metadata":{},"execution_count":108}]},{"cell_type":"markdown","source":["- All steps in one in a for loop"],"metadata":{"id":"2xKejhIB8c-5"}},{"cell_type":"code","source":["x = np.array(1.0)\n","y = np.array(2.0)\n","w = 1\n","lr = 0.1\n","\n","for step in range(10):\n","  y_hat= w * x\n","  loss = (y_hat - y)**2\n","  dw = 2*(y_hat - y)\n","  w = w - lr * dw\n","\n","  print(f\"Step: {step + 1}, predicted = {y_hat:.2f}, Loss = {loss:.3f}, w = {w:.4f}, dw = {dw:.5f}\")\n","\n","print(f\"Final w = {w:.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721122030654,"user_tz":-540,"elapsed":336,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"5e83a577-b89a-404b-eb5e-00ba6c3c224c","id":"3kWyfDez8c-5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Step: 1, predicted = 1.00, Loss = 1.000, w = 1.2000, dw = -2.00000\n","Step: 2, predicted = 1.20, Loss = 0.640, w = 1.3600, dw = -1.60000\n","Step: 3, predicted = 1.36, Loss = 0.410, w = 1.4880, dw = -1.28000\n","Step: 4, predicted = 1.49, Loss = 0.262, w = 1.5904, dw = -1.02400\n","Step: 5, predicted = 1.59, Loss = 0.168, w = 1.6723, dw = -0.81920\n","Step: 6, predicted = 1.67, Loss = 0.107, w = 1.7379, dw = -0.65536\n","Step: 7, predicted = 1.74, Loss = 0.069, w = 1.7903, dw = -0.52429\n","Step: 8, predicted = 1.79, Loss = 0.044, w = 1.8322, dw = -0.41943\n","Step: 9, predicted = 1.83, Loss = 0.028, w = 1.8658, dw = -0.33554\n","Step: 10, predicted = 1.87, Loss = 0.018, w = 1.8926, dw = -0.26844\n","Final w = 1.893\n"]}]},{"cell_type":"markdown","source":["- Set the number of steps to 100, and look at the value of the updated parameter, $w$."],"metadata":{"id":"uFLb-aSC93NU"}},{"cell_type":"markdown","source":["#### **Using PyTorch**\n","\n","- In the codes below the **numpy arrays are changed to torch tensors**."],"metadata":{"id":"BZiyK_Xw_S-K"}},{"cell_type":"code","source":["x = torch.tensor(1.0)\n","y = torch.tensor(2.0)\n","w = torch.tensor(1.0, requires_grad=True)\n","lr = 0.1\n","\n","for step in range(10):\n","  y_hat= w * x\n","  loss = (y_hat - y)**2\n","  dw = 2*(y_hat - y)\n","  w = w - lr * dw\n","\n","  print(f\"Step: {step + 1}, predicted = {y_hat:.2f}, Loss = {loss:.3f}, w = {w:.4f}, dw = {dw:.5f}\")\n","\n","print(f\"Final w = {w:.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"t0t7k_Pd5LUW","executionInfo":{"status":"error","timestamp":1721122038556,"user_tz":-540,"elapsed":411,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"27623d80-3a53-41dc-fd34-0b4f2cfafca6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-128-aa55f2deb640>:11: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n","  w.grad.zero_()\n"]},{"output_type":"error","ename":"AttributeError","evalue":"'NoneType' object has no attribute 'zero_'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-128-aa55f2deb640>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mdw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Step: {step + 1}, predicted = {y_hat:.2f}, Loss = {loss:.3f}, w = {w:.4f}, dw = {dw:.5f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'zero_'"]}]},{"cell_type":"markdown","source":["- Set the number of steps to 100, and look at the value of the updated parameter, $w$."],"metadata":{"id":"HBpVzLjkM7aU"}},{"cell_type":"markdown","source":["- To use inplace update of the parameter(s), it should be wrapped in `with torch.no_grad():` as\n","\n","\n","\n","\n","            ```\n","            with torch.no_grad():\n","                w -= lr * dw\n","            ```\n","\n"],"metadata":{"id":"n6G0Z8X9V6-b"}},{"cell_type":"markdown","source":["## **6.2. Extending to Straight Line**\n","\n","- Now let us look at a straight line:  $y=wx \\Rightarrow y\\approx w*x $."],"metadata":{"id":"A3wft7Z_ISbA"}},{"cell_type":"code","source":["x = np.array([1, 2, 3, 4], dtype=np.float32)\n","y = np.array([2, 4, 6, 8], dtype=np.float32)\n","n = len(x)"],"metadata":{"id":"lGdjd3Upc7SN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Using Numpy**"],"metadata":{"id":"4D24XwL_uB2y"}},{"cell_type":"code","source":["lr = 0.01\n","epochs = 20\n","\n","w = 0.0\n","for step in range(10):\n","  y_pred = w * x\n","  loss = np.sum((y_pred - y)**2) / n\n","  dw = np.sum(2 * x * (y_pred - y)) / n\n","  w = w - lr * dw\n","  print(f'Epoch {step + 1}: w = {w:.3f}, loss = {loss:.5f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VNfTLi1xrqPj","executionInfo":{"status":"ok","timestamp":1721115853286,"user_tz":-540,"elapsed":344,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"2ea34521-cc76-4a90-d491-f5181e8b7e6a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1: w = 0.300, loss = 30.00000\n","Epoch 2: w = 0.555, loss = 21.67500\n","Epoch 3: w = 0.772, loss = 15.66019\n","Epoch 4: w = 0.956, loss = 11.31449\n","Epoch 5: w = 1.113, loss = 8.17472\n","Epoch 6: w = 1.246, loss = 5.90623\n","Epoch 7: w = 1.359, loss = 4.26725\n","Epoch 8: w = 1.455, loss = 3.08309\n","Epoch 9: w = 1.537, loss = 2.22753\n","Epoch 10: w = 1.606, loss = 1.60939\n"]}]},{"cell_type":"markdown","source":["### **Using PyTorch**"],"metadata":{"id":"cO8Qi7EVHITJ"}},{"cell_type":"code","source":["x = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n","y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n","n = len(x)\n","\n","lr = 0.01\n","epochs = 20\n","\n","w = torch.tensor(0.0, requires_grad=True)\n","\n","for step in range(10):\n","  y_pred = w * x\n","  loss = torch.sum((y_pred - y)**2) / n\n","  dw = torch.sum(2 * x * (y_pred - y)) / n\n","  w = w - lr * dw\n","  print(f'Epoch {step + 1}: w = {w:.3f}, loss = {loss:.5f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LW8shRlfATWa","executionInfo":{"status":"ok","timestamp":1721116976771,"user_tz":-540,"elapsed":363,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"7378dd43-d08c-4f46-c530-823d65fb7a5c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1: w = 0.29999998211860657, loss = 30.00000\n","Epoch 2: w = 0.5549999475479126, loss = 21.67500\n","Epoch 3: w = 0.7717499136924744, loss = 15.66019\n","Epoch 4: w = 0.9559874534606934, loss = 11.31449\n","Epoch 5: w = 1.1125893592834473, loss = 8.17472\n","Epoch 6: w = 1.2457009553909302, loss = 5.90623\n","Epoch 7: w = 1.358845829963684, loss = 4.26725\n","Epoch 8: w = 1.4550189971923828, loss = 3.08309\n","Epoch 9: w = 1.5367661714553833, loss = 2.22753\n","Epoch 10: w = 1.6062512397766113, loss = 1.60939\n"]}]},{"cell_type":"markdown","source":["## **6.3. Using Built-in Functions for Loss and Gradient**\n","\n","- Let us functionalize the functions.\n","\n","  - 1. Forward pass - Manually\n","  - 2. Loss calculation - Built-in: `nn.MSELoss()`\n","  - 3. Gradient computation  - Built-in: `.backward()`\n","  - 4. Update parameters - Manually\n","  - 5. Zero gradients - Manually\n","\n","\n"," - The weight update (`w = w - lr * dw`) should **not be part of the computational graph**.\n","\n","    - In-place operation for the update should be wrapped in `with torch.no_grad():` as:\n","\n","    ```\n","      with torch.no_grad():\n","          w -= lr * dw\n","    ```\n","\n"," - One more thing, **must empty or zero the gradients** prior to calling the `.backward` function.\n"," - The `.zero_()` method is used to zero out the elements of a tensor, i.e., `w.grad.zero_()`.\n","    - In the code below, comment out it and observe the difference in the results."],"metadata":{"id":"UO4LClma9EB7"}},{"cell_type":"code","source":["x = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n","y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n","n = len(x)\n","\n","lr = 0.01\n","epochs = 20\n","\n","w = torch.tensor(0.0, requires_grad=True)\n","criterion = nn.MSELoss()\n","\n","for step in range(10):\n","  y_pred = w * x\n","  loss = criterion(y_pred, y)\n","  loss.backward()\n","  with torch.no_grad():\n","    w -= lr * w.grad\n","  w.grad.zero_()\n","\n","  print(f'Epoch {step + 1}: w = {w:.3f}, loss = {loss:.5f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NJkEXsy43qxa","executionInfo":{"status":"ok","timestamp":1721122535059,"user_tz":-540,"elapsed":434,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"d809441b-8b8a-46a9-8a66-f7bcfc2d3eb0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1: w = 0.300, loss = 30.00000\n","Epoch 2: w = 0.555, loss = 21.67500\n","Epoch 3: w = 0.772, loss = 15.66019\n","Epoch 4: w = 0.956, loss = 11.31449\n","Epoch 5: w = 1.113, loss = 8.17472\n","Epoch 6: w = 1.246, loss = 5.90623\n","Epoch 7: w = 1.359, loss = 4.26725\n","Epoch 8: w = 1.455, loss = 3.08309\n","Epoch 9: w = 1.537, loss = 2.22753\n","Epoch 10: w = 1.606, loss = 1.60939\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"DoLDaREt77u_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uNo0hC6k77y4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"u3-HYJ5u772K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"C4j9ebILjnXF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tp74o2ipjnbB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"16LW0aX4jnet"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_Ph26MVi7758"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- **Difference between `axis` and `dim`**?\n","\n","    - `axis` works for both numpy and tensor arrays.\n","    - `dim` works for tensor arrays only."],"metadata":{"id":"arEzyvyViUyo"}},{"cell_type":"code","source":["x = np.array([2.0, 1.0, 0.1])\n","print(x.sum())\n","print(x.sum(axis=0))\n","# print(x.sum(dim=0)) # dim is not working"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7o2TPpE06cS5","executionInfo":{"status":"ok","timestamp":1721122883616,"user_tz":-540,"elapsed":357,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"63fa70b8-24c9-4897-9538-23bf04e8daf4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3.1\n","3.1\n"]}]},{"cell_type":"code","source":["y = torch.tensor([2.0, 1.0, 0.1])\n","print(y.sum())\n","print(y.sum(dim=0))\n","print(y.sum(axis=0)) # axis is also working"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721122910496,"user_tz":-540,"elapsed":330,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"d5f82d12-d810-408c-db8c-699e5dbb8c33","id":"xu57NDMAiUyo"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(3.1000)\n","tensor(3.1000)\n","tensor(3.1000)\n"]}]},{"cell_type":"markdown","source":["**Utility Functions**"],"metadata":{"id":"Ws91ulhcctmR"}},{"cell_type":"code","source":["def accuracy_metric(y_true, y_pred):\n","  correct_preds = torch.eq(y_true, y_pred).sum().item()\n","  return (correct_preds / len(y_pred)) * 100"],"metadata":{"id":"8evslfvZcs65"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Experiment Timing Function**"],"metadata":{"id":"IWWgMfLuddhD"}},{"cell_type":"code","source":["from timeit import default_timer as timer\n","def computing_time( start: float, end: float, device: torch.device = None):\n","    total_time = end - start\n","    print(f\"Computing time on {device}: {total_time:.3f} seconds\")\n","    return total_time"],"metadata":{"id":"i-0QEcYYdId1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["start_time = timer()\n","# some code here\n","end_time = timer()\n","computing_time(start = start_time, end = end_time, device = \"cpu\")"],"metadata":{"id":"xNnrFh0jdJJ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xYmdxPtz-Bc_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tchYdkPn-Bjv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7_LLZfRe-Bot"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JVXpez6b-Buj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"O5vv1mNd-BzN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"V8dFhFcG-B3s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Aq4vJfZ6-B8C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BfhZQngV-CAU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ikE-xtdc-CFi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"VJucdv7R-CKB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Wt09bkrj-CYs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"HwtY1Jrs-Ch9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HXUIf4hw8R_A"},"source":["# **Other**\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"EYHm2O2t6Usd"},"source":["## **Subclassing `nn.Module`**\n","- [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) acts as a box that brings together multiple functions for model implementation, analysis and other uses.\n"]},{"cell_type":"code","metadata":{"id":"lF5CCXcgxjWD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721393331493,"user_tz":-540,"elapsed":507,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"b9d61a56-6537-4dee-ef67-3c516ed06762"},"source":["import torch\n","from torch import nn\n","\n","class Add(nn.Module):\n","    def __init__(self):\n","        super(Add, self).__init__()\n","\n","    def forward(self, x1, x2):\n","        return torch.add(x1, x2)\n","\n","\n","x1 = torch.tensor([1])\n","x2 = torch.tensor([2])\n","\n","add = Add()\n","output = add(x1, x2)\n","\n","output == 3"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([True])"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"6a_OSRXMgc8j"},"source":["## **Containers: [`nn.Sequential()`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential)**\n","\n","\n","- To combine modules into one and run them sequentially."]},{"cell_type":"code","metadata":{"id":"ZAzm120dL1p4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721539195460,"user_tz":-540,"elapsed":384,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"64ee8e81-e4c7-41e4-a932-ffbdef49ab32"},"source":["import torch\n","from torch import nn\n","\n","class Add(nn.Module):\n","    def __init__(self, value):\n","        super().__init__()\n","        self.value = value\n","\n","    def forward(self, x):\n","        return x + self.value\n","\n","\n","#        y = x + 3 + 2 + 5\n","calculator = nn.Sequential(\n","    Add(3),\n","    Add(2),\n","    Add(5))\n","\n","\n","x = torch.tensor([1])\n","\n","output = calculator(x)\n","\n","output.item() == 11"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"a-Zs6pnh1925"},"source":["## **Module List: [`nn.ModuleList()`](https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#torch.nn.ModuleList)**\n","\n","- It looks good to bring together functions that have a fixed order of execution!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7D3cK6pS193J","executionInfo":{"status":"ok","timestamp":1721393892428,"user_tz":-540,"elapsed":512,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"bf300af8-4607-4ece-bec3-7d1f9a0c68e2"},"source":["import torch\n","from torch import nn\n","\n","class Add(nn.Module):\n","    def __init__(self, value):\n","        super().__init__()\n","        self.value = value\n","\n","    def forward(self, x):\n","        return x + self.value\n","\n","class Calculator(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.add_list = nn.ModuleList([Add(2), Add(3), Add(5)])\n","\n","    def forward(self, x):\n","        for i, _ in enumerate(self.add_list):\n","            x = self.add_list[i](x)\n","        return x\n","\n","x = torch.tensor([1])\n","\n","calculator = Calculator()\n","output = calculator(x)\n","\n","output == 11"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([True])"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"XLOhs8I56dYA"},"source":["## **Module Dictionary: [`nn.ModuleDict()`](https://pytorch.org/docs/stable/generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict)**\n","\n","\n","- In `torch.nn.ModuleList()`, if the size of the modules on the list gets really big, it will be really hard to find the module we want with indexing in the future!\n","- If we store a particular module using the key value like Python's dict,\n","Wouldn't it be easier to bring the module we want later?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"suYi2pjj6dYK","executionInfo":{"status":"ok","timestamp":1721394413658,"user_tz":-540,"elapsed":470,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"d903d22c-4058-4681-a3b7-a5bf620f3845"},"source":["import torch\n","from torch import nn\n","\n","class Add(nn.Module):\n","    def __init__(self, value):\n","        super().__init__()\n","        self.value = value\n","\n","    def forward(self, x):\n","        return x + self.value\n","\n","class Calculator(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.add_dict = nn.ModuleDict({'add2': Add(2),\n","                                       'add3': Add(3),\n","                                       'add5': Add(5)})\n","\n","    def forward(self, x):\n","        for key in self.add_dict.keys():\n","          x = self.add_dict[key](x)\n","        return x\n","\n","x = torch.tensor([1])\n","\n","calculator = Calculator()\n","output = calculator(x)\n","\n","output == 11"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([True])"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"CgV9Ntk38ieo"},"source":["## **Python List vs PyTorch ModuleList**"]},{"cell_type":"code","metadata":{"id":"p0X4Bi7E9bjz"},"source":["class Add(nn.Module):\n","    def __init__(self, value):\n","        super().__init__()\n","        self.value = value\n","\n","    def forward(self, x):\n","        return x + self.value\n","\n","\n","class PythonList(nn.Module):\n","    \"\"\"Python List\"\"\"\n","    def __init__(self):\n","        super().__init__()\n","\n","        # Python List\n","        self.add_list = [Add(2), Add(3), Add(5)]\n","\n","    def forward(self, x):\n","        x = self.add_list[1](x)\n","        x = self.add_list[0](x)\n","        x = self.add_list[2](x)\n","\n","        return x\n","\n","class PyTorchList(nn.Module):\n","    \"\"\"PyTorch List\"\"\"\n","    def __init__(self):\n","        super().__init__()\n","\n","        # Pytorch ModuleList\n","        self.add_list = nn.ModuleList([Add(2), Add(3), Add(5)])\n","\n","    def forward(self, x):\n","        x = self.add_list[1](x)\n","        x = self.add_list[0](x)\n","        x = self.add_list[2](x)\n","\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wcZcR67F_MbE","executionInfo":{"status":"ok","timestamp":1721539271732,"user_tz":-540,"elapsed":389,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"62a7a625-63a7-475c-a5a8-01930e0a1ca0"},"source":["x = torch.tensor([1])\n","\n","python_list = PythonList()\n","pytorch_list = PyTorchList()\n","\n","print(python_list(x), pytorch_list(x))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([11]) tensor([11])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o8qgY2EK_lMb","executionInfo":{"status":"ok","timestamp":1721539286913,"user_tz":-540,"elapsed":428,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"0a48c3a6-7e58-4c9c-96fd-b44dd791b0c0"},"source":["python_list"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PythonList()"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I-eFwdj7ABMH","executionInfo":{"status":"ok","timestamp":1721539288539,"user_tz":-540,"elapsed":5,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"a2cc5fb5-ee9e-4d6d-a10e-0e51e07a47c3"},"source":["pytorch_list"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PyTorchList(\n","  (add_list): ModuleList(\n","    (0-2): 3 x Add()\n","  )\n",")"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"8EZ7R-Js8ie5"},"source":["- It is right because PyTorch module list holds other submodules in a list.\n","- PyTorch modules are properly registered, and are visible by all module methods.\n","- The indexing is also similar to like that of a regular Python list.\n"]},{"cell_type":"markdown","metadata":{"id":"LYE0lhVK2Vow"},"source":["## **Module Parameter: [`nn.parameter.Parameter()`](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html?highlight=parameter)**\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wQoHSQcA2Vo3","executionInfo":{"status":"ok","timestamp":1721539914269,"user_tz":-540,"elapsed":338,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"9786c8d6-600d-4d55-a8e8-ce1c6cdd968a"},"source":["import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","\n","\n","class Linear(nn.Module):\n","    def __init__(self, in_features, out_features):\n","        super().__init__()\n","\n","        self.W = Parameter(torch.ones((out_features, in_features)))\n","        self.b = Parameter(torch.ones((out_features)))\n","\n","    def forward(self, x):\n","        output = torch.addmm(self.b, x, self.W.T)\n","\n","        return output\n","\n","\n","x = torch.Tensor([[1, 2],\n","                  [3, 4]])\n","\n","linear = Linear(2, 3)\n","Y = linear(x)\n","Y"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[4., 4., 4.],\n","        [8., 8., 8.]], grad_fn=<AddmmBackward0>)"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"S8u8jNL8H_dN"},"source":["**Tensor vs Parameter**\n","\n","\n","- Should not W and B also use a tensor? Why do we have to use a separate class called `.Parameter`?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ULF5STEQH_dO","executionInfo":{"status":"ok","timestamp":1721540055837,"user_tz":-540,"elapsed":383,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"218c051a-2a35-4d25-bf32-1e4741872833"},"source":["import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","\n","\n","class LinearParameter(nn.Module):\n","    def __init__(self, in_features, out_features):\n","        super().__init__()\n","\n","        self.W = Parameter(torch.ones((out_features, in_features)))\n","        self.b = Parameter(torch.ones(out_features))\n","\n","    def forward(self, x):\n","        output = torch.addmm(self.b, x, self.W.T)\n","\n","        return output\n","\n","class LinearTensor(nn.Module):\n","    def __init__(self, in_features, out_features):\n","        super().__init__()\n","\n","        self.W = torch.ones((out_features, in_features))\n","        self.b = torch.ones(out_features)\n","\n","    def forward(self, x):\n","        output = torch.addmm(self.b, x, self.W.T)\n","\n","        return output\n","\n","\n","x = torch.Tensor([[1, 2],\n","                  [3, 4]])\n","\n","linear_parameter = LinearParameter(2, 3)\n","linear_tensor = LinearTensor(2, 3)\n","\n","Y_parameter = linear_parameter(x)\n","Y_tensor = linear_tensor(x)\n","\n","print(Y_parameter)\n","print(Y_tensor)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[4., 4., 4.],\n","        [8., 8., 8.]], grad_fn=<AddmmBackward0>)\n","tensor([[4., 4., 4.],\n","        [8., 8., 8.]])\n"]}]},{"cell_type":"markdown","source":["- The values are calculated the same!\n","- But we use the parameter to make `W`, `b` only."],"metadata":{"id":"VM4fCmn3yM56"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SCmHCEEWH_dP","executionInfo":{"status":"ok","timestamp":1721540220161,"user_tz":-540,"elapsed":386,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"d4577429-c762-4973-d0d4-5281eb921c4a"},"source":["linear_parameter.state_dict()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('W',\n","              tensor([[1., 1.],\n","                      [1., 1.],\n","                      [1., 1.]])),\n","             ('b', tensor([1., 1., 1.]))])"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5obZKlPzH_dP","executionInfo":{"status":"ok","timestamp":1721540228700,"user_tz":-540,"elapsed":376,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"2b3c4159-1d1e-4f0f-e9dd-119c21b6ed20"},"source":["linear_tensor.state_dict()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict()"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"KH49yfoYH_dR"},"source":["- Parameter objects are tensor objects that can be optimized.\n","- Unlike a parameter, a tensor does not calculate gradients.\n","  - Hence, the value of a tensor is not updated.\n","  - The value of a tensor cannot also be saved unlike a parameter when saving a model.\n","\n","- \"Tensor\"\n","    -  Gradient calculation\n","    -  Update the value\n","    -  Save value when saving model\n","- \"Parameter\"\n","    -  Gradient calculation\n","    -  Update the value\n","    -  Save value when saving model"]}]}