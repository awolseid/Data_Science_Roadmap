{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assigment Custom Model - english","provenance":[{"file_id":"1i56_UtG4CaTA1_uVD4-jYcSSgcEE7D9A","timestamp":1656150845871},{"file_id":"11ZbQpXb6jl5EkiDvrQ0VdzQX-RFsSabw","timestamp":1653356278847},{"file_id":"1We-9x7fHGwxvsiQPoFvAkLcdj1NHJDjL","timestamp":1653356232688}],"collapsed_sections":["nzf_SMkwQIcp","VodIGNr0gI8U","95QrHvgqadqg","jpXu3zuOcjzO","6ARH3kXTPKEq"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"dYStbm6ZsH9a"},"source":["# Custom Model \n","> Welcome to PyTorch's first Essential Assignment! In this Colab, you will have time to take advantage of the various and other useful knowledge you have learned while taking the PyTorch course!\n","- 🌍 Utilize Documentation for Custom Model Creation\n","- ⭐ nn.Module class for custom model creation\n","- 🚀 <font color='yellow'><b>[Optional]</b><font>See Github for Custom Models\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"nzf_SMkwQIcp"},"source":["## 😉 PyTorch Licence\n","\n","PyTorch uses BSD licenses! Free to modify, distribute and even commercially available!\n","\n","\n","![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/pytorch%20official%20-%20bsd%20license.png?raw=true)\n","\n","- [Adding a Contributor License Agreement for PyTorch - PyTorch](https://pytorch.org/blog/a-contributor-license-agreement-for-pytorch/#what-is-not-changing)\n","- [BSD License - Wikipedia](https://en.wikipedia.org/wiki/BSD_licenses)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"TE5_pyW7zvbT"},"source":["## 🌈 Task Type\n","\n","> The challenges that you will face in the future are made up of four types!\n","- 🔎 Explore : Let's go on an adventure looking for information\n","- 👨‍💻 Coding : Write your own code!\n","- 📖 Read : Look through the material with your eyes!\n","- ❓ Quiz :  Guess the answer!\n","\n","**etc**\n","- 🎁 Hint: This article helps you solve the task\n","- ✨ Useful materials: Good to read, but not required\n","- 🔥 Vitality: Task difficulty is high\n","- 🔥🔥🔥 Vibrant: The task is very difficult\n"]},{"cell_type":"markdown","metadata":{"id":"Lh7DIeNXnfZN"},"source":["## 🌍 Utilize Documentation for Custom Model Creation\n","\n","```\n","💡 We'll explore Documentation in the PyTorch library together and learn how to leverage Documentation for custom model creation!\n","```\n","\n","Documentation is a document where developers kindly describe their libraries. The solutions to many of the problems we experience using libraries are mostly well organized on blogs like Stackoverflow and medium found on Google, but there are moments when we need to know the details. In some cases, what we're looking for is nowhere else except documentation.\n","\n","Documentation is a place that contains all the details of the library, and the more you know about it, the wider the tools you can use to create a Custom model. It's the most important cornerstone to create your own more stylish custom model!\n","\n","\n","- 🌓 Get acquainted with Documentation\n","- 🌓Explore information in  Documentation\n","- 🌓Understand and leverage the features found in  Documentation\n","- 🌓 Read Documentation"]},{"cell_type":"markdown","metadata":{"id":"A9pZE3mpaIdG"},"source":["###  🌓 Geting acquainted with Documentationt\n","> When you see Documentation for the first time, you'll be fed up with the huge amount! Especially if it's a documentation in an unfamiliar field, it's not to mention the awkwardness! You don't have to understand the content! Feel free to watch Documentation, press this and that, and explore!\n","\n","- 🔎 <font color='orange'><b>[ Explorer ]</b></font> Check documentation\n","- ❓ <font color='red'><b>[ Quiz ]</b></font> PyTorch Release Status "]},{"cell_type":"markdown","metadata":{"id":"Oknx2fv3Ncvn"},"source":["#### 🔎 <font color='orange'><b>[ 탐색 ]</b></font> Check Documentation \n","> 💡 Please follow the suggested items! It's not a quiz!\n","\n","\n","``` python\n","🦆\n","I went into the official documentation to get to know PyTorch!\n","Like PyTorch, I can see the red highlighted homepage!\n","Let`s take a look around Documentation!\n","\n","```\n","- [Documentation main - PyTorch 공식 문서](https://pytorch.org/docs/stable/index.html)"]},{"cell_type":"markdown","metadata":{"id":"VodIGNr0gI8U"},"source":["##### ✔️ 버젼 (Version)\n","``` python\n","🦆\n","Let`s take a look at the version of PyTorch Documentation that we`re looking at!\n","```\n","\n","- ✅ Check PyTorch Version\n","    - `1.9.0`\n","- ✅ Click on PyTorch version to explore other versions\n","    - ![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/pytorch%20version.png?raw=true)\n","    - `v0.1.12`에서 시작해서 현재 `v1.9.0` 버젼\n","- ✅ Open master version Documentation\n","\n"]},{"cell_type":"markdown","metadata":{"id":"95QrHvgqadqg"},"source":["##### ✔️ 목차 (Index)\n","``` python\n","🦆\n","PyTorch has a lot of things in it\n","It will be well organized in the table of contents so that people can easily find the content!\n","I think there`s a table of contents on the left side of Documentation! Let's take a look together!\n","```\n","\n","- ✅  click `[ - ]` in `python API`\n","    - ![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/+%20-%20button.png?raw=true)\n","- ✅ Check index\n","    - Notes\n","    - Language Bindings\n","    - Python API\n","    - Libraries\n","    - Community\n","- ✅ Review the subtopic of the python API\n","- ✅ Lightly read any subtopic of the Python API\n","    - ex) `torch.nn`\n","- ✅ python API - To check the internal table of contents of a torch document\n","    - [TORCH - PyTorch 공식 문서](https://pytorch.org/docs/stable/torch.html)\n","    - ![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/table%20of%20content%20-%20torch.png?raw=true)\n","    \n"]},{"cell_type":"markdown","metadata":{"id":"tSwYkTH_lgsz"},"source":["##### ✔️ Search\n","``` python\n","🦆\n","There`s a table of contents, so it looks easy to find what you want,\n","If you`re not familiar with it, you`ll be wandering for a long time to find what you want!\n","I think we can use search bar to find what we want right away!\n","```\n","\n","- ✅ Check the search bar \n","    - ![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/pytorch%20search%20bar.png?raw=true)\n","- ✅ Search any keyword you want\n","    - ex) duck\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VfkQ0jmGbSmX"},"source":["#### ❓ <font color='red'><b>[ 퀴즈 ]</b></font> PyTorch Release Status (배포 상태)\n","``` python\n","🦆\n","There's a lot in PyTorch! Stop looking around\n","I'm back on the main page, and there's an explanation about the release status!\n","Stable, Beta, and Prototype. Please tell me what Beta is!\n","```\n","- [Documentation main - PyTorch 공식 문서](https://pytorch.org/docs/stable/index.html)"]},{"cell_type":"markdown","metadata":{"id":"5X_RYE6szDXr"},"source":["```python\n","😮\n","# TODO: It's a matter of absolute certainty. Please read the document and write down the answers freely\n","Uh, um, I mean, What is Beta?\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"JQsWM-vgqV17"},"source":["### 🌓 Navigating information in Documentation\n","\n","> Most solutions can be found right away through googling, and everyone who reads this now will already be using it well. However, not all of Documentation's information comes from googling all the time, so let's practice how to find information with Documentation only without googling!\n","\n","- ❓ <font color='red'><b>[ 퀴즈 ]</b></font> Leverage the search capabilities provided by Documentation\n","\n","- 🔎 <font color='orange'><b>[ 탐색 ]</b></font> Look at the table of contents and find the information you want"]},{"cell_type":"markdown","metadata":{"id":"33PuuiWGZhz5"},"source":["#### ❓ <font color='red'><b>[ 퀴즈 ]</b></font> Leverage the search capabilities provided by Documentation\n","\n","\n","``` python\n","🦆\n","I want to find out what I`m curious about by using the search function provided by PyTorch!\n","\n","```\n","- [Documentation main - PyTorch 공식 문서](https://pytorch.org/docs/stable/index.html)\n"]},{"cell_type":"markdown","metadata":{"id":"M1EGwkfCxDr7"},"source":["##### 💯 Whether the PyTorch functions as a Linear Algebra\n","\n","\n","``` python\n","🦆\n","Does PyTorch have functions related to linear algebra like NumPy?\n","```"]},{"cell_type":"markdown","metadata":{"id":"CmxHQsDxZUoK"},"source":["```python\n","😉\n","# TODO: Feel free to answer whether you have it or not!\n","\n","\n","```"]},{"cell_type":"markdown","metadata":{"id":"D9JlxC5WyO7X"},"source":["##### 💯 Matrix Multiplication\n","\n","``` python\n","🦆\n","What function do you use when you want to do Matrix Multiplication in pytorch?\n","\n","```"]},{"cell_type":"markdown","metadata":{"id":"rHpU8WUZyO7f"},"source":["```python\n","😉\n","# TODO: No fixed format! Please feel free to answer!\n","\n","\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"qXkF-1SC1Q0q"},"source":["##### 💯 Norm\n","> Note that norm is not normalization, but norm, which is the concept of the size of a vector or matrix!\n","\n","``` python\n","🦆\n","I think I'll use a lot of the norm of vectors and matrices when I make models!\n","What function should we use in this case?\n","\n","```"]},{"cell_type":"markdown","metadata":{"id":"orfjxQuq1Q0u"},"source":["```python\n","😃\n","# TODO: No fixed format! Please feel free to answer!\n","\n","\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"oJ0ZuWycwsff"},"source":["#### 🔎 <font color='orange'><b>[ 탐색 ]</b></font> Look at the table of contents and find the information you want\n","\n","> 💡 Please follow the suggested items! It's not a quiz!\n","\n","``` python\n","🦆\n","When I get used to PyTorch later, I want to contribute my code to the library!\n","As with most libraries, PyTorch clearly identifies the contribution process\n","I'm sure there's a document you've written!\n","```\n","- [Documentation main - PyTorch 공식 문서](https://pytorch.org/docs/stable/index.html)\n"]},{"cell_type":"markdown","metadata":{"id":"fUmgABsu8dSn"},"source":["``` python\n","🦆\n","Community (community) is on the table of contents, too!\n","Cord guide for those who want to contribute to the document is here!\n","```\n","\n","- ✅ Explore the Community sub-table of contents\n","- ✅ Open and browse the PyTorch Contribution Guide document\n","    - [PyTorch Contribution Guide - PyTorch 공식 문서](https://pytorch.org/docs/stable/community/contribution_guide.html)\n","- ✅ Check the internal table of contents of the document for PyTorch Contribution Guide \n","    - ![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/table%20of%20content%20-%20contribution.png?raw=true)\n","- ✅ 내부 목차 - Read Common Mistakes to Avoid lightly\n","    - [PyTorch Contribution Guide - Common Mistakes To Avoid - PyTorch 공식 문서](https://pytorch.org/docs/stable/community/contribution_guide.html#common-mistakes-to-avoid)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"5qM693v7A31v"},"source":["### 🌓 Understand and leverage the features found in Documentation\n","> Now you know how to find the information you want in PyTorch documentation! But it's no use just looking! It's really meaningful if you read the description of the function written in Documentation and know how to use it yourself. We will try PyTorch ourselves with a simple example!\n","\n","- ❓ <font color='red'><b>[ 퀴즈 ]</b></font> PyTorch's basic component Tensor\n","\n","- 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> Calculating four fundamental arithmetic operations\n","\n","- 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> Indexing"]},{"cell_type":"markdown","metadata":{"id":"zfJJRMVx4uZU"},"source":["#### ❓ <font color='red'><b>[ 퀴즈 ]</b></font> PPyTorch's basic component Tensor\n","``` python\n","🦆\n","PyTorch said that the sensor is the basic component of everything\n","I looked it up to use, and I said, \"torch.tensor\" and \"torch.Tensor\"\n","There are two kinds! What's the difference?\n","```\n","- [Documentation main - PyTorch 공식 문서](https://pytorch.org/docs/stable/index.html)"]},{"cell_type":"markdown","metadata":{"id":"JXqdRH8h4uZc"},"source":["```python\n","🙃\n","# TODO: It's a matter of absolute certainty. Please read the document and write down the answers freely\n","\n","\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"f3MnmB0zE-TK"},"source":["#### 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> Calculating the four fundamental arithmetic operations\n","\n","``` python\n","🦆\n","We`re finally starting coding using PyTorch!\n","Let's start with a simple calculation!\n","```\n","- [Documentation main - PyTorch 공식 문서](https://pytorch.org/docs/stable/index.html)\n"]},{"cell_type":"markdown","metadata":{"id":"dgoOCMtbJHEL"},"source":["##### 💡 더하기 (add)\n","\n","```python\n","🦆\n","I'll calculate the 5+7 first!\n","\n","```\n","\n","- [torch.add - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.add.html?highlight=add#torch.add)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K5-9T-fjE3a_","executionInfo":{"status":"ok","timestamp":1653357472619,"user_tz":-540,"elapsed":3738,"user":{"displayName":"최성철","userId":"16731672827766253258"}},"outputId":"2c8bb494-d691-4929-cd19-05c7f6dd96fa"},"source":["import torch\n","\n","A = torch.Tensor([5])\n","B = torch.Tensor([7])\n","\n","torch.add(A, B)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([12.])"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9U9Wd_2oCLVR","executionInfo":{"status":"ok","timestamp":1653357472619,"user_tz":-540,"elapsed":7,"user":{"displayName":"최성철","userId":"16731672827766253258"}},"outputId":"249f60b1-8259-403f-fc59-ddf6f7c53ecd"},"source":["# 🦆You can use torch.add through the + operator!\n","\n","A + B"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([12.])"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kq9h3ucECtoe","executionInfo":{"status":"ok","timestamp":1653357472619,"user_tz":-540,"elapsed":5,"user":{"displayName":"최성철","userId":"16731672827766253258"}},"outputId":"41f22341-9811-49dc-bcbe-d835fcbdfba7"},"source":["# 🦆 When calculating, if any of the operand is entered as a tensor, the result comes out as a tensor!\n","A + 7"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([12.])"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"W-eAr6c7GEHl"},"source":["##### 💡 Calculating the four fundamental arithmetic operations\n","```python\n","🦆\n","(3 + 7) * 2 - 5 / 10 What is it?\n","Use the function to calculate without operator (+, -, *, /)!\n","```\n","\n","What name does each rule operation use for the torch?\n","- `+` : [torch.add](https://pytorch.org/docs/stable/generated/torch.add.html?highlight=add#torch.add)\n","- `-` : \n","- `*` : \n","- `/` : "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a-1cyVz1CiCK","executionInfo":{"status":"ok","timestamp":1654576069421,"user_tz":-540,"elapsed":4713,"user":{"displayName":"최성철","userId":"16731672827766253258"}},"outputId":"94eebf24-dc03-471d-fafa-e079287270bb"},"source":["import torch\n","\n","A = torch.Tensor([3])\n","B = torch.Tensor([7])\n","C = torch.Tensor([2])\n","D = torch.Tensor([5])\n","E = torch.Tensor([10])\n","\n","# Use the TODO : torch function to calculate (3 + 7) * 2 - 5 / 10!\n","# The answer should be 19.5!\n","\n","output1 = torch.add(A, B) # Use only one torch function per line!\n","output1 = torch.mul(output1, C) # Use only one torch function per line!\n","\n","output2 = torch.div(D, E) # Use only one torch function per line!\n","output = torch.sub(output1, output2)\n","\n","\n","# You do not need to modify the code below!\n","if output == 19.5:\n","    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","else:\n","    print(\"🦆 다시 도전해봐요!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["🎉🎉🎉 성공!!! 🎉🎉🎉\n"]}]},{"cell_type":"markdown","metadata":{"id":"m7w_YfK6HXQ9"},"source":["#### 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> 인덱싱 (Indexing)\n","> <font color='yellow'><b>[ Optional ]</b></font> For problems 🔥 can be very difficult If you don't understand just 🔥 Documentation, googling is allowed. It may take a lot of time due to its high level of difficulty, so I recommend it only for those who have time.\n","\n","``` python\n","🦆\n","I want to get only the value I want from the tensor, but I don't know what to do!\n","Is it similar to indexing a list in Python?\n","```\n","\n","- [Documentation main - PyTorch 공식 문서](https://pytorch.org/docs/stable/index.html)"]},{"cell_type":"markdown","metadata":{"id":"LZ0zV31lX6zN"},"source":["##### 💡 index_select\n","\n","\n","``` python\n","🦆\n","[[1 2]\n"," [3 4] I want to get [1 3] from a 2D tensor!\n","```\n","\n","- [torch.index_select - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.index_select.html?highlight=index#torch.index_select)\n","\n","🎁 **힌트** 🎁\n","- Want when you want to change in the shape of a tensor [torch.Tensor.view](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html?highlight=view#torch.Tensor.view)라는 함수를 사용하면 됩니다!\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wIDKrXzXZs07","executionInfo":{"status":"ok","timestamp":1654576386983,"user_tz":-540,"elapsed":435,"user":{"displayName":"최성철","userId":"16731672827766253258"}},"outputId":"932797a3-c94b-4559-85a9-b0b5e0a8e557"},"source":["import torch\n","\n","A = torch.Tensor([[1, 2],\n","                  [3, 4]])\n","\n","# TODO: Make [1, 3]!\n","\n","# # torch.Try using the index_select function!\n","output = A\n","output = torch.index_select(A, 1, torch.tensor([0]))\n","output = output.view(-1)\n","print(output)\n","# You do not need to modify the code below!\n","if torch.all(output == torch.Tensor([1, 3])):\n","    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","else:\n","    print(\"🦆 다시 도전해봐요!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 3.])\n","🎉🎉🎉 성공!!! 🎉🎉🎉\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Co8YFuVtaVZr","executionInfo":{"status":"ok","timestamp":1627655512170,"user_tz":-540,"elapsed":406,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"ca23c7ba-de52-4d78-a8a5-ef8bb2189a8c"},"source":["# Do it in a similar way to Python List Indexing!\n","output = A\n","\n","# You do not need to modify the code below!\n","if torch.all(output == torch.Tensor([1, 3])):\n","    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","else:\n","    print(\"🦆 다시 도전해봐요!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["🦆 다시 도전해봐요!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TwdiREr_YLEa"},"source":["##### 💡 Import diagonal elements from 2D sensor - 2D daughter\n","\n","``` python\n","🦆\n","[[1 2]\n"," [3 4] I want to make a 1D tensor by taking only diagonal elements from a 2D tensor\n","\n","I tried to do it through indexing, but somehow it didn't work!\n","Friend said, \"torch.He advised me to use the function \"gather\"!\n","```\n","- [torch.gather - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.gather.html#torch.gather)\n"]},{"cell_type":"code","source":["matrix"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BWUQu0LrcwZO","executionInfo":{"status":"ok","timestamp":1654576583842,"user_tz":-540,"elapsed":7,"user":{"displayName":"최성철","userId":"16731672827766253258"}},"outputId":"55ce9fcd-36c9-431a-8164-e391739fc8d9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.],\n","        [10., 11., 12., 13., 14., 15., 16., 17., 18., 19.],\n","        [20., 21., 22., 23., 24., 25., 26., 27., 28., 29.],\n","        [30., 31., 32., 33., 34., 35., 36., 37., 38., 39.],\n","        [40., 41., 42., 43., 44., 45., 46., 47., 48., 49.],\n","        [50., 51., 52., 53., 54., 55., 56., 57., 58., 59.],\n","        [60., 61., 62., 63., 64., 65., 66., 67., 68., 69.],\n","        [70., 71., 72., 73., 74., 75., 76., 77., 78., 79.],\n","        [80., 81., 82., 83., 84., 85., 86., 87., 88., 89.],\n","        [90., 91., 92., 93., 94., 95., 96., 97., 98., 99.]])"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kwx3LEqKbU9M","executionInfo":{"status":"ok","timestamp":1654576831826,"user_tz":-540,"elapsed":3,"user":{"displayName":"최성철","userId":"16731672827766253258"}},"outputId":"1bf2c1e2-ae58-4e8c-b114-aadd9e80f21a"},"source":["import torch\n","\n","A = torch.Tensor([[1, 2],\n","                  [3, 4]])\n","\n","# torch.Try using the gather function!\n","output = A\n","\n","output = torch.gather(A, 1, torch.tensor([[0],[1]]))\n","output = output.flatten()\n","\n","# You do not need to modify the code below!\n","if torch.all(output == torch.Tensor([1, 4])):\n","    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","else:\n","    print(\"🦆 다시 도전해봐요!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["🎉🎉🎉 성공!!! 🎉🎉🎉\n"]}]},{"cell_type":"markdown","metadata":{"id":"SHpq-zKFdQ8j"},"source":["##### 💡 🔥 <font color='yellow'><b>[ Optional ]</b></font> Import Diagonal Elements from 3D Sensor - 3D Gather 🔥\n","> It's a little difficult for PyTorch skilled people. Most of the tensors covered in PyTorch are 3D or more, so I recommend you to practice them when you have time.\n","\n","``` python\n","🦆\n","\n","I'm so happy to have successfully collected diagonal elements in 2D!\n","I'd like to apply it to 3D, is it possible?\n","\n","[[[1 2]\n","  [3 4]]\n"," [[5 6] \n","  [7 8] I want to make a two-dimensional tensor called \n","\n","  [[1 4]\n","   [5 8] by taking only diagonal elements from the three-dimensional tensor\n","\n","```\n","- [torch.gather - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.gather.html#torch.gather)\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N7_WCGcpdQ81","executionInfo":{"status":"ok","timestamp":1654577398703,"user_tz":-540,"elapsed":444,"user":{"displayName":"최성철","userId":"16731672827766253258"}},"outputId":"87725328-8bbf-4bc3-f187-4b391f593759"},"source":["import torch\n","\n","A = torch.Tensor([[[1, 2],\n","                   [3, 4]],\n","                  [[5, 6],\n","                   [7, 8]]])\n","\n","# torch.Try using the gather function!\n","output = A\n","\n","indexes = torch.tensor([\n","              [\n","               [0],[1]\n","               ],\n","              [\n","               [0],[1]\n","               ]\n","              ])\n","output = torch.gather(A, 2, indexes)\n","output = output.view(2, 2)\n","\n","# You do not need to modify the code below!\n","if torch.all(output == torch.Tensor([[1, 4], [5, 8]])):\n","    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","else:\n","    print(\"🦆 다시 도전해봐요!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["🎉🎉🎉 성공!!! 🎉🎉🎉\n"]}]},{"cell_type":"markdown","metadata":{"id":"VfmnV6cRuYf5"},"source":["##### 💡 🔥🔥🔥 <font color='yellow'><b>[ Optional ]</b></font>Collect diagonal elements from any size 3D sensor - 3D daughter 🔥🔥🔥\n","> It's also a challenge for PyTorch experienced people. It is also a problem that you encounter in the process of creating a model that can respond robustly to inputs of various sizes. You should be familiar with the behavior of the gather and write flexible, scalable code.\n","\n","``` python\n","🦆\n","So far, we've taken diagonal elements from inputs of a given size\n","Can a 3D tensor of any size take diagonal elements and make a 2D tensor as well?\n","```\n","- [torch.gather - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.gather.html#torch.gather)\n","\n","🎁 **힌트** 🎁\n","- to make the desired size of the [torch.Tensor.expand](https://pytorch.org/docs/stable/generated/torch.Tensor.expand.html?highlight=expand)is available!"]},{"cell_type":"code","metadata":{"id":"yg_byIzJxoPC"},"source":["import torch\n","\n","# TODO: Create a function that takes diagonal elements from a 3D sensor of any size and returns them in 2D!\n","def get_diag_element_3D(A):\n","    C, H, W = A.size()\n","    diag_size = min(H,W)\n","\n","    gather_index = torch.arange(diag_size).view(diag_size, -1).expand(\n","        C, diag_size, 1)\n","    output = torch.gather(A, 2, gather_index)\n","    output = output.view(C, diag_size)\n","\n","    return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7q9gz0d5rYiG","executionInfo":{"status":"ok","timestamp":1654578005128,"user_tz":-540,"elapsed":5,"user":{"displayName":"최성철","userId":"16731672827766253258"}},"outputId":"babda601-645d-4d44-813e-5d5adb065db7"},"source":["# TODO: Make a 3D sensor of your size and test it to see if it works properly!\n","C = 1\n","H = 2\n","W = 3\n","\n","# You do not need to modify the code below!\n","A = torch.tensor([i for i in range(1, C*H*W + 1)])\n","A = A.view(C, H, W)\n","\n","print(f\"원본 3D 행렬\\n{A}\")\n","print(\"-\" * 50)\n","\n","print(f\"대각선 요소를 모은 2D 행렬\")\n","get_diag_element_3D(A)\n","\n","# tensor([[1, 5]])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["원본 3D 행렬\n","tensor([[[1, 2, 3],\n","         [4, 5, 6]]])\n","--------------------------------------------------\n","대각선 요소를 모은 2D 행렬\n","1\n","2\n","3\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 5]])"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ORBb-HPcJnCg","executionInfo":{"status":"ok","timestamp":1627655570603,"user_tz":-540,"elapsed":248,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"76ce2d57-1429-4421-9f75-db02686221ac"},"source":["# You do not need to modify the code below!\n","A = torch.tensor([[[1]]])\n","\n","if torch.all(get_diag_element_3D(A) == torch.Tensor([[1]])):\n","    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","else:\n","    print(\"🦆 다시 도전해봐요!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["🎉🎉🎉 성공!!! 🎉🎉🎉\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pSbNIk3tyj8U","executionInfo":{"status":"ok","timestamp":1627655571758,"user_tz":-540,"elapsed":10,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"5e5d385c-9a1d-45f2-9f52-5493990747b8"},"source":["# You do not need to modify the code below!\n","A = torch.Tensor([[[1, 2],\n","                   [3, 4]],\n","                  [[5, 6],\n","                   [7, 8]]])\n","\n","if torch.all(get_diag_element_3D(A) == torch.Tensor([[1, 4],\n","                                                     [5, 8]])):\n","    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","else:\n","    print(\"🦆 다시 도전해봐요!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["🦆 다시 도전해봐요!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H3ewV_sBJ-nm","executionInfo":{"status":"error","timestamp":1627655573287,"user_tz":-540,"elapsed":258,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"95159470-f216-4819-ed98-b905b57e3acf"},"source":["# You do not need to modify the code below!\n","A = torch.Tensor([[[1, 2, 3],\n","                   [4, 5, 6]]])\n","\n","if torch.all(get_diag_element_3D(A) == torch.Tensor([[1, 5]])):\n","    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","else:\n","    print(\"🦆 다시 도전해봐요!\")"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-5690f10ee105>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                    [4, 5, 6]]])\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_diag_element_3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"🎉🎉🎉 성공!!! 🎉🎉🎉\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 2"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fueU_tOgIzDC","executionInfo":{"status":"error","timestamp":1627655616394,"user_tz":-540,"elapsed":259,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"29aae5d1-059c-458f-a6d2-c2eaed5e7b33"},"source":["# You do not need to modify the code below!\n","A = torch.tensor([[[ 1,  2,  3,  4,  5],\n","                   [ 6,  7,  8,  9, 10],\n","                   [11, 12, 13, 14, 15]],\n","          \n","                  [[16, 17, 18, 19, 20],\n","                   [21, 22, 23, 24, 25],\n","                   [26, 27, 28, 29, 30]]])\n","\n","if torch.all(get_diag_element_3D(A) == torch.Tensor([[ 1,  7, 13],\n","                                                     [16, 22, 28]])):\n","    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","else:\n","    print(\"🦆 다시 도전해봐요!\")"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-bcf1e4ed077e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m if torch.all(get_diag_element_3D(A) == torch.Tensor([[ 1,  7, 13],\n\u001b[0;32m---> 11\u001b[0;31m                                                      [16, 22, 28]])):\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"🎉🎉🎉 성공!!! 🎉🎉🎉\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (3) at non-singleton dimension 2"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1MKSgAWOJWvb","executionInfo":{"status":"error","timestamp":1627655622303,"user_tz":-540,"elapsed":253,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"85cd21c9-a615-489a-e194-8fbec5288582"},"source":["# You do not need to modify the code below!\n","A = torch.tensor([[[ 1,  2,  3],\n","                   [ 4,  5,  6],\n","                   [ 7,  8,  9],\n","                   [10, 11, 12],\n","                   [13, 14, 15]],\n","        \n","                  [[16, 17, 18],\n","                   [19, 20, 21],\n","                   [22, 23, 24],\n","                   [25, 26, 27],\n","                   [28, 29, 30]],\n","        \n","                  [[31, 32, 33],\n","                   [34, 35, 36],\n","                   [37, 38, 39],\n","                   [40, 41, 42],\n","                   [43, 44, 45]]])\n","\n","if torch.all(get_diag_element_3D(A) == torch.Tensor([[ 1,  5,  9],\n","                                                     [16, 20, 24],\n","                                                     [31, 35, 39]])):\n","    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","else:\n","    print(\"🦆 다시 도전해봐요!\")"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-669673b146fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m if torch.all(get_diag_element_3D(A) == torch.Tensor([[ 1,  5,  9],\n\u001b[1;32m     21\u001b[0m                                                      \u001b[0;34m[\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                                                      [31, 35, 39]])):\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"🎉🎉🎉 성공!!! 🎉🎉🎉\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (3) at non-singleton dimension 1"]}]},{"cell_type":"markdown","metadata":{"id":"6h_5Q9Xejktd"},"source":["### 🌓 Read Documentation\n","> Find the information you want in PyTorch documentation and use it without any problems! But we still don't know what PyTorch has to offer. The more you know about PyTorch's capabilities in creating custom models, the more you know, the more diverse and cooler you can create! That's why we're going to have a time to read Documentation carefully in this section!\n","\n","- 📖 <font color='gold' ><b>[ 읽기 ]</b></font> read torch document\n","- 📖 <font color='gold' ><b>[ 읽기 ]</b></font> Read torch.linalg documentation\n","- 📖 <font color='gold' ><b>[ 읽기 ]</b></font> Read torch.nn documentation\n","- 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> torch.nn `Linear Layers`\n","- ❓ <font color='red'><b>[ 퀴즈 ]</b></font> Linear vs LazyLinear"]},{"cell_type":"markdown","metadata":{"id":"Ybvq8tz4769-"},"source":["#### 📖 <font color='gold' ><b>[ 읽기 ]</b></font> Read torch documentation\n","``` python\n","🦆\n","I took a quick look at the documentation, and I found a torch file in the Python API table of contents\n","I think it's full of important and useful content!\n","\n","There are various functions that the developers worked hard on\n","I'd be really sad if it's not used because I don't know!\n","\n","Let's read it together!\n","```\n","\n","- [torch 문서 - PyTorch 공식 문서](https://pytorch.org/docs/stable/torch.html)"]},{"cell_type":"markdown","metadata":{"id":"5d8rq3BlRjmH"},"source":["##### 💌 Tensors\n","\n","``` python\n","🦆\n","I read the \"Tensors\" part first and organized it\n","I'll share how I read that part!\n","```\n","\n","- [Tensors - PyTorch 공식 문서](https://pytorch.org/docs/stable/torch.html#tensors)"]},{"cell_type":"markdown","metadata":{"id":"XOvQP1sYUfci"},"source":["``` python\n","🦆\n","I've been looking at the name \"Tensors\" and I've been trying to figure out if you're creating a data structure for the sensor\n","I think there are functions that can extract related characteristics!\n","\n","First, I read the Tensors section and saw what functions there were!\n","The data structure is based on function names such as \"is_tensor\" and \"is_storage\"\n","I think it's a function of checking!\n","```\n","\n","![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/torch%20-%20tensors.png?raw=true)"]},{"cell_type":"markdown","metadata":{"id":"_EYZfH4CX7tT"},"source":["``` python\n","🦆\n","I wanted to know more about the function \"is_tensor\" so I went in on the link!\n","After reading the explanation on the blue box,\n","It is correct to check if the sensor data structure is correct!\n","\n","There was an example in the red box below!\n","I thought it'd be easier to understand if I played the chords myself\n","I've implemented an example myself with wings!\n","```\n","- [torch.is_tensor - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.is_tensor.html#torch.is_tensor)\n","![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/torch%20is%20tensor.png?raw=true)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-up9L8HlYzmm","executionInfo":{"status":"ok","timestamp":1627279066714,"user_tz":-540,"elapsed":286,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"f10c02a1-fd32-4896-9ddd-c20b25349983"},"source":["import torch\n","\n","x = torch.tensor([1,2,3])\n","y = [1, 2, 3]\n","\n","# 🦆 It works so well! That's what I expected!\n","\n","torch.is_tensor(x), torch.is_tensor(y) "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(True, False)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L-pYoFx5bYcj","executionInfo":{"status":"ok","timestamp":1627279716336,"user_tz":-540,"elapsed":280,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"435704b0-f02c-4b2f-c0f3-20c85967b7f3"},"source":["# 🦆 I also used the function numel once! It's working well!\n","\n","torch.numel(x)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"6wP5qfTMUYxq"},"source":["``` python\n","🦆\n","When I scroll down, these are functions that belong to the Tensor\n","They categorized it into the following details!\n","- \"Creation Ops\"\n","- \"Indexing, Slicing, Joining, Mutating Ops\"\n","\n","So I'm going to make a new section and organize it instead of organizing it here\n","```\n","\n","![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/torch%20-%20tensors%20-%20ops.png?raw=true)\n"]},{"cell_type":"markdown","metadata":{"id":"jpXu3zuOcjzO"},"source":["##### 💌 Tensors - Creation Ops\n","\n","``` python\n","🦆\n","If it's part of Tensor, I want to organize it separately\n","It's divided into separate sections\n","```\n","- [Tensors - PyTorch 공식 문서](https://pytorch.org/docs/stable/torch.html#tensors)"]},{"cell_type":"markdown","metadata":{"id":"rJZJuicGdHwm"},"source":["``` python\n","🦆\n","이름을 보면 \"Tensors\"라는 자료구조를 만드는 함수들이 모여있겠죠?\n","저는 먼저 아래 그림에서 빨간 박스 친 부분을 유심히 읽어보았어요!\n","\"함수명\"과 우측에 \"함수에 대한 요약 설명\"을 읽어나갔죠!\n","```\n","\n","- ✅ 함수와 요약 설명을 가볍게 훑어보세요!\n","\n","![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/torch%20-%20tensors%20-%20creation%20ops.png?raw=true)"]},{"cell_type":"markdown","metadata":{"id":"5b6lTFnCjQwc"},"source":["```python\n","🦆\n","뭐든지 직접 손으로 쳐본게 더 이해가 잘가고 기억에 오래 남더라구요!\n","그래서 함수들을 쭉 둘러보고 3가지 함수의 예제를 구현해보았어요!\n","```\n","\n","- ✅ <font color='yellow'><b>[ Optional ]</b></font> 원하는 3개 함수를 골라서 예제 코드를 돌려보세요!\n","    - from_numpy\n","    - zeros\n","    - zeros_like\n","\n","\n","- [torch.from_numpy - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.from_numpy.html#torch.from_numpy)\n","- [torch.zeros - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.zeros.html#torch.zeros)\n","- [torch.zeros_like - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.zeros_like.html#torch.zeros_like)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vhp7vsgE8FY4","executionInfo":{"status":"ok","timestamp":1627282787999,"user_tz":-540,"elapsed":257,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"fd99ebdf-2516-4352-b58e-2ba07ea20829"},"source":["import torch\n","import numpy as np\n","\n","# 🦆 torch.from_numpy\n","a = np.array([1,2,3])\n","t = torch.from_numpy(a)\n","t"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1, 2, 3])"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1mzqAJDGm9Hd","executionInfo":{"status":"ok","timestamp":1627282760940,"user_tz":-540,"elapsed":249,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"281dfd46-d555-4003-e347-014947ca2c48"},"source":["# 🦆 torch.zeros\n","torch.zeros(2, 3)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0., 0., 0.],\n","        [0., 0., 0.]])"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BA2pv3pFiu3M","executionInfo":{"status":"ok","timestamp":1627282792076,"user_tz":-540,"elapsed":241,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"74f4478e-7b97-402e-bcd8-9134ee6d29f0"},"source":["# 🦆 torch.zeros_like\n","torch.zeros_like(t)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0, 0, 0])"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"yBmtQly_nqR7"},"source":["##### 💌 Tensors - Indexing, Slicing, Joining, Mutating Ops\n","\n","``` python\n","🦆\n","This is the last detail of the Tensor's item!\n","Indexing, slicing, and other important functions will be gathered!\n","```\n","\n","- [Tensors - PyTorch 공식 문서](https://pytorch.org/docs/stable/torch.html#tensors)"]},{"cell_type":"markdown","metadata":{"id":"h4iVxzyHnqR-"},"source":["``` python\n","🦆\n","As I read it, sometimes there are functions that don't have an example code!\n","In this case, I think I should read the description of the function more carefully and implement it!\n","```\n","\n","- ✅ Skim through functions and summary descriptions!\n","- ✅ <font color='yellow'><b>[ Optional ]</b></font> Choose the 3 functions you want and return the example code!\n","    - chunk\n","    - swapdims\n","    - zeros_like\n","\n","\n","- [torch.chunk - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.chunk.html#torch.chunk)\n","- [torch.swapdims - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.swapdims.html#torch.swapdims)\n","- [torch.Tensor.scatter_ - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_.html#torch.Tensor.scatter_)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nq9zOgoznqR_","executionInfo":{"status":"ok","timestamp":1627284609241,"user_tz":-540,"elapsed":270,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"eaba0257-5640-457f-eefb-9990929a5d09"},"source":["import torch\n","import numpy as np\n","\n","# 🦆 torch.chunk\n","t = torch.tensor([[1, 2, 3],\n","                  [4, 5, 6]])\n","\n","# 🦆 There is no example, but I read documentation and implemented it!\n","\n","print(torch.chunk(t, 2, 0))\n","print(torch.chunk(t, 2, 1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(tensor([[1, 2, 3]]), tensor([[4, 5, 6]]))\n","(tensor([[1, 2],\n","        [4, 5]]), tensor([[3],\n","        [6]]))\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t7Qy8zEPnqSA","executionInfo":{"status":"ok","timestamp":1627284746101,"user_tz":-540,"elapsed":514,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"68aa59ee-6161-4036-e260-c4f43b2f5c1c"},"source":["# 🦆 torch.swapdims\n","x = torch.tensor([[[0,1],[2,3]],[[4,5],[6,7]]])\n","x"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[0, 1],\n","         [2, 3]],\n","\n","        [[4, 5],\n","         [6, 7]]])"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8o6mHeHeutTh","executionInfo":{"status":"ok","timestamp":1627284766848,"user_tz":-540,"elapsed":270,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"e3b6ece2-5ec6-41d8-99c8-1f6527fed246"},"source":["torch.swapdims(x, 0, 1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[0, 1],\n","         [4, 5]],\n","\n","        [[2, 3],\n","         [6, 7]]])"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8TBo37wDu4xW","executionInfo":{"status":"ok","timestamp":1627284966981,"user_tz":-540,"elapsed":359,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"6b681245-e9e0-4a22-961a-6e36eb701092"},"source":["torch.swapdims(x, 0, 2)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[0, 4],\n","         [2, 6]],\n","\n","        [[1, 5],\n","         [3, 7]]])"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M08dZW2fnqSB","executionInfo":{"status":"ok","timestamp":1627285134269,"user_tz":-540,"elapsed":266,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"7cee4df5-0a32-4a84-f77e-a8dd220ca98f"},"source":["# 🦆 torch.Tensor.scatter_\n","src = torch.arange(1, 11).reshape((2, 5))\n","src"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1,  2,  3,  4,  5],\n","        [ 6,  7,  8,  9, 10]])"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z6WstSp-wLU4","executionInfo":{"status":"ok","timestamp":1627285299924,"user_tz":-540,"elapsed":272,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"71193973-859a-4f3b-cb59-3948b54cb485"},"source":["# 🦆 It feels similar to the gather we studied together!\n","\n","index = torch.tensor([[0, 1, 2, 0]])\n","torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 0, 0, 4, 0],\n","        [0, 2, 0, 0, 0],\n","        [0, 0, 3, 0, 0]])"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R0yIEAw-xAdV","executionInfo":{"status":"ok","timestamp":1627285417032,"user_tz":-540,"elapsed":279,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"ec91babc-9a61-4e1c-fbd9-9046fc7f907b"},"source":["index = torch.tensor([[0, 1, 2], [0, 1, 4]])\n","torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 2, 3, 0, 0],\n","        [6, 7, 0, 0, 8],\n","        [0, 0, 0, 0, 0]])"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"jPvOek5YxfRg"},"source":["##### 💌 Random sampling\n","\n","``` python\n","🦆\n","I think random functions can be used in various places such as initialization and sampling!\n","If you pay attention to it as much as it's useful, I think it'll be used well later on!\n","```\n","\n","- [Random sampling - PyTorch 공식 문서](https://pytorch.org/docs/stable/torch.html#random-sampling)"]},{"cell_type":"markdown","metadata":{"id":"LAcT0HckxfR7"},"source":["- ✅ Skim through functions and summary descriptions!\n","- ✅ <font color='yellow'><b>[ Optional ]</b></font>hoose 3 functions you want and return the example code!\n","    - \n","    - \n","    - \n"]},{"cell_type":"markdown","metadata":{"id":"VBC_HD024zT7"},"source":["##### 💌 Math operations - Pointwise Ops\n","\n","``` python\n","🦆\n","There are various functions related to computation!\n","They must be functions that process with pointwise!\n","```\n","\n","- [Math operations - PyTorch 공식 문서](https://pytorch.org/docs/stable/torch.html#math-operations)\n","- [Pointwise - Wikipedia](https://en.wikipedia.org/wiki/Pointwise)"]},{"cell_type":"markdown","metadata":{"id":"YQDWkg-S4zT9"},"source":["- ✅ Skim through functions and summary descriptions!\n","- ✅ <font color='yellow'><b>[ Optional ]</b></font> Choose 3 functions and return the example code!\n","    - \n","    - \n","    - "]},{"cell_type":"markdown","metadata":{"id":"zLFA5jeb7dcB"},"source":["##### 💌 Math operations - Reduction Ops\n","\n","``` python\n","🦆\n","The functions only take certain values from the tensor, depending on the conditions\n","Reduce the size of the given tensor, such as reducing the size through an operation\n","I think it's named reduction because it's printed out!\n","```\n","\n","- [Math operations - PyTorch 공식 문서](https://pytorch.org/docs/stable/torch.html#math-operations)"]},{"cell_type":"markdown","metadata":{"id":"poy8CCOC7dcC"},"source":["- ✅ Skim through functions and summary descriptions!\n","- ✅ <font color='yellow'><b>[ Optional ]</b></font> Choose 3 functions and return the example code!\n","    - \n","    - \n","    - "]},{"cell_type":"markdown","metadata":{"id":"IJNyfmll_h_o"},"source":["##### 💌 Math operations - Comparison Ops\n","\n","``` python\n","🦆\n","It looks like functions that involve these comparisons, small or large!\n","I think it'll be as useful as an ifelse door!\n","```\n","\n","- [Math operations - PyTorch 공식 문서](https://pytorch.org/docs/stable/torch.html#math-operations)"]},{"cell_type":"markdown","metadata":{"id":"rOStUYzm_h_p"},"source":["- ✅ Skim through functions and summary descriptions!\n","- ✅ <font color='yellow'><b>[ Optional ]</b></font> Choose 3 functions and return the example code!\n","    - \n","    - \n","    - "]},{"cell_type":"markdown","metadata":{"id":"qrEsHFT2FRDj"},"source":["##### 💌 Math operations - Other Operations\n","\n","``` python\n","🦆\n","Specific details as hard to functions and must have it!\n","Some useful function that stands out!\n","Tensor useful for the calculation of unit and placement \"einsum\", in particular.\n","Do you remember for some reason, I will be custom, if you happened to be used when creating a model!\n","```\n","\n","- [Math operations - PyTorch 공식 문서](https://pytorch.org/docs/stable/torch.html#math-operations)"]},{"cell_type":"markdown","metadata":{"id":"O9dwBl4SFRDk"},"source":["- ✅ Skim through functions and summary descriptions!\n","- ✅ <font color='yellow'><b>[ Optional ]</b></font> Choose 3 functions and return the example code!\n","    - \n","    - \n","    - "]},{"cell_type":"markdown","metadata":{"id":"8r1QkKGGJobo"},"source":["##### 💌 Math operations - BLAS and LAPACK Operations\n","\n","``` python\n","🦆\n","Surprised by the threatening name? I was surprised, too!\n","\n","- - \"BLAS\" - Basic Linear Algebra Subprograms\n","- - \"LAPACK\" - Linear Algebra PACKage\n","\n","I looked it up and it's all related to Linear Algebra!\n","When I look at the function, I can feel the familiarity!\n","```\n","\n","- [Math operations - PyTorch 공식 문서](https://pytorch.org/docs/stable/torch.html#math-operations)\n","- [BLAS - netlib](http://www.netlib.org/blas/)\n","- [LAPACK - netlib](http://www.netlib.org/lapack/)"]},{"cell_type":"markdown","metadata":{"id":"3ZVGkAp5Jobp"},"source":["- ✅ Skim through functions and summary descriptions!\n","- ✅ <font color='yellow'><b>[ Optional ]</b></font> Choose 3 functions and return the example code!\n","    - \n","    - \n","    - "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qbzHU6WTJobq","executionInfo":{"status":"ok","timestamp":1627303461540,"user_tz":-540,"elapsed":4393,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"b120dcf4-4f10-4005-9d29-65e80972961d"},"source":["import torch\n","\n","M = torch.randn(2, 3)\n","mat1 = torch.randn(2, 3)\n","mat2 = torch.randn(3, 3)\n","torch.addmm(M, mat1, mat2)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.2715, -0.1265, -1.1123],\n","        [ 1.0081,  0.3057,  0.7136]])"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uRk9bcnqJobr","executionInfo":{"status":"ok","timestamp":1627303859093,"user_tz":-540,"elapsed":405,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"eb6b9287-c99a-4a7b-d719-d17de377f644"},"source":["a = torch.eye(10)\n","torch.matrix_rank(a)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: torch.matrix_rank is deprecated in favor of torch.linalg.matrix_rankand will be removed in a future PyTorch release. The parameter 'symmetric' was renamed in torch.linalg.matrix_rank to 'hermitian'. (Triggered internally at  /pytorch/aten/src/ATen/native/LinearAlgebra.cpp:438.)\n","  \n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["tensor(10)"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g5GegxahJobr","executionInfo":{"status":"ok","timestamp":1627303889586,"user_tz":-540,"elapsed":299,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"39756d58-4f11-402f-8a5c-2b40e05c52d0"},"source":["b = torch.eye(10)\n","b[0, 0] = 0\n","torch.matrix_rank(b)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(9)"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7_b9Xu6qJobs","executionInfo":{"status":"ok","timestamp":1627303980226,"user_tz":-540,"elapsed":270,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"ecf9704e-73ea-4d45-901a-e0f06b0513e3"},"source":["a = torch.tensor([[12., -51, 4],\n","                  [6, 167, -68],\n","                  [-4, 24, -41]])\n","q, r = torch.qr(a)\n","q"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.8571,  0.3943,  0.3314],\n","        [-0.4286, -0.9029, -0.0343],\n","        [ 0.2857, -0.1714,  0.9429]])"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W5mBhSmmJobs","executionInfo":{"status":"ok","timestamp":1627303981674,"user_tz":-540,"elapsed":266,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"ddbd5f95-6503-45d4-ccbb-d2523d9c4f7a"},"source":["r"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ -14.0000,  -21.0000,   14.0000],\n","        [   0.0000, -175.0000,   70.0000],\n","        [   0.0000,    0.0000,  -35.0000]])"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e9SbUGKmJobs","executionInfo":{"status":"ok","timestamp":1627303988522,"user_tz":-540,"elapsed":287,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"593ac454-8315-497b-d5b5-f770c0bf1389"},"source":["torch.mm(q, r).round()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 12., -51.,   4.],\n","        [  6., 167., -68.],\n","        [ -4.,  24., -41.]])"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C_2T-Q3EJobt","executionInfo":{"status":"ok","timestamp":1627304013193,"user_tz":-540,"elapsed":371,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"248583c8-600a-4c8d-f67e-b3f05b46d210"},"source":["torch.allclose(torch.matmul(q, r), a)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"GGZDh_Tw4tpS"},"source":["#### 📖 <font color='gold' ><b>[ 읽기 ]</b></font> Read torch.linalg documentation\n","``` python\n","🦆\n","The functions related to linear algebra that I saw while reading the torch document,\n","It's newly organized as \"torch.linalg\" and it's a song that's part of \"torch\"\n","Linear algebraic functions seem to have been degraded!\n","\n","The directory has been moved, and the function name already feels familiar! Isn't it?\n","```\n","\n","- [torch.linalg 문서 - PyTorch 공식 문서](https://pytorch.org/docs/stable/linalg.html#)"]},{"cell_type":"markdown","metadata":{"id":"tOg5zeq46J0A"},"source":["- ✅ Check sub contents of torch.linalg \n","    - Matrix Properties\n","    - Decompositions\n","    - Solvers\n","    - Inverses\n","    - Matrix Products\n","    - Tensor Operations\n","    - Experimental Functions\n","- ✅ Look through each sub-table of contents to see which functions belong!\n","    - ex) Matrix Properties에는 `norm`, `vector_norm` 등이 있다\n","    - ex) Decompositions에는 `cholesky`, `qr`, `svd` 등이 있다\n","    - ex) Inverses에는 `inv`, `pinv` 2개의 함수가 있다"]},{"cell_type":"markdown","metadata":{"id":"HXUIf4hw8R_A"},"source":["#### 📖 <font color='gold' ><b>[ 읽기 ]</b></font> Read torch.nn documenrtation\n","``` python\n","🦆\n","The description says \"basic building block\" to make a graph!\n","\n","If you use the various functions that we've identified so far,\n","You can make a basic building block here, but it takes time\n","PyTorch pre-made it and said, \"torch.I think it's tied up with \"nn\"!\n","\n","If you use the blocks provided here well, I think you can make a deep learning model called a graph!\n","\n","It looks very important, but it has a lot of content!\n","You can't read all this, so just look through it!\n","It may seem unfamiliar and difficult now, but you'll get used to it gradually!\n","```\n","\n","- [torch.nn 문서 - PyTorch 공식 문서](https://pytorch.org/docs/stable/nn.html)"]},{"cell_type":"markdown","metadata":{"id":"MQjpdQWB8R_S"},"source":["- ✅ torch.Take a look at the sub-table of nn!\n","- ✅ Explore which layers or functions belong to each sub-table of contents!\n"]},{"cell_type":"markdown","metadata":{"id":"R68OFoe8BzbF"},"source":["#### 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> torch.nn `Linear Layers`\n","\n","``` python\n","🦆\n","Be lightly rubbed for one or two, but it's still trying to be read only directly, I want to try the example!\n","Who frequently appear when you study dimneoning y officially do you remember? = + b wx\n","The linear transformation for a connecting to \"a nn linear\".\n","\"linear layers\" item for a moment as look at it!\n","```\n","\n","- [torch.nn Linear Layers - PyTorch 공식 문서](https://pytorch.org/docs/stable/nn.html#linear-layers)"]},{"cell_type":"markdown","metadata":{"id":"rZmymVenGzXd"},"source":["##### 💡 nn.Linear\n","\n","\n","``` python\n","🦆\n","I have a hunch that I'll run into this \"nn.Linear\" a lot in the future!\n","\n","```\n","\n","- [torch.nn.Linear - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)\n","\n","🎁 **힌트** 🎁\n","- PyTorch has a function that returns the sensor size (or shape)! What is the size in English?\n"]},{"cell_type":"code","metadata":{"id":"tjHTIZdrGzXd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654579619461,"user_tz":-540,"elapsed":9,"user":{"displayName":"최성철","userId":"16731672827766253258"}},"outputId":"603c4f46-53b6-4e44-c0c2-b393e4ce8585"},"source":["import torch\n","from torch import nn\n","\n","X = torch.Tensor([[1, 2],\n","                  [3, 4]])\n","\n","# TODO : The size of the sensor X is (2, 2)\n","#         nn.Use Linear to resize to (2, 5) and print this size!\n","\n","linear = nn.Linear(2, 5)\n","output = linear(X)\n","output"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.3164,  0.5765,  2.0986,  0.2382,  0.6197],\n","        [ 0.5824, -0.0308,  4.1102, -0.2014,  0.6886]],\n","       grad_fn=<AddmmBackward0>)"]},"metadata":{},"execution_count":41}]},{"cell_type":"markdown","metadata":{"id":"eU_nhb1vKTi-"},"source":["##### 💡 nn.Identity\n","> Believe it or not, this layer is also useful. However, you don't need to know where to use this layer because you rarely use it when you're just learning deep learning. However, I leave a link for those who are curious.\n","\n","``` python\n","🦆\n","What the hell is \"nn.Identity\"?\n","The input and output are the same, so why did they make it?\n","But... Try it!\n","```\n","\n","- [torch.nn.Identity - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Identity.html#torch.nn.Identity)\n","\n","**✨ 유용한 자료 ✨**\n","- [What is the use of nn.Identity? - PyTorch Forum](https://discuss.pytorch.org/t/what-is-the-use-of-nn-identity/51781)\n","- [What is the idea behind using nn.Identity for residual learning? - Stack Overflow](https://stackoverflow.com/questions/64229717/what-is-the-idea-behind-using-nn-identity-for-residual-learning)"]},{"cell_type":"code","metadata":{"id":"Om5zRqyvKTjA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654579946784,"user_tz":-540,"elapsed":403,"user":{"displayName":"최성철","userId":"16731672827766253258"}},"outputId":"4614fb65-60b3-4d3b-8000-4a80ca1bf574"},"source":["import torch\n","from torch import nn\n","\n","X = torch.Tensor([[1, 2],\n","                  [3, 4]])\n","\n","# TODO : nn identity x the input came after output value is equal and x!\n","identity = nn.Identity()\n","identity(X)\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 2.],\n","        [3., 4.]])"]},"metadata":{},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"ZRWBmAYkOYgy"},"source":["#### ❓ <font color='red'><b>[ 퀴즈 ]</b></font> Linear vs LazyLinear\n","``` python\n","🦆\n","I was just trying to pass by, but it bothers me!\n","What`s the difference between Linear and Lazy Linear?!\n","```\n","\n","- [torch.nn.Linear - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)\n","- [torch.nn.LazyLinear - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.LazyLinear.html#torch.nn.LazyLinear)"]},{"cell_type":"markdown","metadata":{"id":"SIrfhKtCOYg6"},"source":["```python\n","😂\n","# TODO :  Please read the document and write down the answers freely\n","\n","```"]},{"cell_type":"markdown","metadata":{"id":"PNriTnyfdI0-"},"source":["### 🎉🎉🎉 Documentation complete! 🎉🎉🎉\n","\n","```python\n","\n","The documentation chapter was harder than you thought, right?<br>\n","Congratulations on successfully finishing the show even though it was not a small amount! 🎉<br> It's never easy.\n","\n","You are now ready to take advantage of Documentation.<br>\n","Now it's time to deal with the content related to our original purpose of modeling.<br>"]},{"cell_type":"markdown","metadata":{"id":"EYHm2O2t6Usd"},"source":["## ⭐ nn.Module class for custom model creation\n","\n","\n","```\n","💡 We will use the various functions provided \n","by the PyTorch library and nn.Module \n","to create and analyze models!\n","```\n","\n","Now that we've learned how to find and utilize the various features in Documentation, it's time to combine the features that PyTorch provides to create a great model. It would be messy if you simply listed the functions to make a model, right? So PyTorch brings these series of functions together and gives us a class to abstract them into one model.\n","\n","\n","```\n","💡 nn.Module\n","```\n","- [torch.nn.Module - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)\n","\n","The 'nn.Module' class acts as a box that brings together multiple functions.<br>\n","The box 'nn.Module' is another 'nn.Module' box can also be included!<br>\n","Depending on how you use it, \"nnn.The 'Module' box has a different meaning.\n","\n","- If the 'nn.Module' box is filled with 'functions', 'basic building block'\n","- In the box 'nn.Module', the 'basic building block' is called 'nn.'Deep learning model' if full of Module's\n","- In a box called 'nn.Module', the 'Deep Learning Model' 'nn.If you have a lot of Module's, it's a bigger deep learning model\n","\n","\" nn module ' how to use this just an empty that lights up and plays is fully the system architects will!<br>\n","' functional ' and ' basic building block of the ' model ' and ' dimneoning and at random and <br> a wall.\n","' functional ' is ' functional ' with \" the ` block block ' hierarchical with a wall with a number!\n","\n","We are here, nnModule \" Using the models manufactured and analyzed how models are configured at will!<br>\n","Additionally, custom models that can be useful in the function will have a look at some of the ` module, nn!\n","\n","\n","- ☄️ nn.Module : Implementation model\n","- ☄️ nn.Module : analyze model\n","- ☄️ nn.Module : something that helps you\n"]},{"cell_type":"markdown","metadata":{"id":"yXCog9jT_MJt"},"source":["### ☄️ nn.Module Implementation model\n","> After understanding what nn.Module is, we will have time to practice various ways of making models using it and to understand the important concepts in making custom models\n","\n","\n","- 📖 <font color='gold' ><b>[ 읽기 ]</b></font> torch.nn.Module 문서 읽기\n","- 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> 1 + 2\n","- 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> Container\n","- ❓ <font color='red'><b>[ 퀴즈 ]</b></font> Python List vs PyTorch ModuleList\n","- 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> a conditional statement\n","- 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> Module들의 흐름 느껴보기\n","- 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> Parameter\n","- ❓ <font color='red'><b>[ 퀴즈 ]</b></font> Tensor vs Parameter\n","- 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> Buffer"]},{"cell_type":"markdown","metadata":{"id":"mgJ38Rsiy2Tc"},"source":["#### 📖 <font color='gold' ><b>[ 읽기 ]</b></font> torch.nn.Module Read Document\n","\n","\n","- [Documentation main - PyTorch 공식 문서](https://pytorch.org/docs/stable/index.html)"]},{"cell_type":"markdown","metadata":{"id":"IoDjvw97y2Tr"},"source":["- ✅ Search for nn.Module in Documentation and find it!\n","- ✅ Read a description of the document, nn module!\n","\n","    - ![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/nn.Module.png?raw=true)\n","- ✅ 41 / 5000발음듣기복사하기필기인식기번역하기자동완성자동완성\t\n","영어열기/닫기 아이콘\n","Take a quick look at the names and descriptions of the methods inside the nn.Module!\n","```\n","🔔 It's not a time to memorize or understand!\n","If you can't see the explanation and it's awkward, it's very normal\n","You don't have to force yourself to read it! If you can't see it, just pass by!\n","As you study, you will get used to it\n","Just look at it lightly and see if there's something like this!\n","```\n","    - add_module\n","    - apply\n","    - bfloat16\n","    - buffers\n","    - children\n","    - cpu\n","    - cuda\n","    - double\n","    - dump_patches\n","    - eval\n","    - extra_repr\n","    - float\n","    - forward\n","    - get_buffer\n","    - get_parameter\n","    - get_submodule\n","    - half\n","    - load_state_dict\n","    - modules\n","    - named_buffers\n","    - named_children\n","    - named_modules\n","    - named_parameters\n","    - parameters\n","    - register_backward_hook\n","    - register_buffer\n","    - register_forward_hook\n","    - register_forward_pre_hook\n","    - register_full_backward_hook\n","    - register_parameter\n","    - requires_grad_\n","    - share_memory\n","    - state_dict\n","    - to\n","    - to_empty\n","    - train\n","    - type\n","    - xpu\n","    - zero_grad"]},{"cell_type":"markdown","metadata":{"id":"5OhWyjstxvUt"},"source":["#### 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> 1 + 2\n","\n","``` python\n","🦆\n","While reading the documentation, I'll use \"torch.add\"\n","Do you remember calculating the four rules?\n","\n","This time, let's make a model that uses \"nn.Module\" to do a plus operation!\n","```\n","\n","- [Documentation main - PyTorch 공식 문서](https://pytorch.org/docs/stable/index.html)\n","- [torch.add - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.add.html?highlight=add#torch.add)"]},{"cell_type":"code","metadata":{"id":"lF5CCXcgxjWD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654580077249,"user_tz":-540,"elapsed":10,"user":{"displayName":"최성철","userId":"16731672827766253258"}},"outputId":"4a21ceed-2a5a-424b-cd24-f4ca24c3740f"},"source":["import torch\n","from torch import nn\n","\n","# TODO: Complete the Add model!\n","class Add(nn.Module):\n","    def __init__(self):\n","        # TODO :  There is a super related code that must be entered in the init process\n","        super().__init__()\n","\n","    def forward(self, x1, x2):\n","        output = torch.add(x1, x2)\n","        return output\n","        # TODO : Please do the addition operation by using functions, torch.add\n","        pass\n","\n","\n","# You do not need to modify the code below!\n","x1 = torch.tensor([1])\n","x2 = torch.tensor([2])\n","\n","add = Add()\n","output = add(x1, x2)\n","\n","if output == 3:\n","    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","else:\n","    print(\"🦆 다시 도전해봐요!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["🎉🎉🎉 성공!!! 🎉🎉🎉\n"]}]},{"cell_type":"markdown","metadata":{"id":"ZfhwgR6kYy6i"},"source":["``` python\n","🦆\n","Why is it like that to do init through super?\n","\n","Reading the text on the link below, I think I'm solving some of the questions!\n","```\n","\n","**✨ 유용한 자료 ✨**\n","- [Why is the super constructor necessary in PyTorch custom modules? - Stack Overflow](https://stackoverflow.com/questions/63058355/why-is-the-super-constructor-necessary-in-pytorch-custom-modules)"]},{"cell_type":"markdown","metadata":{"id":"MpJ51jOZL1pm"},"source":["#### 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> Container\n","\n","``` python\n","🦆\n","We successfully made the module we wanted!\n","I don't know if it's half the start, but it's definitely a model!\n","\n","I want to use modules that are made like this together, how do I do it?\n","Should I keep the modules on Python's list?\n","\n","Oh! I found it!\n","I looked up Documentation and found out that the related functions\n","It's included in the Container entry in \"torch.nn\"!\n","```\n","\n","- [Documentation main - PyTorch 공식 문서](https://pytorch.org/docs/stable/index.html)\n","- [Containers  - PyTorch 공식 문서](https://pytorch.org/docs/stable/nn.html#containers)"]},{"cell_type":"markdown","metadata":{"id":"6a_OSRXMgc8j"},"source":["##### 💡 torch.nn.Sequential\n","\n","``` python\n","🦆\n","When you want to combine modules into one and run them sequentially\n","torch.nn.It's using Sequential! Let's make it together!\n","```\n","\n","- [torch.nn.Sequential - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential)"]},{"cell_type":"code","metadata":{"id":"ZAzm120dL1p4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654580264419,"user_tz":-540,"elapsed":360,"user":{"displayName":"최성철","userId":"16731672827766253258"}},"outputId":"1f1ab517-94ab-4cc5-ef95-4649de32bb44"},"source":["import torch\n","from torch import nn\n","\n","# TODO : Read and understand the following modules!\n","class Add(nn.Module):\n","    def __init__(self, value):\n","        super().__init__()\n","        self.value = value\n","\n","    def forward(self, x):\n","        return x + self.value\n","\n","# TODO : Module and nn above.Using Sequential,\n","#        Given an input of x, create a model that processes the following operations!\n","#        y = x + 3 + 2 + 5\n","calculator = nn.Sequential(Add(3), Add(2), Add(5))\n","\n","\n","# You do not need to modify the code below!\n","x = torch.tensor([1])\n","\n","output = calculator(x)\n","print(output)\n","if output == 11:\n","    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","else:\n","    print(\"🦆 다시 도전해봐요!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([11])\n","🎉🎉🎉 성공!!! 🎉🎉🎉\n"]}]},{"cell_type":"markdown","metadata":{"id":"a-Zs6pnh1925"},"source":["##### 💡 torch.nn.ModuleList\n","\n","``` python\n","🦆\n","torch.nn.Sequential performs the modules tied up one by one\n","It looks good to bring together functions that have a fixed order of execution!\n","\n","But like Python's list, I'll just keep it together, and then I'll just keep what I want\n","To write through indexing, torch.Why don't we write nn.ModuleList?\n","```\n","\n","- [torch.nn.ModuleList - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#torch.nn.ModuleList)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7D3cK6pS193J","executionInfo":{"status":"ok","timestamp":1654580470594,"user_tz":-540,"elapsed":387,"user":{"displayName":"최성철","userId":"16731672827766253258"}},"outputId":"1af71699-a9f0-495e-9dd8-d443bf1d24b9"},"source":["import torch\n","from torch import nn\n","\n","# TODO : Read and understand the following modules!\n","\n","class Add(nn.Module):\n","    def __init__(self, value):\n","        super().__init__()\n","        self.value = value\n","\n","    def forward(self, x):\n","        return x + self.value\n","\n","\n","# TODO : Complete the Calculator Model!\n","\n","class Calculator(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.add_list = nn.ModuleList([Add(2), Add(3), Add(5)])\n","\n","    def forward(self, x):\n","        # TODO : self.add_list에 담긴 모듈들을 이용하여서\n","        #        \n","        # y = ((x + 3) + 2) + 5 의 연산을 구현하세요!\n","        x = self.add_list[1](x)\n","        x = self.add_list[0](x)\n","        x = self.add_list[2](x)\n","        \n","        return x\n","\n","\n","# You do not need to modify the code below!\n","x = torch.tensor([1])\n","\n","calculator = Calculator()\n","output = calculator(x)\n","\n","if output == 11:\n","    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","else:\n","    print(\"🦆 다시 도전해봐요!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["🎉🎉🎉 성공!!! 🎉🎉🎉\n"]}]},{"cell_type":"markdown","metadata":{"id":"XLOhs8I56dYA"},"source":["##### 💡 torch.nn.ModuleDict\n","\n","``` python\n","🦆\n","torch.nn.ModuleLists are really convenient!\n","But if the size of the modules on the list gets really big,\n","I think it'll be really hard to find the module you want with indexing in the future!\n","\n","If you store a particular module using the key value like Python's dict,\n","Wouldn't it be easier to bring the module you want later?\n","I happened to get a torch for PyTorch.There's an nn.ModuleDict! Let's write it together!\n","```\n","\n","- [torch.nn.ModuleDict - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"suYi2pjj6dYK","executionInfo":{"status":"ok","timestamp":1627656147851,"user_tz":-540,"elapsed":245,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"74e3ae0b-8ece-4717-92a8-5d37ffc15b5e"},"source":["import torch\n","from torch import nn\n","\n","# TODO : Read and understand the following modules!\n","\n","class Add(nn.Module):\n","    def __init__(self, value):\n","        super().__init__()\n","        self.value = value\n","\n","    def forward(self, x):\n","        return x + self.value\n","\n","\n","# TODO : Complete the Calculator Model!\n","class Calculator(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.add_dict = nn.ModuleDict({'add2': Add(2),\n","                                       'add3': Add(3),\n","                                       'add5': Add(5)})\n","\n","    def forward(self, x):\n","        # TODO : self.add_dict에 담긴 모듈들을 이용하여서\n","        #        y = ((x + 3) + 2) + 5 의 연산을 구현하세요!\n","        x = self.add_dict['add3'](x)\n","        x = self.add_dict['add2'](x)\n","        x = self.add_dict['add5'](x)\n","        \n","        return x\n","\n","\n","#  You do not need to modify the code below!\n","x = torch.tensor([1])\n","\n","calculator = Calculator()\n","output = calculator(x)\n","\n","if output == 11:\n","    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","else:\n","    print(\"🦆 다시 도전해봐요!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["🦆 다시 도전해봐요!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CgV9Ntk38ieo"},"source":["#### ❓ <font color='red'><b>[ 퀴즈 ]</b></font> Python List vs PyTorch ModuleList\n","``` python\n","🦆\n","But now that I think about it, there's a list on Python, too\n","Did PyTorch make the ModuleList separately?\n","\n","I wonder why!\n","```\n","\n","- [torch.nn.ModuleList - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#torch.nn.ModuleList)\n","\n","🎁 **힌트** 🎁\n","- You can get a hint by executing the code written below!"]},{"cell_type":"code","metadata":{"id":"p0X4Bi7E9bjz"},"source":["# You do not need to modify the code below!\n","class Add(nn.Module):\n","    def __init__(self, value):\n","        super().__init__()\n","        self.value = value\n","\n","    def forward(self, x):\n","        return x + self.value\n","\n","\n","class PythonList(nn.Module):\n","    \"\"\"Python List\"\"\"\n","    def __init__(self):\n","        super().__init__()\n","\n","        # Python List\n","        self.add_list = [Add(2), Add(3), Add(5)]\n","\n","    def forward(self, x):\n","        x = self.add_list[1](x)\n","        x = self.add_list[0](x)\n","        x = self.add_list[2](x)\n","        \n","        return x\n","\n","class PyTorchList(nn.Module):\n","    \"\"\"PyTorch List\"\"\"\n","    def __init__(self):\n","        super().__init__()\n","\n","        # Pytorch ModuleList\n","        self.add_list = nn.ModuleList([Add(2), Add(3), Add(5)])\n","\n","    def forward(self, x):\n","        x = self.add_list[1](x)\n","        x = self.add_list[0](x)\n","        x = self.add_list[2](x)\n","        \n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wcZcR67F_MbE","executionInfo":{"status":"ok","timestamp":1627377103209,"user_tz":-540,"elapsed":6,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"44cbf0d1-701e-4791-a362-90adc75275c0"},"source":["# You do not need to modify the code below!\n","x = torch.tensor([1])\n","\n","python_list = PythonList()\n","pytorch_list = PyTorchList()\n","\n","# Functional operation is the same!\n","\n","print(python_list(x), pytorch_list(x))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([11]) tensor([11])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o8qgY2EK_lMb","executionInfo":{"status":"ok","timestamp":1627377103210,"user_tz":-540,"elapsed":5,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"ca84b04f-e6c9-493c-8e09-c4a43d6c97dd"},"source":["# Python list their collection module with vanished into thin air!\n","\n","python_list"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PythonList()"]},"metadata":{"tags":[]},"execution_count":82}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I-eFwdj7ABMH","executionInfo":{"status":"ok","timestamp":1627377103210,"user_tz":-540,"elapsed":4,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"bd6f2454-d9a6-42e3-bf3d-bee644d9e82e"},"source":["# But pytorch modulelist were salty! turned up in a collection module with!\n","pytorch_list"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PyTorchList(\n","  (add_list): ModuleList(\n","    (0): Add()\n","    (1): Add()\n","    (2): Add()\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":83}]},{"cell_type":"markdown","metadata":{"id":"8EZ7R-Js8ie5"},"source":["```python\n","😌\n","# TODO : It's a question that's right and wrong. Please read the document and write down the answers freely\n","\n","\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"6ARH3kXTPKEq"},"source":["#### 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> a conditional statement\n","\n","``` python\n","🦆\n","It's harder than I thought to learn so many things at once💦\n","I'm sorry! I usually use human language, but if it's hard, I sometimes get a duck!\n","\n","When creating a model, PyTorch uses dynamic calculation graphs\n","I heard that it has the advantage of being able to use conditional statements such as if/else easily!\n","\n","I think it's really cool! Let's write it together!\n","```\n","\n","- [Documentation main - PyTorch 공식 문서](https://pytorch.org/docs/stable/index.html)\n","\n","**✨ useful materials ✨**\n","- [Can someone explain the use of a dynamic graph? - Reddit](https://www.reddit.com/r/pytorch/comments/8kpsjy/can_someone_explain_the_use_of_a_dynamic_graph/)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mDBSmecjPKE7","executionInfo":{"status":"ok","timestamp":1654580733991,"user_tz":-540,"elapsed":404,"user":{"displayName":"최성철","userId":"16731672827766253258"}},"outputId":"fa65b81c-cc38-4f20-f9d4-33e1d42863d4"},"source":["import torch\n","from torch import nn\n","\n","# TODO : 다음의 모듈(Module)을 읽고 이해해보세요!\n","class Add(nn.Module):\n","    def __init__(self, value):\n","        super().__init__()\n","        self.value = value\n","\n","    def forward(self, x):\n","        return x + self.value\n","\n","class Sub(nn.Module):\n","    def __init__(self, value):\n","        super().__init__()\n","        self.value = value\n","\n","    def forward(self, x):\n","        return x - self.value\n","\n","\n","# TODO : Calculator 모델을 완성하세요!\n","class Calculator(nn.Module):\n","    def __init__(self, cal_type):\n","        super().__init__()\n","        self.cal_type = cal_type\n","        self.add = Add(3)\n","        self.sub = Sub(3)\n","\n","    def forward(self, x):\n","        # TODO : cal_type에 \"add\"가 입력되면 더하기 모델 y = x + 3\n","        #                   \"sub\"가 입력되면 빼기 모델 y = x - 3\n","        #                   \"add\", \"sub\"가 아닌 다른 문자열이 입력되면 ValueError을 일으키세요!\n","        #        if/elif/else 조건문을 사용하세요! \n","        if self.cal_type == \"add\":\n","            x = self.add(x)\n","        elif self.cal_type == \"sub\":\n","            x = self.sub(x)\n","        else:\n","            raise ValueError(f\"cal_type should be add or sub. entered {self.cal_type}\")\n","\n","\n","        return x\n","\n","\n","# 아래 코드는 수정하실 필요가 없습니다!\n","x = torch.tensor([5])\n","\n","try:\n","    calculator = Calculator(\"none\")\n","    output = calculator(x)\n","\n","    print(\"🦆 잘못된 문자열 입력에는 에러를 발생시키세요!!\")\n","except ValueError:\n","    calculator = Calculator(\"add\")\n","    add_output = calculator(x)\n","\n","    calculator = Calculator(\"sub\")\n","    sub_output = calculator(x)\n","    \n","    if add_output == 8 and sub_output == 2:\n","        print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","    else:\n","        print(\"🦆 다시 도전해봐요!\")\n","except:\n","    print(\"🦆 ValueError를 발생시키세요!!\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["🎉🎉🎉 성공!!! 🎉🎉🎉\n"]}]},{"cell_type":"markdown","metadata":{"id":"Pfdy2siYp4ua"},"source":["#### 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> To feel the flow of module.\n","\n","``` python\n","🦆\n","It's cool that a module can contain a module!\n","\n","- Function, which is the smallest functional unit\n","- a layer of functions\n","- Model with layers\n","\n","If you stack blocks from small parts one by one, then at some point,\n","We will be able to see a great tower called the giant deep learning model!\n","\n","Experience the flow of module-to-module connections!\n","What is the order of initialization for each module?\n","Take your time to think about when it starts and ends!\n","```\n","\n","- [Documentation main - PyTorch 공식 문서](https://pytorch.org/docs/stable/index.html)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uGPSjEytp4um","executionInfo":{"status":"ok","timestamp":1627387349953,"user_tz":-540,"elapsed":283,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"a6976a96-3f3b-4e45-e439-420e90511f59"},"source":["import torch\n","from torch import nn\n","\n","\n","# Function\n","class Function_A(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        print(f\"        Function A Initialized\")\n","\n","    def forward(self, x):\n","        print(f\"        Function A started\")\n","        print(f\"        Function A done\")\n","\n","class Function_B(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        print(f\"        Function B Initialized\")\n","\n","    def forward(self, x):\n","        print(f\"        Function B started\")\n","        print(f\"        Function B done\")\n","\n","class Function_C(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        print(f\"        Function C Initialized\")\n","\n","    def forward(self, x):\n","        print(f\"        Function C started\")\n","        print(f\"        Function C done\")\n","\n","class Function_D(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        print(f\"        Function D Initialized\")\n","\n","    def forward(self, x):\n","        print(f\"        Function D started\")\n","        print(f\"        Function D done\")\n","\n","\n","# Layer\n","class Layer_AB(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.a = Function_A()\n","        self.b = Function_B()\n","\n","        print(f\"    Layer AB Initialized\")\n","\n","    def forward(self, x):\n","        print(f\"    Layer AB started\")\n","        self.a(x)\n","        self.b(x)\n","        print(f\"    Layer AB done\")\n","\n","class Layer_CD(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.c = Function_C()\n","        self.d = Function_D()\n","\n","        print(f\"    Layer CD Initialized\")\n","\n","    def forward(self, x):\n","        print(f\"    Layer CD started\")\n","        self.c(x)\n","        self.d(x)\n","        print(f\"    Layer CD done\")\n","\n","\n","# Model\n","class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.ab = Layer_AB()\n","        self.cd = Layer_CD()\n","\n","        print(f\"Model ABCD Initialized\\n\")\n","\n","    def forward(self, x):\n","        print(f\"Model ABCD started\")\n","        self.ab(x)\n","        self.cd(x)\n","        print(f\"Model ABCD done\\n\")\n","\n","\n","x = torch.tensor([7])\n","\n","model = Model()\n","model(x)\n","\n","print(\"🎉🎉🎉 모든 딥러닝 모델은 이처럼 Module들이 쌓이고 쌓여서 만들어집니다! 🎉🎉🎉\")\n","print(\"🎉🎉🎉 흐름을 느껴보시고 이 흐름이 이해가 되신 분은 다음으로 가시면 됩니다! 🎉🎉\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["        Function A Initialized\n","        Function B Initialized\n","    Layer AB Initialized\n","        Function C Initialized\n","        Function D Initialized\n","    Layer CD Initialized\n","Model ABCD Initialized\n","\n","Model ABCD started\n","    Layer AB started\n","        Function A started\n","        Function A done\n","        Function B started\n","        Function B done\n","    Layer AB done\n","    Layer CD started\n","        Function C started\n","        Function C done\n","        Function D started\n","        Function D done\n","    Layer CD done\n","Model ABCD done\n","\n","🎉🎉🎉 모든 딥러닝 모델은 이처럼 Module들이 쌓이고 쌓여서 만들어집니다! 🎉🎉🎉\n","🎉🎉🎉 흐름을 느껴보시고 이 흐름이 이해가 되신 분은 다음으로 가시면 됩니다! 🎉🎉\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LYE0lhVK2Vow"},"source":["#### 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> Parameter\n","\n","``` python\n","🦆\n","I was thinking about linear transformation, Y = XW + b!\n","We're going to torch X.We make it with Tensor, but where do we make W and B?\n","\n","At first glance, I heard from a friend that the pre-made tensors in the nn.Module\n","I think I heard you can keep it! What did I say, I think I said Parameter!\n","```\n","\n","- [Documentation main - PyTorch 공식 문서](https://pytorch.org/docs/stable/index.html)\n","- [torch.nn.parameter.Parameter - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html?highlight=parameter)\n","\n","🎁 **힌트** 🎁\n","- [PyTorch linear.py L81 - L85 - PyTorch 공식 Github](https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/linear.py#L81-L85)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wQoHSQcA2Vo3","executionInfo":{"status":"ok","timestamp":1654580893901,"user_tz":-540,"elapsed":5,"user":{"displayName":"최성철","userId":"16731672827766253258"}},"outputId":"7f984ce1-1c94-4cc9-da8a-a2052dcef265"},"source":["import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","\n","\n","# TODO : Complete the Linear Model!\n","\n","class Linear(nn.Module):\n","    def __init__(self, in_features, out_features):\n","        super().__init__()\n","\n","        # TODO : Create W, b parameters! Please initialize all to 1!\n","        self.W = Parameter(torch.ones((out_features, in_features)))\n","        self.b = Parameter(torch.ones(out_features))\n","\n","\n","    def forward(self, x):\n","        output = torch.addmm(self.b, x, self.W.T)\n","\n","        return output\n","\n","\n","# You do not need to modify the code below!\n","x = torch.Tensor([[1, 2],\n","                  [3, 4]])\n","\n","linear = Linear(2, 3)\n","output = linear(x)\n","\n","if torch.all(output == torch.Tensor([[4, 4, 4],\n","                                     [8, 8, 8]])):\n","    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","else:\n","    print(\"🦆 다시 도전해봐요!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["🎉🎉🎉 성공!!! 🎉🎉🎉\n"]}]},{"cell_type":"markdown","metadata":{"id":"S8u8jNL8H_dN"},"source":["#### ❓ <font color='red'><b>[ 퀴즈 ]</b></font> Tensor vs Parameter\n","``` python\n","🦆\n","If you think about it, shouldn't W and B also use a tensor?\n","Why do you have to use a separate class called Parameter?\n","```\n","🎁 **힌트** 🎁\n","- If you drawn up under the code to run, you can get the hint!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ULF5STEQH_dO","executionInfo":{"status":"ok","timestamp":1627392343166,"user_tz":-540,"elapsed":268,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"30568cfc-42b8-4c21-d7b0-e52ddde878f4"},"source":["import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","\n","\n","class Linear_Parameter(nn.Module):\n","    def __init__(self, in_features, out_features):\n","        super().__init__()\n","\n","        # torch.nn.parameter.Parameter\n","        self.W = Parameter(torch.ones((out_features, in_features)))\n","        self.b = Parameter(torch.ones(out_features))\n","\n","    def forward(self, x):\n","        output = torch.addmm(self.b, x, self.W.T)\n","\n","        return output\n","\n","class Linear_Tensor(nn.Module):\n","    def __init__(self, in_features, out_features):\n","        super().__init__()\n","\n","        # torch.Tensor\n","        self.W = torch.ones((out_features, in_features))\n","        self.b = torch.ones(out_features)\n","\n","    def forward(self, x):\n","        output = torch.addmm(self.b, x, self.W.T)\n","\n","        return output\n","\n","\n","x = torch.Tensor([[1, 2],\n","                  [3, 4]])\n","\n","linear_parameter = Linear_Parameter(2, 3)\n","linear_tensor = Linear_Tensor(2, 3)\n","\n","output_parameter = linear_parameter(x)\n","output_tensor = linear_tensor(x)\n","\n","# You can see that the values are calculated the same!\n","# But if you look closely at the output, you can only use the parameter to make W, b\n","# Grad_fn, a function that calculates gradients, is created in the output tensor\n","print(output_parameter)\n","print(output_tensor)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([[4., 4., 4.],\n","        [8., 8., 8.]], grad_fn=<AddmmBackward>)\n","tensor([[4., 4., 4.],\n","        [8., 8., 8.]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SCmHCEEWH_dP","executionInfo":{"status":"ok","timestamp":1627392616501,"user_tz":-540,"elapsed":386,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"887cdf54-adad-451a-f46a-be030ced826f"},"source":["# W, b made of parameters are designated as the tensor to be stored\n","linear_parameter.state_dict()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('W', tensor([[1., 1.],\n","                      [1., 1.],\n","                      [1., 1.]])), ('b', tensor([1., 1., 1.]))])"]},"metadata":{"tags":[]},"execution_count":139}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5obZKlPzH_dP","executionInfo":{"status":"ok","timestamp":1627392793928,"user_tz":-540,"elapsed":284,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"10ea426a-b2cb-4c47-a8ca-dcee3e65892f"},"source":["# # torch.W, b made with Tensor will not be saved\n","linear_tensor.state_dict()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict()"]},"metadata":{"tags":[]},"execution_count":140}]},{"cell_type":"markdown","metadata":{"id":"KH49yfoYH_dR"},"source":["```python\n","😏\n","# TODO: It's a matter of absolute certainty. Please read the document and write down the answers freely\n","```"]},{"cell_type":"markdown","metadata":{"id":"C3WfRph4AYrb"},"source":["#### 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> Buffer\n","\n","``` python\n","🦆\n","Friend says that most custom models are torches.The layers implemented on the nn\n","It's said that it's very rare to handle the Parameter yourself because it's taken away and used!\n","\n","If we're not going to write a new layer ourselves,\n","It's said that you rarely!\n","\n","But he praised me for saying that it's important to know how to use Parameters!\n","I also told her that there's a buffer!\n","\n","Unlike a parameter, a normal tensor does not calculate gradients\n","The value is not updated, and it is ignored when saving the model, right?\n","\n","However, even if the value is not updated because the parameter is not specified,\n","There might be a sensor that you want to save, right?\n","\n","In that case, you can register the tensor on the buffer!\n","When saving the model, not only the parameter but also the tensors registered as buffers are stored together!\n","\n","To sum up, it's\n","\n","- \"Tensor\"\n","  - ❌ Gradient calculation\n","  - ❌ Update the value\n","  - ❌ Save value when saving model\n","- \"Parameter\"\n","  - ✅ Gradient calculation\n","  - ✅ Update the value\n","  - ✅ Save value when saving model\n","- \"Buffer\"\n","  - ❌ Gradient calculation\n","  - ❌ Update the  value\n","  - ✅ Save value when saving model\n","```\n","\n","- [Documentation main - PyTorch 공식 문서](https://pytorch.org/docs/stable/index.html)\n","- [register_buffer - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=register_buffer#torch.nn.Module.register_buffer)\n","\n","**✨ 유용한 자료 ✨**\n","- [What is the difference between `register_buffer` and `register_parameter` of `nn.Module` - PyTorch Forum](https://discuss.pytorch.org/t/what-is-the-difference-between-register-buffer-and-register-parameter-of-nn-module/32723)"]},{"cell_type":"code","metadata":{"id":"xU_FYpsgAYri","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654580999760,"user_tz":-540,"elapsed":3,"user":{"displayName":"최성철","userId":"16731672827766253258"}},"outputId":"3c75c301-27ed-42f5-aa59-a7a2d3abe3c9"},"source":["import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","\n","\n","# TODO : Complete the Model Model!\n","class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.parameter = Parameter(torch.Tensor([7]))\n","        self.tensor = torch.Tensor([7])\n","\n","        # TODO : torch.Tensor([7])를 buffer이라는 이름으로 buffer에 등록해보세요!\n","        self.register_buffer('buffer', torch.Tensor([7]), persistent=True)\n","\n","\n","\n","# You do not need to modify the code below!\n","model = Model()\n","\n","try:\n","    buffer = model.get_buffer('buffer')\n","    print(buffer)\n","    if buffer == 7:\n","        print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\\n\")\n","        print(\"🎉 이제 buffer에 등록된 tensor는 모델이 저장될 때 같이 저장될거예요! 🎉\")\n","        print(model.state_dict())\n","    else:\n","        print(\"🦆 다시 도전해봐요!\")\n","except:\n","    print(\"🦆 다시 도전해봐요!\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([7.])\n","🎉🎉🎉 성공!!! 🎉🎉🎉\n","\n","🎉 이제 buffer에 등록된 tensor는 모델이 저장될 때 같이 저장될거예요! 🎉\n","OrderedDict([('parameter', tensor([7.])), ('buffer', tensor([7.]))])\n"]}]},{"cell_type":"markdown","metadata":{"id":"HY5I6ZQbScV2"},"source":["``` python\n","😩\n","Ah, it's so hard... So where do you use this?\n","```\n","\n","``` python\n","🦆\n","I knew you'd say that I prepared it!\n","One good example is used in BatchNorm!\n","I have attached the link below, so please read it for more information!\n","\n","I think it's rare to use this buffer just like Parameter!\n","But if you know it, one day you'll use it here, right?\n","```\n","\n","\n","**✨ 유용한 자료 ✨**\n","- [torch.nn.BatchNorm1d - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html?highlight=buffer)\n","- [PyTorch batchnorm.py L51 - L52 - PyTorch 공식 Github](https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/batchnorm.py#L51-L52)"]},{"cell_type":"markdown","metadata":{"id":"jr6BwccdiH5s"},"source":["### ☄️ nn.Module 분석하기\n","> I understand the basic concepts that are important in building a model. Now we have the power to build the model we want. But how do we know how the interior of the custom model is constructed after making it? If it's a custom model that you made, it's okay because I can remember it somehow. So how do you analyze the inside of a model when you bring it to refer to someone else's model? We will have time to take a quick look at the method.\n","\n","\n","- 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> Analyzing the Model of Mudeok\n","\n","- 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> Modifying a Mudeok Model - Remove a module reference\n","- 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> Modifying the Mudeok Model - Modifying the Module Output\n","- 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> Modifying the Mudeok Model - Creating a Docstring\n","- 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> Analyze BatchNorm1d\n","\n","\n","    \n"]},{"cell_type":"markdown","metadata":{"id":"P0rBcgFOdVTL"},"source":["#### 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> 부덕이 모델 분석해보기\n","\n","``` python\n","🦆\n","I didn't know anything about PyTorch\n","I can't believe you can make your own models! It's like a dream!\n","\n","I'm looking at the code that I wrote to feel the flow of modules\n","I can't stop the wing dance because I'm so proud of myself\n","\n","But after making the model, which module and parameter did you use?\n","How do you know?\n","\n","I think the \"nn.Module\" documentation will show you how to do it!\n","\n","I brought the code that I wrote before! It's a bit different from when you saw it, right?\n","I changed it little by little to apply what I learned!\n","Let's analyze this model I made together!\n","```\n","\n","- [Documentation main - PyTorch 공식 문서](https://pytorch.org/docs/stable/index.html)\n","- [torch.nn.Module - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0wIMxj_7cxSH","executionInfo":{"status":"ok","timestamp":1627532584292,"user_tz":-540,"elapsed":288,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"5e163a32-97a2-4cf9-df5e-231f443f98fe"},"source":["import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","\n","\n","# You do not need to modify the code below!\n","# But look at the code below and understand it as much as you can before you do the task below!\n","\n","# Function\n","class Function_A(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","\n","    def forward(self, x):\n","        x = x * 2\n","        return x\n","\n","class Function_B(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.W1 = Parameter(torch.Tensor([10]))\n","        self.W2 = Parameter(torch.Tensor([2]))\n","\n","    def forward(self, x):\n","        x = x / self.W1\n","        x = x / self.W2\n","\n","        return x\n","\n","class Function_C(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.register_buffer('duck', torch.Tensor([7]), persistent=True)\n","\n","    def forward(self, x):\n","        x = x * self.duck\n","        \n","        return x\n","\n","class Function_D(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.W1 = Parameter(torch.Tensor([3]))\n","        self.W2 = Parameter(torch.Tensor([5]))\n","        self.c = Function_C()\n","\n","    def forward(self, x):\n","        x = x + self.W1\n","        x = self.c(x)\n","        x = x / self.W2\n","\n","        return x\n","\n","\n","# Layer\n","class Layer_AB(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.a = Function_A('duck')\n","        self.b = Function_B()\n","\n","    def forward(self, x):\n","        x = self.a(x) / 5\n","        x = self.b(x)\n","\n","        return x\n","\n","class Layer_CD(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.c = Function_C()\n","        self.d = Function_D()\n","\n","    def forward(self, x):\n","        x = self.c(x)\n","        x = self.d(x) + 1\n","\n","        return x\n","\n","\n","# Model\n","class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.ab = Layer_AB()\n","        self.cd = Layer_CD()\n","\n","    def forward(self, x):\n","        x = self.ab(x)\n","        x = self.cd(x)\n","\n","        return x\n","\n","x = torch.tensor([7])\n","\n","model = Model()\n","model(x)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([6.5720], grad_fn=<AddBackward0>)"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"markdown","metadata":{"id":"SvtNG5hkeb2G"},"source":["##### 💡 named_children vs named_modules\n","> 🦆 부덕이가 코드를 작성해주었어요\n","\n","``` python\n","🦆\n","I don't remember which modules were in the model I made!\n","So I want to see the list of modules inside the model!\n","\n","I looked up the documentation and found out that it was named children or module\n","I think the function has the function I want!\n","\n","But what's the difference between these two?\n","As expected, I'll have to check it out through the code myself!\n","```\n","\n","- [named_children - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=child#torch.nn.Module.named_children)\n","- [named_modules - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=named#torch.nn.Module.named_modules)\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zSZh9S6SjCSQ","executionInfo":{"status":"ok","timestamp":1627532584589,"user_tz":-540,"elapsed":16,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"0a566083-a1db-4231-d027-3f23f0cadd65"},"source":["for name, module in model.named_modules():\n","    print(f\"[ Name ] : {name}\\n[ Module ]\\n{module}\")\n","    print(\"-\" * 30)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[ Name ] : \n","[ Module ]\n","Model(\n","  (ab): Layer_AB(\n","    (a): Function_A()\n","    (b): Function_B()\n","  )\n","  (cd): Layer_CD(\n","    (c): Function_C()\n","    (d): Function_D(\n","      (c): Function_C()\n","    )\n","  )\n",")\n","------------------------------\n","[ Name ] : ab\n","[ Module ]\n","Layer_AB(\n","  (a): Function_A()\n","  (b): Function_B()\n",")\n","------------------------------\n","[ Name ] : ab.a\n","[ Module ]\n","Function_A()\n","------------------------------\n","[ Name ] : ab.b\n","[ Module ]\n","Function_B()\n","------------------------------\n","[ Name ] : cd\n","[ Module ]\n","Layer_CD(\n","  (c): Function_C()\n","  (d): Function_D(\n","    (c): Function_C()\n","  )\n",")\n","------------------------------\n","[ Name ] : cd.c\n","[ Module ]\n","Function_C()\n","------------------------------\n","[ Name ] : cd.d\n","[ Module ]\n","Function_D(\n","  (c): Function_C()\n",")\n","------------------------------\n","[ Name ] : cd.d.c\n","[ Module ]\n","Function_C()\n","------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IKfekNTn3D3n","executionInfo":{"status":"ok","timestamp":1627532584590,"user_tz":-540,"elapsed":14,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"ae7c198f-cd66-4c63-deba-ad807d36ed70"},"source":["for name, child in model.named_children():\n","    print(f\"[ Name ] : {name}\\n[ Children ]\\n{child}\")\n","    print(\"-\" * 30)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[ Name ] : ab\n","[ Children ]\n","Layer_AB(\n","  (a): Function_A()\n","  (b): Function_B()\n",")\n","------------------------------\n","[ Name ] : cd\n","[ Children ]\n","Layer_CD(\n","  (c): Function_C()\n","  (d): Function_D(\n","    (c): Function_C()\n","  )\n",")\n","------------------------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Fc5uZnP929pS"},"source":["``` python\n","🦆\n","Aha! I got it now!\n","\n","\"children\" means to display only one submodule below the level\n","\"modules\" means to display all the submodules that belong to you!\n","\n","\"named_modules\", \"named_children\" returns the name of the module\n","If you just need a module, you can use \"modules\" or \"children\"!\n","\n","No, but why is \"Function_D\" referring to \"Function_C\"?\n","The same basic unit should be independent of each other, but I think there will be a problem!\n","I'll have to fix it when I'm done analyzing it!\n","```"]},{"cell_type":"markdown","metadata":{"id":"bC4XBN5k5g53"},"source":["##### 💡 get_submodule\n","\n","``` python\n","🦆\n","What I made the model! know whether there are module\n","Now, I want! I want to bring certain module\n","\n","Could you bring  Function_A?\n","\n","```\n","\n","- [get_submodule - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=get_submodule#torch.nn.Module.get_submodule)\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MSYN3x5hl4Wf","executionInfo":{"status":"ok","timestamp":1627532584590,"user_tz":-540,"elapsed":13,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"a6fdba55-ffbd-41a7-a157-26400a0d37d7"},"source":["# TODO : Bring Function_A!\n","submodule = None\n","\n","\n","# You do not need to modify the code below!\n","if submodule.__class__.__name__  == 'Function_A':\n","    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","else:\n","    print(\"🦆 다시 도전해봐요!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["🎉🎉🎉 성공!!! 🎉🎉🎉\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"87fdrrUW_Eyg"},"source":["##### 💡 Parameter\n","\n","``` python\n","🦆\n","Now I have confidence in module!\n","But thinking about it, while studying about Parameters,\n","I think I created a parameter on a module!\n","\n","We'll look at the module list in the module and see the specific module\n","Let's do the same with Parameters, as we've found!\n","```\n","\n","- [parameters - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=parameters#torch.nn.Module.parameters)\n","- [named_parameters - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=named#torch.nn.Module.named_parameters)\n","- [get_parameter - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=get#torch.nn.Module.get_parameter)\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5HZk5-vlly_P","executionInfo":{"status":"ok","timestamp":1627532584590,"user_tz":-540,"elapsed":11,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"120396a5-25be-4e3b-a314-2f7965fae1e9"},"source":["# 🦆 I made four parameters!\n","for name, parameter in model.named_parameters():\n","    print(f\"[ Name ] : {name}\\n[ Parameter ]\\n{parameter}\")\n","    print(\"-\" * 30)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[ Name ] : ab.b.W1\n","[ Parameter ]\n","Parameter containing:\n","tensor([10.], requires_grad=True)\n","------------------------------\n","[ Name ] : ab.b.W2\n","[ Parameter ]\n","Parameter containing:\n","tensor([2.], requires_grad=True)\n","------------------------------\n","[ Name ] : cd.d.W1\n","[ Parameter ]\n","Parameter containing:\n","tensor([3.], requires_grad=True)\n","------------------------------\n","[ Name ] : cd.d.W2\n","[ Parameter ]\n","Parameter containing:\n","tensor([5.], requires_grad=True)\n","------------------------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lWwtgIOBD5-0"},"source":["``` python\n","🦆\n","Aha! I made four parameters!\n","It's so nice to see where the parameter belongs by displaying the name!\n","\n","- \"Function_B\" has two W1, W2 parameters\n","- \"Function_D\" has two W1, W2 parameters\n","\n","You can use \"parameters\" to check the list\n","It doesn't show the name, so it's a part of a module\n","It's going to be so hard to tell if it's a parameter!\n","\n","I want to use Parameter W1, which is part of Function_B\n","Can you bring me this?\n","```"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hIhreLUX_Eyj","executionInfo":{"status":"ok","timestamp":1627532584591,"user_tz":-540,"elapsed":11,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"4564110d-7180-4d6e-bd76-c36abb367d5f"},"source":["# TODO :  Bring parameter W1 belonging to Function_B!\n","parameter = None\n","\n","\n","# You do not need to modify the code below!\n","if parameter  == 10:\n","    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","else:\n","    print(\"🦆 다시 도전해봐요!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["🎉🎉🎉 성공!!! 🎉🎉🎉\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1ZC6RK20H8iC"},"source":["##### 💡 Buffer\n","\n","``` python\n","🦆\n","Come to think of it, I think I added a buffer\n","Let's analyze the buffer together!\n","```\n","\n","- [buffers - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=buffers#torch.nn.Module.buffers)\n","- [named_buffers - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=named_buffers#torch.nn.Module.named_buffers)\n","- [get_buffer - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=get_buffer#torch.nn.Module.get_buffer)\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"4AxUn_jgH8iE","executionInfo":{"status":"error","timestamp":1653388834139,"user_tz":-540,"elapsed":295,"user":{"displayName":"최성철","userId":"16731672827766253258"}},"outputId":"9a82d0fc-dbac-472c-82f4-46d6f46b28a3"},"source":["#  TODO : to get a complete list of buffers belonging to the model by using named_buffers !\n","for name, buffer in model.named_buffers():\n","    print(f\"[ Name ] : {name}\\n[ Buffer ] : {buffer}\")\n","    print(\"-\" * 30)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-71f118ff34a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#  TODO : to get a complete list of buffers belonging to the model by using named_buffers !\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_buffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[ Name ] : {name}\\n[ Buffer ] : {buffer}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xWjaJqgWI5r-","executionInfo":{"status":"ok","timestamp":1627532584591,"user_tz":-540,"elapsed":9,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"b72ac3fb-9abe-4f8b-c276-65af6060a189"},"source":["# TODO : Use buffers to get a complete list of buffers belonging to a model!\n","for buffer in model.buffers():\n","    print(f\"[ Buffer ] : {buffer}\")\n","    print(\"-\" * 30)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[ Buffer ] : tensor([7.])\n","------------------------------\n","[ Buffer ] : tensor([7.])\n","------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B2ePuoOWH8iF","executionInfo":{"status":"ok","timestamp":1627532584592,"user_tz":-540,"elapsed":9,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"30108bf2-ee03-409d-bb58-11961874a212"},"source":["# TODO : Bring the buffer that belongs to Function_C!\n","buffer = None\n","\n","\n","# You do not need to modify the code below!\n","if buffer == 7:\n","    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","else:\n","    print(\"🦆 다시 도전해봐요!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["🎉🎉🎉 성공!!! 🎉🎉🎉\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JfrjK8Q5tNH6"},"source":["##### 💡 Docstring\n","\n","``` python\n","🦆\n","Oops! I forgot!\n","\n","All functions and classes provided by PyTorch are written with Docstring!\n","But I don't really use Documentation because it's more convenient!\n","\n","I'm creating a custom model and I'm going to use this custom model\n","Writing Docstring is a must for other developers and for themselves in the future!\n","If you have this Docstring when you make Documentation later, it will be easy to make, right?\n","\n","You made a basic mistake!\n","I should add Docstring later!\n","```\n","- [Docstring - Wikipedia](https://en.wikipedia.org/wiki/Docstring)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tCkBRdsItfTQ","executionInfo":{"status":"ok","timestamp":1627532584878,"user_tz":-540,"elapsed":294,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"2c82b927-9911-492a-889e-9f0c969a2abf"},"source":["print(model.__doc__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["None\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VeIqAIk1NTUh"},"source":["#### 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> 부덕이 모델 수정하기 - module 참조 제거\n","\n","``` python\n","🦆\n","When I analyzed my model, I found out that \"Function_D\" which I made as the most basic unit contains \"Function_C\"!\n","\n","I don't want modules to refer to each other as basic units!\n","\n","And even if you remove \"Function_C\" from \"Function_D\",\n","I want to make the whole operation the same!\n","\n","Let's fix it together!\n","```\n","\n","- [Documentation main - PyTorch 공식 문서](https://pytorch.org/docs/stable/index.html)\n","- [torch.nn.Module - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A95FtG-1Px7k","executionInfo":{"status":"ok","timestamp":1627656607883,"user_tz":-540,"elapsed":242,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"a8d38af6-d9dd-43d6-b8f7-25ff42f6dc23"},"source":["import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","\n","\n","# Function\n","class Function_A(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","\n","    def forward(self, x):\n","        x = x * 2\n","        return x\n","\n","class Function_B(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.W1 = Parameter(torch.Tensor([10]))\n","        self.W2 = Parameter(torch.Tensor([2]))\n","\n","    def forward(self, x):\n","        x = x / self.W1\n","        x = x / self.W2\n","\n","        return x\n","\n","class Function_C(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.register_buffer('duck', torch.Tensor([7]), persistent=True)\n","\n","    def forward(self, x):\n","        x = x * self.duck\n","        \n","        return x\n","\n","# TODO : Remove the reference to Function_C and add an alternative operation!\n","#        The computational results of the entire model must not change!\n","class Function_D(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.W1 = Parameter(torch.Tensor([3]))\n","        self.W2 = Parameter(torch.Tensor([5]))\n","        self.c = Function_C()\n","\n","    def forward(self, x):\n","        x = x + self.W1\n","        x = self.c(x)\n","        x = x / self.W2\n","\n","        return x\n","\n","\n","# Layer\n","class Layer_AB(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.a = Function_A('duck')\n","        self.b = Function_B()\n","\n","    def forward(self, x):\n","        x = self.a(x) / 5\n","        x = self.b(x)\n","\n","        return x\n","\n","class Layer_CD(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.c = Function_C()\n","        self.d = Function_D()\n","\n","    def forward(self, x):\n","        x = self.c(x)\n","        x = self.d(x) + 1\n","\n","        return x\n","\n","\n","# Model\n","class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.ab = Layer_AB()\n","        self.cd = Layer_CD()\n","\n","    def forward(self, x):\n","        x = self.ab(x)\n","        x = self.cd(x)\n","\n","        return x\n","\n","\n","\n","# 아래 코드는 수정하실 필요가 없습니다!\n","x = torch.tensor([7])\n","\n","model = Model()\n","output = model(x)\n","\n","fixed = 1\n","for name, _ in model.named_modules():\n","    if 'cd.d.c' == name:\n","        print(\"🦆 아직 Function_D가 Function_C를 참조하고 있네요!\")\n","        fixed = 0\n","\n","if fixed:\n","    if output == 6.5720:\n","        print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","    else:\n","        print(\"🦆 The reference between modules was successfully modified, but the model operation has changed!\")\n","        print(\"🦆 Add a replacement operation to Function_D as you remove Function_C!\")\n","else:\n","    print(\"🦆 다시 도전해봐요!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["🦆 아직 Function_D가 Function_C를 참조하고 있네요!\n","🦆 다시 도전해봐요!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ij7zgUmsUwD6"},"source":["#### 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> 부덕이 모델 수정하기 - module 출력 내용 변경하기\n","\n","``` python\n","🦆\n","In the case of \"Function_A\" which is a function unit module,\n","To create an instance, you have to enter a name!\n","So we created the \"Function_A\" as follows!\n","\n","# Function_A('duck')\n","\n","I wanted to print out the completed model and it would look like this!\n","\n","✅ The ideal output that Boo-duk wants\n","\n","Model(\n","  (ab): Layer_AB(\n","    (a): Function_A(name=duck)\n","    (b): Function_B()\n","  )\n","  (cd): Layer_CD(\n","    (c): Function_C()\n","    (d): Function_D()\n","  )\n",")\n","\n","But when I actually printed it out, it looked like this.\n","\n","❌ Actual Output Results\n","\n","Model(\n","  (ab): Layer_AB(\n","    (a): Function_A()\n","    (b): Function_B()\n","  )\n","  (cd): Layer_CD(\n","    (c): Function_C()\n","    (d): Function_D()\n","  )\n",")\n","\n","What should I do with this? Tightly! 💦\n","```\n","\n","- [Documentation main - PyTorch 공식 문서](https://pytorch.org/docs/stable/index.html)\n","- [extra_repr - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=repr#torch.nn.Module.extra_repr)\n","\n","🎁 **힌트** 🎁\n","- Find repr-related methods in the nn.Module class!\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"enxjXUKNUwD9","executionInfo":{"status":"ok","timestamp":1627656658562,"user_tz":-540,"elapsed":278,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"51f53b80-3eb9-4a01-fe68-c276b0fa2716"},"source":["import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","\n","\n","# Function\n","\n","# TODO : Please modify Function_A so that the right output comes out!\n","\n","class Function_A(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","\n","    def forward(self, x):\n","        x = x * 2\n","        return x\n","\n","class Function_B(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.W1 = Parameter(torch.Tensor([10]))\n","        self.W2 = Parameter(torch.Tensor([2]))\n","\n","    def forward(self, x):\n","        x = x / self.W1\n","        x = x / self.W2\n","\n","        return x\n","\n","class Function_C(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.register_buffer('duck', torch.Tensor([7]), persistent=True)\n","\n","    def forward(self, x):\n","        x = x * self.duck\n","        \n","        return x\n","\n","class Function_D(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.W1 = Parameter(torch.Tensor([3]))\n","        self.W2 = Parameter(torch.Tensor([5]))\n","        self.register_buffer('duck', torch.Tensor([7]), persistent=True)\n","\n","    def forward(self, x):\n","        x = x + self.W1\n","        x = x * self.duck\n","        x = x / self.W2\n","\n","        return x\n","\n","\n","# Layer\n","class Layer_AB(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.a = Function_A('duck')\n","        self.b = Function_B()\n","\n","    def forward(self, x):\n","        x = self.a(x) / 5\n","        x = self.b(x)\n","\n","        return x\n","\n","class Layer_CD(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.c = Function_C()\n","        self.d = Function_D()\n","\n","    def forward(self, x):\n","        x = self.c(x)\n","        x = self.d(x) + 1\n","\n","        return x\n","\n","\n","# Model\n","class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.ab = Layer_AB()\n","        self.cd = Layer_CD()\n","\n","    def forward(self, x):\n","        x = self.ab(x)\n","        x = self.cd(x)\n","\n","        return x\n","\n","\n","# You do not need to modify the code below!\n","\n","model = Model()\n","model_repr = repr(model)\n","\n","print(\"모델 출력 결과\")\n","print(\"-\" * 30)\n","print(model_repr)\n","print(\"-\" * 30)\n","\n","answer = \"Model(\\n  (ab): Layer_AB(\\n    (a): Function_A(name=duck)\\n    (b): Function_B()\\n  )\\n  (cd): Layer_CD(\\n    (c): Function_C()\\n    (d): Function_D()\\n  )\\n)\"\n","\n","if model_repr == answer:\n","    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","    print(\"🦆 너무 고마워요 꽉꽉!\")\n","else:\n","    print(\"🦆 다시 도전해봐요!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["모델 출력 결과\n","------------------------------\n","Model(\n","  (ab): Layer_AB(\n","    (a): Function_A()\n","    (b): Function_B()\n","  )\n","  (cd): Layer_CD(\n","    (c): Function_C()\n","    (d): Function_D()\n","  )\n",")\n","------------------------------\n","🦆 다시 도전해봐요!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"B6lHaqZqvnb5"},"source":["#### 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> 부덕이 모델 수정하기 - Docstring 작성\n","\n","``` python\n","🦆\n","Let's write a docstring lightly!\n","There are various styles like Numpy, Pydoc, Google, and so on, so if you're curious,\n","Let's read the link below and study!\n","\n","For now, let's just add something called Docstring regardless of style!\n","```\n","\n","- [Documentation main - PyTorch 공식 문서](https://pytorch.org/docs/stable/index.html)\n","\n","**✨ 유용한 자료 ✨**\n","- [Docstrings in Python - Data Camp](https://www.datacamp.com/community/tutorials/docstrings-python)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X8_KUU4AvncC","executionInfo":{"status":"ok","timestamp":1627656678517,"user_tz":-540,"elapsed":263,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"de5faa92-df60-4244-a935-068c92c74eeb"},"source":["import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","\n","# TODO : Add Docstring!\n","class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","\n","\n","# You do not need to modify the code below!\n","model = Model()\n","\n","if model.__doc__:\n","    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","else:\n","    print(\"🦆 다시 도전해봐요!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["🦆 다시 도전해봐요!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tka7VMeekxd7"},"source":["#### 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> BatchNorm1d 분석해보기\n","\n","``` python\n","🦆\n","I think I have confidence now!\n","\n","Analyze one of the modules that PyTorch made in advance\n","I want to know how much I've grown!\n","\n","Well, what's good? Try BatchNorm1d!\n","```\n","\n","- [Documentation main - PyTorch 공식 문서](https://pytorch.org/docs/stable/index.html)\n","- [torch.nn.BatchNorm1d - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html#torch.nn.BatchNorm1d)"]},{"cell_type":"code","metadata":{"id":"WUshguoBlTNm"},"source":["import torch\n","import torch.nn\n","\n","module = nn.BatchNorm1d(10)\n","\n","# TODO : nn.Parameter d and 1 batchnorm buffer the number!\n","parameter_n = None\n","buffer_n = None\n","\n","# TODO : nn.Find out the buffer name of BatchNorm1d!\n","#           [Name, name, name] Please save it in the form\n","buffer_names = None\n","\n","\n","\n","# You do not need to modify the code below!\n","\n","answer = set(['running_mean', 'running_var', 'num_batches_tracked'])\n","\n","if parameter_n == 2 and buffer_n == 3 and answer == set(buffer_names):\n","    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","else:\n","    print(\"🦆 다시 도전해봐요!\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lFLQWT3w0m4v"},"source":["``` python\n","🦆\n","It's much more convenient to look at the official PyTorch document than the Docstring\n","BatchNorm1d didn't watch Docstring separately!\n","\n","But if you're using a model that doesn't have Documentation,\n","Think of Docstring as Documentation and look carefully!\n","```"]},{"cell_type":"markdown","metadata":{"id":"2clV-zzGiH-v"},"source":["### ☄️ nn.Module 알쓸신잡\n","> Although not covered on the nn module. If you know of the ability to provide useful look at!\n","\n","- 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> hook\n","- 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> apply\n"]},{"cell_type":"markdown","metadata":{"id":"7tJVT5Mp9I4S"},"source":["#### 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> hook\n","\n","``` python\n","🦆\n","I've never heard of the unfamiliar term hook!\n","What is this? I'm scared for some reason!\n","\n","I looked it up on the internet, and found that other programmers in packaged code\n","This interface is designed to execute custom code in the middle!\n","\n","- Analyze the execution logic of a program or\n","- When you want to add additional functionality to a program\n","\n","It's said that used!\n","\n","It's not like I know! My friend is helping me, so let's learn together!\n","```\n","\n","- [Documentation main - PyTorch 공식 문서](https://pytorch.org/docs/stable/index.html)\n","- [hook - WhatIs](https://whatis.techtarget.com/definition/hook)"]},{"cell_type":"markdown","metadata":{"id":"5HujUYII-wih"},"source":["##### 💡 hook의 원리\n","> 🦆 부덕이 친구가 코드를 작성해주었어요\n","\n","``` python\n","🦆\n","My friend wrote me the code because I said I really don't know what hook is!\n","They say it'll be easier to understand after seeing this code!\n","```\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nok5e_w1PjwS","executionInfo":{"status":"ok","timestamp":1627527096053,"user_tz":-540,"elapsed":361,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"0df97dc7-d157-42b7-9809-f4eb83633dd1"},"source":["def program_A(x):\n","    print('program A processing!')\n","    return x + 3\n","\n","def program_B(x):\n","    print('program B processing!')\n","    return x - 3\n","\n","class Package(object):\n","    \"\"\"Package code tied to program A and B\"\"\"\n","    def __init__(self):\n","        self.programs = [program_A, program_B]\n","        self.hooks = []\n","\n","    def __call__(self, x):\n","        for program in self.programs:\n","            x = program(x)\n","\n","            #  re-created interface hooks for package users to register their own custom programs\n","            if self.hooks:\n","                for hook in self.hooks:\n","                    output = hook(x)\n","\n","                    # Update x only for hooks with return values\n","                    if output:\n","                        x = output\n","\n","        return x\n","\n","# 패키지 생성\n","package = Package()\n","\n","# 패키지 실행\n","input = 3\n","output = package(input)\n","\n","# 패키지 결과\n","print(f\"Package Process Result! [ input {input} ] [ output {output} ]\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["program A processing!\n","program B processing!\n","Package Process Result! [ input 3 ] [ output 3 ]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0KIn1D59SxDf"},"source":["``` python\n","🦆\n","I think I'm starting to get the hang of it after I saw the chords\n","\n","Package originally had a variable called self.hooks!\n","So when you run the package, you can see the programs that are included in the package one by one\n","In the middle of running, you check if there is a function registered in self.hooks!\n","\n","- Run if any function registered in self.hooks ✅\n","- Ignore functions registered in self.hooks ❌\n","\n","Developers who use the package can use their custom code in the middle of the package\n","It's an interface made in advance by the developers who made the package so that it can be executed!\n","\n","```\n","```python\n","😯\n","Oh my god! We've been using various packages\n","So that we can execute the custom code inside the package,\n","You could have had an interface called \"hook\"!\n","```\n","\n","``` python\n","🦆\n","I think I need to know everything to use it\n","\n","Let's take a look at the example of using the hook that my friend gave me!\n","```"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aMmA-BQdeYfi","executionInfo":{"status":"ok","timestamp":1627527096053,"user_tz":-540,"elapsed":8,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"91acec0a-96aa-452d-e05b-9991beba152a"},"source":["# Hook - Example of using a program's execution logic analysis\n","def hook_analysis(x):\n","    print(f'hook for analysis, current value is {x}')\n","\n","# Add hook to generated package\n","package.hooks = []\n","package.hooks.append(hook_analysis)\n","\n","# 패키지 실행\n","input = 3\n","output = package(input)\n","\n","# 패키지 결과\n","print(f\"Package Process Result! [ input {input} ] [ output {output} ]\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["program A processing!\n","hook for analysis, current value is 6\n","program B processing!\n","hook for analysis, current value is 3\n","Package Process Result! [ input 3 ] [ output 3 ]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ijgpx3s6fLAO","executionInfo":{"status":"ok","timestamp":1627527096054,"user_tz":-540,"elapsed":8,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"35df2dd0-36dc-448b-ce52-62f021e72d1b"},"source":["# Hook - Example of adding features to a program\n","def hook_multiply(x):\n","    print('hook for multiply')\n","    return x * 3\n","\n","# Add hook to generated package\n","package.hooks = []\n","package.hooks.append(hook_multiply)\n","\n","# 패키지 실행\n","input = 3\n","output = package(input)\n","\n","# 패키지 결과\n","print(f\"Package Process Result! [ input {input} ] [ output {output} ]\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["program A processing!\n","hook for multiply\n","program B processing!\n","hook for multiply\n","Package Process Result! [ input 3 ] [ output 45 ]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RxWqcHgBg2PU","executionInfo":{"status":"ok","timestamp":1627527096054,"user_tz":-540,"elapsed":6,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"a4810bd7-eb17-496c-bebc-decc2de382f2"},"source":["# 여러개의 hook을 넣을 수 있다\n","package.hooks = []\n","package.hooks.append(hook_multiply)\n","package.hooks.append(hook_analysis)\n","\n","# 패키지 실행\n","input = 3\n","output = package(input)\n","\n","# 패키지 결과\n","print(f\"Package Process Result! [ input {input} ] [ output {output} ]\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["program A processing!\n","hook for multiply\n","hook for analysis, current value is 18\n","program B processing!\n","hook for multiply\n","hook for analysis, current value is 45\n","Package Process Result! [ input 3 ] [ output 45 ]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sVflo4JVhIHV"},"source":["``` python\n","🦆\n","In the example hook given by a friend, only after the program runs\n","You can use the hook function!\n","\n","When designing a package, if you put a hook in front of or behind the program,\n","We can execute our custom function both before and after the program runs!\n","\n","So that you can use hook before running the program\n","I created an interface called pre_hook!\n","```"]},{"cell_type":"code","metadata":{"id":"o1iz3uPh9I4b"},"source":["def program_A(x):\n","    print('program A processing!')\n","    return x + 3\n","\n","def program_B(x):\n","    print('program B processing!')\n","    return x - 3\n","\n","class Package(object):\n","    \"\"\"프로그램 A와 B를 묶어놓은 패키지 코드\"\"\"\n","    def __init__(self):\n","        self.programs = [program_A, program_B]\n","\n","        # hooks\n","        self.pre_hooks = []\n","        self.hooks = []\n","\n","    def __call__(self, x):\n","        for program in self.programs:\n","            \n","            # pre_hook\n","            if self.pre_hooks:\n","                for hook in self.pre_hooks:\n","                    output = hook(x)\n","                    if output:\n","                        x = output\n","\n","            x = program(x)\n","\n","            # hook\n","            if self.hooks:\n","                for hook in self.hooks:\n","                    output = hook(x)\n","                    if output:\n","                        x = output\n","\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YvZi6GDLh9iJ"},"source":["``` python\n","🦆\n","I sent the above code to my friend and he complimented me!\n","\n","It's up to the designer to decide where to put the hook!\n","In the example you sent me, I made a hook interface on the package,\n","They said that we could create a hook interface inside the program!\n","\n","In this case, you can use different hooks for each program\n","They said it's better to customize!\n","```"]},{"cell_type":"markdown","metadata":{"id":"70LM7F_OjMqB"},"source":["##### 💡 PyTorch의 hook\n","> 🦆 부덕이가 코드를 작성해주었어요\n","\n","``` python\n","🦆\n","After I understood the hook, I looked at what kind of hook is in PyTorch!\n","It was divided into two main categories!\n","\n","- Hook applied to Tensor\n","- Hook to apply to Module\n","```"]},{"cell_type":"markdown","metadata":{"id":"pR6xLrKogJoy"},"source":["```python\n","🦆\n","Tensor can enter can be found at \"_ _ backward hooks\" in!\n","\n","Unlike module tensor, backward hook million!\n","Forward hook and find out, but there isn`t!\n","\n","```\n","- [register_hook - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.Tensor.register_hook.html#torch.Tensor.register_hook)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N75CZzOwie3a","executionInfo":{"status":"ok","timestamp":1627484904277,"user_tz":-540,"elapsed":315,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"f7bb4455-6b9c-4af2-fece-b1554c89fbaa"},"source":["import torch\n","\n","tensor = torch.rand(1, requires_grad=True)\n","\n","def tensor_hook(grad):\n","    pass\n","\n","tensor.register_hook(tensor_hook)\n","\n","# 🦆 The tensor only has a backup hook!\n","\n","tensor._backward_hooks"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict([(111, <function __main__.tensor_hook>)])"]},"metadata":{"tags":[]},"execution_count":71}]},{"cell_type":"markdown","metadata":{"id":"dJ_ll23vibx-"},"source":["```python\n","🦆\n","All hooks registered in nn.Module can be checked at once by using \"__dict__\"!\n","\n","```\n","\n","- [register_forward_pre_hook - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=hook#torch.nn.Module.register_forward_pre_hook)\n","- [register_forward_hook - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=hook#torch.nn.Module.register_forward_hook)\n","- [register_backward_hook - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=hook#torch.nn.Module.register_backward_hook)\n","- [register_full_backward_hook - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=register_full#torch.nn.Module.register_full_backward_hook)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f522pSdWXgGA","executionInfo":{"status":"ok","timestamp":1627484875082,"user_tz":-540,"elapsed":316,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"14827ab7-632f-4bab-bf97-275e853379a1"},"source":["from torch import nn\n","\n","class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","def module_hook(grad):\n","    pass\n","\n","model = Model()\n","model.register_forward_pre_hook(module_hook)\n","model.register_forward_hook(module_hook)\n","model.register_full_backward_hook(module_hook)\n","\n","# 🦆 __dict__ contains all variables of the module and important information such as parameters and hooks!\n","# Don't forget to use the module when you need it in the future as it is a space for storing information\n","model.__dict__"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'_backward_hooks': OrderedDict([(110, <function __main__.module_hook>)]),\n"," '_buffers': OrderedDict(),\n"," '_forward_hooks': OrderedDict([(109, <function __main__.module_hook>)]),\n"," '_forward_pre_hooks': OrderedDict([(108, <function __main__.module_hook>)]),\n"," '_is_full_backward_hook': True,\n"," '_load_state_dict_pre_hooks': OrderedDict(),\n"," '_modules': OrderedDict(),\n"," '_non_persistent_buffers_set': set(),\n"," '_parameters': OrderedDict(),\n"," '_state_dict_hooks': OrderedDict(),\n"," 'training': True}"]},"metadata":{"tags":[]},"execution_count":70}]},{"cell_type":"markdown","metadata":{"id":"UxX-trOlrvjh"},"source":["```python\n","🦆\n","When I checked \"__dict__\", I found the following 5 things!\n","\n","- - forward_pre_hooks\n","- - forward_hooks\n","- - backward_hooks # deprecated\n","- - full_backward_hooks\n","- - state_dict_hooks # used internally\n","\n","I think I know when you use it by looking at the name\n","Hooks are called at the time of forward and backward, right?\n","\n","- For forward, there are pre_hooks and hooks\n","- There's only a hook in the poem for backward!\n","- In the case of state_dict, there's a hook, but we don't use it\n","The \"load_state_dict\" function is used internally!\n","The contents are written in the attached link below!\n","\n","I didn't know that nn.Module made this space called hook!\n","Since we got to know each other well, let's use it if we have a chance!\n","\n","Every time I run the module, the module checks whether there is a registered hook or not\n","Wouldn't module be sad if there's no hook registered every time?\n","\n","I think I'll be so sad.\n","```\n","- [Invoking Time of nn.Module _register_state_dict_hook() - PyTorch Forum](https://discuss.pytorch.org/t/invoking-time-of-nn-module-register-state-dict-hook/108163)"]},{"cell_type":"markdown","metadata":{"id":"1r2HJhPzCqZM"},"source":["##### 💡 forward hook\n","``` python\n","🦆\n","You'll understand better if you use it yourself, right?\n","\n","It's a forward hook that can only be applied to modules! Let's use it together!\n","```\n","\n","**Module**\n","- [register_forward_pre_hook - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=hook#torch.nn.Module.register_forward_pre_hook)\n","- [register_forward_hook - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=hook#torch.nn.Module.register_forward_hook)"]},{"cell_type":"markdown","metadata":{"id":"RfanMq-Et5gc"},"source":["``` python\n","🦆\n","Let's find out what values are propagated to the Add model!\n","I'm sure you'll find out if it's a list and a forward hook that you made in advance!\n","```"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AMmXBTDhtOIc","executionInfo":{"status":"ok","timestamp":1627656797251,"user_tz":-540,"elapsed":259,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"f7ac8d7a-5430-4ce4-d83d-495e63232c76"},"source":["import torch\n","from torch import nn\n","\n","\n","# Do not modify the Add model!\n","\n","class Add(nn.Module):\n","    def __init__(self):\n","        super().__init__() \n","\n","    def forward(self, x1, x2):\n","        output = torch.add(x1, x2)\n","\n","        return output\n","\n","# 모델 생성\n","add = Add()\n","\n","# TODO:Put the answers in the list in order of x1, x2, and output\n","answer = []\n","\n","\n","# TODO : Use pre_hook to find out the values of x1, x2 and save them in answer\n","def pre_hook(module, input):\n","    pass\n","\n","# TODO : Use the hook to find the output value and save it to the answer\n","def hook(module, input, output):\n","    pass\n","\n","\n","# 아래 코드는 수정하실 필요가 없습니다!\n","x1 = torch.rand(1)\n","x2 = torch.rand(1)\n","\n","output = add(x1, x2)\n","\n","if answer == [x1, x2, output]:\n","    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","else:\n","    print(\"🦆 다시 도전해봐요!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["🦆 다시 도전해봐요!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OyygsrsQD_4E"},"source":["``` python\n","🦆\n","Phew, I think it was harder than I thought!\n","Maybe it's because I'm not used to it yet!\n","\n","We just saved the values that are spread through the model using hook\n","Not only this, but I heard that it is possible to modify the propagation value!\n","\n","Let's see if it's really possible!\n","```"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dj7hpOeCEv5-","executionInfo":{"status":"ok","timestamp":1627656834689,"user_tz":-540,"elapsed":464,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"164e3f0f-3c64-4099-ba43-cc82e9a0d84d"},"source":["import torch\n","from torch import nn\n","\n","# Do not modify the Add model!\n","\n","class Add(nn.Module):\n","    def __init__(self):\n","        super().__init__() \n","\n","    def forward(self, x1, x2):\n","        output = torch.add(x1, x2)\n","\n","        return output\n","\n","# 모델 생성\n","add = Add()\n","\n","\n","#  TODO : Use hook to add 5 to the output value that is propagated!\n","\n","def hook(module, input, output):\n","    pass\n","\n","\n","# You do not need to modify the code below!\n","\n","x1 = torch.rand(1)\n","x2 = torch.rand(1)\n","\n","output = add(x1, x2)\n","\n","if output == x1 + x2 + 5:\n","    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","else:\n","    print(\"🦆 다시 도전해봐요!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["🦆 다시 도전해봐요!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XdSszPOlFg2C"},"source":["``` python\n","🦆\n","We did it! We modified the propagation value!\n","\n","Hook, that's very powerful!\n","I think it'll be really useful if you use it well!\n","\n","Where else can I use it?\n","I read the comments below out of curiosity, and I think there are good examples!\n","\n","There's also a topic related to the background hook\n","I need to practice the backup hook and finish reading this part!\n","```\n","\n","**✨ 유용한 자료 ✨**\n","- [How to Use PyTorch Hooks - Medium](https://medium.com/the-dl/how-to-use-pytorch-hooks-5041d777f904)\n","- [PyTorch 101, Part 5: Understanding Hooks - Paperspace blog](https://blog.paperspace.com/pytorch-hooks-gradient-clipping-debugging/)"]},{"cell_type":"markdown","metadata":{"id":"IA_-_-XdtJwT"},"source":["##### 💡 backward hook\n","``` python\n","🦆\n","The forward hook can only be applied to modules,\n","The backward hook can be applied to the sensor and module!\n","\n","Let's use it together!\n","```\n","\n","**Tensor**\n","- [register_hook - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.Tensor.register_hook.html#torch.Tensor.register_hook)\n","\n","**Module**\n","- [register_backward_hook - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=hook#torch.nn.Module.register_backward_hook)\n","- [register_full_backward_hook - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=register_full#torch.nn.Module.register_full_backward_hook)"]},{"cell_type":"markdown","metadata":{"id":"3qIlAHSCy19v"},"source":["``` python\n","🦆\n","Now! you start to deal with gradientI am so excited!\n","In the model radio back when backpropagation gradient value that is find out together!\n","\n","Forward list and like they've done in backward hook, must be possible!\n","```"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BT96uu7WYURO","executionInfo":{"status":"ok","timestamp":1627656864940,"user_tz":-540,"elapsed":262,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"42d53cd6-0dd4-437f-f551-2981f884336a"},"source":["import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","\n","\n","# Model 모델을 수정하지 마세요! \n","class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.W = Parameter(torch.Tensor([5]))\n","\n","    def forward(self, x1, x2):\n","        output = x1 * x2\n","        output = output * self.W\n","\n","        return output\n","\n","# 모델 생성\n","model = Model()\n","\n","\n","# TODO: The answer, 1, 2 ; grad x grad x grad, output list in order to put one by one!\n","answer = []\n","\n","# TODO : hook를 이용해서 x1.grad, x2.grad, output.grad 값을 알아내 answer에 저장하세요\n","         Using hook x1.grad x2.grad output.grad answer out to the store. a value, grad output\n","def module_hook(module, grad_input, grad_output):\n","    pass\n","\n","\n","# You do not need to modify the code below!\n","x1 = torch.rand(1, requires_grad=True)\n","x2 = torch.rand(1, requires_grad=True)\n","\n","output = model(x1, x2)\n","output.retain_grad()\n","output.backward()\n","\n","if answer == [x1.grad, x2.grad, output.grad]:\n","    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","else:\n","    print(\"🦆 다시 도전해봐요!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["🦆 다시 도전해봐요!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bHkgQGZm35q4"},"source":["``` python\n","🦆\n","The module-by-module backward hook is really good,\n","Based on the module, only the input, output gradient values are taken\n","The gradient value of the sensor inside the module cannot be determined!\n","\n","So I want to know the gradient value of Parameter W of the model,\n","I can't figure it out with module unit backward hook!\n","\n","I should use the tensor backup hook!\n","```"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PG0_rueTaYj3","executionInfo":{"status":"ok","timestamp":1627656894394,"user_tz":-540,"elapsed":255,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"223e2fce-ae99-46ec-ef71-c7f7c5129a03"},"source":["import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","\n","class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.W = Parameter(torch.Tensor([5]))\n","\n","    def forward(self, x1, x2):\n","        output = x1 * x2\n","        output = output * self.W\n","\n","        return output\n","\n","# 모델 생성\n","model = Model()\n","\n","\n","# TODO: Save the gradient value of Parameter W in the model!\n","answer = []\n","\n","# TODO : Use the hook to find the gradient value of W and store it in the answer\n","\n","def tensor_hook(grad):\n","    pass\n","\n","\n","# You do not need to modify the code below!\n","\n","x1 = torch.rand(1, requires_grad=True)\n","x2 = torch.rand(1, requires_grad=True)\n","\n","output = model(x1, x2)\n","output.backward()\n","\n","if answer == [model.W.grad]:\n","    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","else:\n","    print(\"🦆 다시 도전해봐요!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["🦆 다시 도전해봐요!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EQtbwyLO6Z7p"},"source":["``` python\n","🦆\n","Now, we're going to use any of the models' sensors\n","I was able to figure out the gradient value I wanted!\n","\n","By the way, can the backward hook also affect the flow of gradient values?\n","```"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J-C4I5fX6AE8","executionInfo":{"status":"ok","timestamp":1627656920901,"user_tz":-540,"elapsed":367,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"9ebf908b-54d6-40a0-9c05-aa9dec2f5f69"},"source":["import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","\n","class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.W = Parameter(torch.Tensor([5]))\n","\n","    def forward(self, x1, x2):\n","        output = x1 * x2\n","        output = output * self.W\n","\n","        return output\n","\n","# Model generation\n","model = Model()\n","\n","\n","# TODO : Use the hook to make the sum of the gradient outputs of the module equal to 1!\n","#        ex) (1.5, 0.5) -> (0.75, 0.25)\n","def module_hook(module, grad_input, grad_output):\n","    pass\n","\n","\n","# You do not need to modify the code below!\n","\n","x1 = torch.rand(1, requires_grad=True)\n","x2 = torch.rand(1, requires_grad=True)\n","\n","output = model(x1, x2)\n","output.backward()\n","\n","if x1.grad + x2.grad == 1:\n","    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","else:\n","    print(\"🦆 다시 도전해봐요!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["🦆 다시 도전해봐요!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rOY2fP6aR1d8"},"source":["``` python\n","🦆\n","\n","We've covered both the `forward hook` and the `backward hooks`!\n","Phew! It was really hard!\n","\n","But I'm very happy that I learned a useful function!\n","I think I can do the next thing!\n","\n","- Visualize changes in gradient values\n","- Gradient exporting alert notification when gradient exceeds a certain threshold\n","- If the gradient value of a particular sensor is observed to become too large or too small,\n","Gradient clipping for the corresponding tensor only\n","\n","Oh! Come to think of it, I was practicing and reading the forward hook and it reminded me of the document!\n","I'll have to finish reading about the backup hook!\n","\n","I found a video clip and it explains the hook in detail well!\n","I'll have to see it when I want to know more about the principles of hook\n","```\n","\n","**✨ 유용한 자료 ✨**\n","- [How to Use PyTorch Hooks - Medium](https://medium.com/the-dl/how-to-use-pytorch-hooks-5041d777f904)\n","- [PyTorch 101, Part 5: Understanding Hooks - Paperspace blog](https://blog.paperspace.com/pytorch-hooks-gradient-clipping-debugging/)\n","- [PyTorch Hooks Explained - In-depth Tutorial - YouTube](https://www.youtube.com/watch?v=syLFCVYua6Q)"]},{"cell_type":"markdown","metadata":{"id":"tz48RlN1_6t_"},"source":["#### 👨‍💻 <font color='green'><b>[ 코딩 ]</b></font> apply\n","\n","``` python\n","🦆\n","This is my drill I think I can explain!Study hard!\n","\n","We are of the pytorch nn module is box that I learned together!\n","That is why module module may include the other module can go into!\n","\n","When all of those module the other in one module.\n","We call a set of model these huge module!\n","\n","The model with numerous module module a complex mix with each other.\n","(tree) or graphs can be seen as a (graph) tree!\n","\n","Something to the model is applied, not just at the top one of the module.\n","All shall be applied to models that make up the entire module.\n","A nn module method of the mostly internal support for it!\n","\n","We don't care. if applied \"cpu ().\" as an example for the top module\n","To all that exists at the bottom of the module module with \"cpu ().\"!\n","\n","Then module the already been implemented, not a method nn.\n","What if you want to apply to the model the function of our own custom?\n","Belonging to the model every function shall be applied to all module?\n","\n","The use of \"apply\" is what someone working!\n","Cot to apply the function is not did well to come home?They can be used with!\n","```\n","\n","- [Documentation main - PyTorch 공식 문서](https://pytorch.org/docs/stable/index.html)\n","- [apply - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=apply#torch.nn.Module.apply)\n"]},{"cell_type":"markdown","metadata":{"id":"5kOCk33KLR8i"},"source":["##### 💡 apply 예제\n","\n","``` python\n","🦆\n","I can understand the functions that I've never seen before by using the example of Documentation!\n","I brought the example written in the apply function\n","```\n","- [apply - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=apply#torch.nn.Module.apply)"]},{"cell_type":"code","metadata":{"id":"P7tUi0q0CVap","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627551882555,"user_tz":-540,"elapsed":440,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"a1acbc60-6930-4388-8d70-e9950d4653c9"},"source":["import torch\n","from torch import nn\n","\n","@torch.no_grad()\n","def init_weights(m):\n","    print(m)\n","    if type(m) == nn.Linear:\n","        m.weight.fill_(1.0)\n","        print(m.weight)\n","\n","net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n","net.apply(init_weights)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Linear(in_features=2, out_features=2, bias=True)\n","Parameter containing:\n","tensor([[1., 1.],\n","        [1., 1.]], requires_grad=True)\n","Linear(in_features=2, out_features=2, bias=True)\n","Parameter containing:\n","tensor([[1., 1.],\n","        [1., 1.]], requires_grad=True)\n","Sequential(\n","  (0): Linear(in_features=2, out_features=2, bias=True)\n","  (1): Linear(in_features=2, out_features=2, bias=True)\n",")\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): Linear(in_features=2, out_features=2, bias=True)\n","  (1): Linear(in_features=2, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":252}]},{"cell_type":"markdown","metadata":{"id":"kdSFfplQPgg9"},"source":["```python\n","🦆\n","Aha! So the function that is applied through apply receives module as input!\n","I think all the modules of the model are input and processed sequentially!\n","\n","The apply function is commonly used for weight initialization!\n","I think it means that the value of the sensor specified by Parameter is specified as the desired value!\n","But I'm still unfamiliar with it, so I don't know if it's accurate!\n","When I saw the chords like \"m.weight.fill_\", I suddenly had a headache.\n","```"]},{"cell_type":"markdown","metadata":{"id":"b7RtvqiWNGen"},"source":["##### 💡 부덕이 모델 apply - Module 출력해보기\n","\n","\n","``` python\n","🦆\n","I don't understand something just from the examples!\n","I'll have to bring back the model I made before and apply it!\n","```"]},{"cell_type":"code","metadata":{"id":"wBfaXAWNN6-C"},"source":["import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","\n","\n","# You do not need to modify the code below!\n","# But look at the code below and understand it as much as you can before you do the task below!\n","\n","# Function\n","class Function_A(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(1))\n","\n","    def forward(self, x):\n","        return x + self.W\n","\n","class Function_B(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(1))\n","\n","    def forward(self, x):\n","        return x - self.W\n","\n","class Function_C(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(1))\n","\n","    def forward(self, x):\n","        return x * self.W\n","\n","class Function_D(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(1))\n","\n","    def forward(self, x):\n","        return x / self.W\n","\n","\n","# Layer\n","class Layer_AB(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.a = Function_A('plus')\n","        self.b = Function_B('substract')\n","\n","    def forward(self, x):\n","        x = self.a(x)\n","        x = self.b(x)\n","\n","        return x\n","\n","class Layer_CD(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.c = Function_C('multiply')\n","        self.d = Function_D('divide')\n","\n","    def forward(self, x):\n","        x = self.c(x)\n","        x = self.d(x)\n","\n","        return x\n","\n","\n","# Model\n","class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.ab = Layer_AB()\n","        self.cd = Layer_CD()\n","\n","    def forward(self, x):\n","        x = self.ab(x)\n","        x = self.cd(x)\n","\n","        return x\n","\n","\n","model = Model()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I-3cdt8TR3_v","executionInfo":{"status":"ok","timestamp":1629302810144,"user_tz":-540,"elapsed":9,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"52987791-5706-4eb6-bf99-8936e2f513af"},"source":["def print_module(module):\n","    print(module)\n","    print(\"-\" * 30)\n","\n","# 🦆 Please return the module that has been applied!\n","\n","returned_module = model.apply(print_module)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Function_A()\n","------------------------------\n","Function_B()\n","------------------------------\n","Layer_AB(\n","  (a): Function_A()\n","  (b): Function_B()\n",")\n","------------------------------\n","Function_C()\n","------------------------------\n","Function_D()\n","------------------------------\n","Layer_CD(\n","  (c): Function_C()\n","  (d): Function_D()\n",")\n","------------------------------\n","Model(\n","  (ab): Layer_AB(\n","    (a): Function_A()\n","    (b): Function_B()\n","  )\n","  (cd): Layer_CD(\n","    (c): Function_C()\n","    (d): Function_D()\n","  )\n",")\n","------------------------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4oFU67qIS-KA"},"source":["``` python\n","🦆\n","Aha! Apply applies functions to modules using Postorder Traversal method!\n","I think I understand now!\n","```\n","\n","- [4 Types of Tree Traversal Algorithms - Towards Data Science](https://towardsdatascience.com/4-types-of-tree-traversal-algorithms-d56328450846)"]},{"cell_type":"markdown","metadata":{"id":"RX9s5bAEZR81"},"source":["##### 💡 model apply - weight initialization\n","\n","\n","``` python\n","🦆\n","The term weight initialization is unfamiliar\n","As expected, it was right to initialize the parameter value!\n","\n","The model I made has a total of 4 parameters, so let's reset all the values to 1!\n","```\n","\n","🎁 **힌트** 🎁\n","- [How to initialize weights in PyTorch? - Stack Overflow](https://stackoverflow.com/questions/49433936/how-to-initialize-weights-in-pytorch)"]},{"cell_type":"code","metadata":{"id":"FJHv20B8ZR9E"},"source":["import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","\n","\n","# You do not need to modify the code below!\n","# Just do it and move on to the next cell!\n","\n","# Function\n","class Function_A(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(1))\n","\n","    def forward(self, x):\n","        return x + self.W\n","\n","class Function_B(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(1))\n","\n","    def forward(self, x):\n","        return x - self.W\n","\n","class Function_C(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(1))\n","\n","    def forward(self, x):\n","        return x * self.W\n","\n","class Function_D(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(1))\n","\n","    def forward(self, x):\n","        return x / self.W\n","\n","\n","# Layer\n","class Layer_AB(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.a = Function_A('plus')\n","        self.b = Function_B('substract')\n","\n","    def forward(self, x):\n","        x = self.a(x)\n","        x = self.b(x)\n","\n","        return x\n","\n","class Layer_CD(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.c = Function_C('multiply')\n","        self.d = Function_D('divide')\n","\n","    def forward(self, x):\n","        x = self.c(x)\n","        x = self.d(x)\n","\n","        return x\n","\n","\n","# Model\n","class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.ab = Layer_AB()\n","        self.cd = Layer_CD()\n","\n","    def forward(self, x):\n","        x = self.ab(x)\n","        x = self.cd(x)\n","\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_jifkSJbZR9F","executionInfo":{"status":"ok","timestamp":1627657017005,"user_tz":-540,"elapsed":3,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"a4d69755-4ab5-4dee-8694-361a6bbfc3c0"},"source":["model = Model()\n","\n","# TODO : Use apply to set all parameter values to 1\n","\n","def weight_initialization(module):\n","    module_name = module.__class__.__name__\n","\n","\n","# 🦆 Please return the module that has been applied!\n","\n","returned_module = model.apply(weight_initialization)\n","\n","\n","# You do not need to modify the code below!\n","x = torch.rand(1)\n","\n","output = model(x)\n","\n","if torch.isclose(output, x):\n","    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","else:\n","    print(\"🦆 다시 도전해봐요!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["🦆 다시 도전해봐요!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tXUDj5guCimd"},"source":["``` python\n","🦆\n","When you take the Pretrained model and use it, use the parameter that you want\n","I think it's possible to add a backup hook!\n","```"]},{"cell_type":"markdown","metadata":{"id":"g_Aa_VhGg5ds"},"source":["##### 💡 <font color='yellow'><b>[ Optional ]</b></font> 🔥  Model apply - Modify repr 🔥\n","\n","``` python\n","🦆\n","If you print out the current model, it looks like this!\n","\n","❌ 실제 출력 결과\n","Model(\n","  (ab): Layer_AB(\n","    (a): Function_A()\n","    (b): Function_B()\n","  )\n","  (cd): Layer_CD(\n","    (c): Function_C()\n","    (d): Function_D()\n","  )\n",")\n","\n","I want to make it printed as follows.\n","\n","✅ ideal output\n","\n","Model(\n","  (ab): Layer_AB(\n","    (a): Function_A(name=plus)\n","    (b): Function_B(name=substract)\n","  )\n","  (cd): Layer_CD(\n","    (c): Function_C(name=multiply)\n","    (d): Function_D(name=divide)\n","  )\n",")\n","\n","Let's modify repr output message using apply!\n","```\n","\n","🎁 **힌트** 🎁\n","- [Any elegant way to add a method to an existing object in python? - Stack Overflow](https://stackoverflow.com/questions/30294458/any-elegant-way-to-add-a-method-to-an-existing-object-in-python/30294947)"]},{"cell_type":"code","metadata":{"id":"UR1C9k7-g-my"},"source":["#@title 부덕이 모델\n","import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","\n","\n","# You do not need to modify the code below!\n","# Just do it and move on to the next cell!\n","\n","\n","# Function\n","class Function_A(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(1))\n","\n","    def forward(self, x):\n","        return x + self.W\n","\n","class Function_B(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(1))\n","\n","    def forward(self, x):\n","        return x - self.W\n","\n","class Function_C(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(1))\n","\n","    def forward(self, x):\n","        return x * self.W\n","\n","class Function_D(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(1))\n","\n","    def forward(self, x):\n","        return x / self.W\n","\n","\n","# Layer\n","class Layer_AB(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.a = Function_A('plus')\n","        self.b = Function_B('substract')\n","\n","    def forward(self, x):\n","        x = self.a(x)\n","        x = self.b(x)\n","\n","        return x\n","\n","class Layer_CD(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.c = Function_C('multiply')\n","        self.d = Function_D('divide')\n","\n","    def forward(self, x):\n","        x = self.c(x)\n","        x = self.d(x)\n","\n","        return x\n","\n","\n","# Model\n","class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.ab = Layer_AB()\n","        self.cd = Layer_CD()\n","\n","    def forward(self, x):\n","        x = self.ab(x)\n","        x = self.cd(x)\n","\n","        return x\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OOq-Hv_ruX-y","executionInfo":{"status":"ok","timestamp":1627657136585,"user_tz":-540,"elapsed":10,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"7f537218-e8db-4e80-d63b-b9cdfb953404"},"source":["model = Model()\n","\n","# TODO : Use apply to modify the repr output as Budeok wants!\n","from functools import partial\n","\n","def function_repr(self):\n","    return f'name={self.name}'\n","\n","def add_repr(module):\n","    module_name = module.__class__.__name__\n","\n","\n","\n","# 🦆 Please return the module that has been `apply`!\n","\n","returned_module = model.apply(add_repr)\n","\n","\n","# The following code is a modification aren't necessary!\n","\n","model_repr = repr(model)\n","\n","print(\"모델 출력 결과\")\n","print(\"-\" * 30)\n","print(model_repr)\n","print(\"-\" * 30)\n","\n","answer = \"Model(\\n  (ab): Layer_AB(\\n    (a): Function_A(name=plus)\\n    (b): Function_B(name=substract)\\n  )\\n  (cd): Layer_CD(\\n    (c): Function_C(name=multiply)\\n    (d): Function_D(name=divide)\\n  )\\n)\"\n","\n","if model_repr == answer:\n","    print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","    print(\"🦆 너무 고마워요 꽉꽉!\")\n","else:\n","    print(\"🦆 다시 도전해봐요!\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["모델 출력 결과\n","------------------------------\n","Model(\n","  (ab): Layer_AB(\n","    (a): Function_A()\n","    (b): Function_B()\n","  )\n","  (cd): Layer_CD(\n","    (c): Function_C()\n","    (d): Function_D()\n","  )\n",")\n","------------------------------\n","🦆 다시 도전해봐요!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RYMJgAEQZR9G"},"source":["``` python\n","🦆\n","Can be! at any time want to add to the model desired module method\n","Something where, and applications will be a lot!\n","```"]},{"cell_type":"markdown","metadata":{"id":"dim6OGlSD4Hk"},"source":["##### 💡 <font color='yellow'><b>[ Optional ]</b></font> 🔥🔥🔥 부덕이 모델 apply - Modify `Function` (Black Magic)\n","🔥🔥🔥\n","\n","``` python\n","🦆\n","My friend looked at my model's code and gave me a question!\n","\n","There are currently four functions A, B, C, and D!\n","\n","- A : x + W\n","- B : x - W\n","- C : x * W\n","- D : x / W\n","\n","Change it to act like linear transformation like this!\n","\n","\n","- A : x @ W + b\n","- B : x @ W + b\n","- C : x @ W + b\n","- D : x @ W + b\n","\n","W is the parameter already created for each function\n","B is a new parameter!\n","\n","They say the calculation formula doesn't have to be the same, but the calculation should be the same!\n","They're going to verify that they made it using the \"nn.Linear\" model themselves!\n","\n","In order to compare the results, both W and B initialize the values to 1!\n","\n","Oh, now of value is to tensor scalar, not.\n","The size of 2 * 2! be careful on the fact that matrix\n","For some reason, I went and I never tease me that I can solve with!💢\n","```\n","\n","🎁 **힌트** 🎁\n","- forward hook"]},{"cell_type":"code","metadata":{"id":"POOWtst-zqip"},"source":["#@title Test 코드\n","\n","# code is under revision aren't necessary!\n","\n","def tester(model, friend_model):\n","    x = torch.rand(2, 2, requires_grad=True)\n","\n","    # The model we created\n","    output = model(x)\n","    output = output.sum()\n","    output.backward()\n","\n","    our_grad = x.grad.clone()\n","    grads = [(name, param.grad) for name, param in model.named_parameters()]\n","\n","    x.grad = None\n","\n","    # A friend-generated model\n","    friend_output = friend_model(x)\n","    friend_output = friend_output.sum()\n","    friend_output.backward()\n","\n","    friend_grad = x.grad.clone()\n","    friend_grads = [(name, param.grad) for name, param in friend_model.named_parameters()]\n","\n","    # a total result\n","    total_result = 0\n","\n","    # Compare the number of parameters\n","    if len(grads) == len(friend_grads):\n","        print(\"\\x1b[32m[PASS]\\x1b[0m 두 모델이 같은 Parameter 갯수를 가지네요!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m 두 모델이 다른 Parameter 갯수를 가지네요!\")\n","        print(f\"🦆 우리 모델 Parameter 갯수 : {len(grads)} 🐦 친구 모델 Parameter 갯수 : {len(friend_grads)}\")\n","        return\n","\n","    print(\"-\" * 50)\n","\n","    # Parameter name check\n","    params = []\n","    for grad in grads:\n","        param = ''.join(grad[0].split('.')[1:])\n","        params.append(param)\n","\n","    if 'ab' in params:\n","        print(\"\\x1b[32m[PASS]\\x1b[0m Function_A에 Parameter b를 만드셨네요!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m Function_A에 Parameter b가 없어요!\")\n","        return\n","    print(\"-\" * 50)\n","\n","    if 'bb' in params:\n","        print(\"\\x1b[32m[PASS]\\x1b[0m Function_B에 Parameter b를 만드셨네요!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m Function_B에 Parameter b가 없어요!\")\n","        return\n","    print(\"-\" * 50)\n","\n","    if 'cb' in params:\n","        print(\"\\x1b[32m[PASS]\\x1b[0m Function_C에 Parameter b를 만드셨네요!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m Function_C에 Parameter b가 없어요!\")\n","        return\n","    print(\"-\" * 50)\n","\n","    if 'db' in params:\n","        print(\"\\x1b[32m[PASS]\\x1b[0m Function_D에 Parameter b를 만드셨네요!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m Function_D에 Parameter b가 없어요!\")\n","        return\n","    print(\"-\" * 50)\n","\n","    # Parameter initialization check\n","    if torch.all(torch.stack([torch.all(param == 1) for param in model.parameters()])):\n","        print(\"\\x1b[32m[PASS]\\x1b[0m Parameter W, b를 모두 1로 초기화시키셨네요!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m Parameter W, b를 모두 1로 초기화시키세요!\")\n","        return\n","    print(\"-\" * 50)\n","\n","    # Check the model output value\n","    if torch.isclose(output, friend_output):\n","        print(\"\\x1b[32m[PASS]\\x1b[0m 두 모델이 동일한 출력값을 가지네요!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m 두 모델이 다른 출력값을 가지네요!\")\n","        print(f\"🦆 우리 모델 출력값 : {output:.2f} 🐦 친구 모델 출력값 : {friend_output:.2f}\")\n","    print(\"-\" * 50)\n","\n","    # Input value x gradient check\n","    if torch.all(torch.isclose(our_grad, friend_grad)):\n","        print(\"\\x1b[32m[PASS]\\x1b[0m 입력에 사용된 x가 동일한 Gradient 값을 가지네요!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m 입력에 사용된 x가 다른 Gradient 값을 가지네요!\")\n","        print(f\"🦆 우리 모델 x grad 값\\n{our_grad}\\n🐦 친구 모델 x grad 값\\n{friend_grad}\")\n","    print(\"-\" * 50)\n","\n","    # Function A gradient check\n","    if torch.all(torch.isclose(grads[0][1], friend_grads[0][1])):\n","        print(\"\\x1b[32m[PASS]\\x1b[0m Function_A Parameter W가 동일한 Gradient 값을 가지네요!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m Parameter W가 다른 Gradient 값을 가지네요!\")\n","        print(f\"🦆 우리 모델 Function_A Parameter W grad 값\\n{grads[0][1]}\\n🐦 친구 모델 nn.Linear Parameter W grad 값\\n{friend_grads[0][1]}\")\n","    print(\"-\" * 50)\n","\n","    if torch.all(torch.isclose(grads[1][1], friend_grads[1][1])):\n","        print(\"\\x1b[32m[PASS]\\x1b[0m Function_A Parameter b가 동일한 Gradient 값을 가지네요!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m Parameter b가 다른 Gradient 값을 가지네요!\")\n","        print(f\"🦆 우리 모델 Function_A Parameter b grad 값\\n{grads[1][1]}\\n🐦 친구 모델 nn.Linear Parameter b grad 값\\n{friend_grads[1][1]}\")\n","    print(\"-\" * 50)\n","\n","    # Function B gradient check\n","    if torch.all(torch.isclose(grads[2][1], friend_grads[2][1])):\n","        print(\"\\x1b[32m[PASS]\\x1b[0m Function_B Parameter W가 동일한 Gradient 값을 가지네요!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m Parameter W가 다른 Gradient 값을 가지네요!\")\n","        print(f\"🦆 우리 모델 Function_B Parameter W grad 값\\n{grads[2][1]}\\n🐦 친구 모델 nn.Linear Parameter W grad 값\\n{friend_grads[2][1]}\")\n","    print(\"-\" * 50)\n","\n","    if torch.all(torch.isclose(grads[3][1], friend_grads[3][1])):\n","        print(\"\\x1b[32m[PASS]\\x1b[0m Function_B Parameter b가 동일한 Gradient 값을 가지네요!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m Parameter b가 다른 Gradient 값을 가지네요!\")\n","        print(f\"🦆 우리 모델 Function_B Parameter b grad 값\\n{grads[3][1]}\\n🐦 친구 모델 nn.Linear Parameter b grad 값\\n{friend_grads[3][1]}\")\n","    print(\"-\" * 50)\n","\n","    # Function C gradient check\n","    if torch.all(torch.isclose(grads[4][1], friend_grads[4][1])):\n","        print(\"\\x1b[32m[PASS]\\x1b[0m Function_C Parameter W가 동일한 Gradient 값을 가지네요!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m Parameter W가 다른 Gradient 값을 가지네요!\")\n","        print(f\"🦆 우리 모델 Function_C Parameter W grad 값\\n{grads[4][1]}\\n🐦 친구 모델 nn.Linear Parameter W grad 값\\n{friend_grads[4][1]}\")\n","    print(\"-\" * 50)\n","\n","    if torch.all(torch.isclose(grads[5][1], friend_grads[5][1])):\n","        print(\"\\x1b[32m[PASS]\\x1b[0m Function_C Parameter b가 동일한 Gradient 값을 가지네요!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m Parameter b가 다른 Gradient 값을 가지네요!\")\n","        print(f\"🦆 우리 모델 Function_C Parameter b grad 값\\n{grads[5][1]}\\n🐦 친구 모델 nn.Linear Parameter b grad 값\\n{friend_grads[5][1]}\")\n","    print(\"-\" * 50)\n","\n","    # Function D gradient check\n","    if torch.all(torch.isclose(grads[6][1], friend_grads[6][1])):\n","        print(\"\\x1b[32m[PASS]\\x1b[0m Function_D Parameter W가 동일한 Gradient 값을 가지네요!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m Parameter W가 다른 Gradient 값을 가지네요!\")\n","        print(f\"🦆 우리 모델 Function_D Parameter W grad 값\\n{grads[6][1]}\\n🐦 친구 모델 nn.Linear Parameter W grad 값\\n{friend_grads[6][1]}\")\n","    print(\"-\" * 50)\n","\n","    if torch.all(torch.isclose(grads[7][1], friend_grads[7][1])):\n","        print(\"\\x1b[32m[PASS]\\x1b[0m Function_D Parameter b가 동일한 Gradient 값을 가지네요!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m Parameter b가 다른 Gradient 값을 가지네요!\")\n","        print(f\"🦆 우리 모델 Function_D Parameter b grad 값\\n{grads[7][1]}\\n🐦 친구 모델 nn.Linear Parameter b grad 값\\n{friend_grads[7][1]}\")\n","    print(\"-\" * 50)\n","\n","\n","    if total_result == 16:\n","        print(f\"\\x1b[32m[ALL PASS {total_result}/16]\\x1b[0m 🎉🎉🎉 성공!!! 🎉🎉🎉\")\n","    else:\n","        print(f\"\\x1b[31m[FAIL {total_result}/16]\\x1b[0m 🦆 다시 도전해봐요!\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9fvtuqHDD4H2"},"source":["#@title 부덕이 모델\n","import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","\n","\n","# You do not need to modify the code below!\n","# Just do it and move on to the next cell!\n","\n","# Function\n","class Function_A(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(2, 2))\n","\n","    def forward(self, x):\n","        return x + self.W\n","\n","class Function_B(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(2, 2))\n","\n","    def forward(self, x):\n","        return x - self.W\n","\n","class Function_C(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(2, 2))\n","\n","    def forward(self, x):\n","        return x * self.W\n","\n","class Function_D(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(2, 2))\n","\n","    def forward(self, x):\n","        return x / self.W\n","\n","\n","# Layer\n","class Layer_AB(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.a = Function_A('plus')\n","        self.b = Function_B('substract')\n","\n","    def forward(self, x):\n","        x = self.a(x)\n","        x = self.b(x)\n","\n","        return x\n","\n","class Layer_CD(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.c = Function_C('multiply')\n","        self.d = Function_D('divide')\n","\n","    def forward(self, x):\n","        x = self.c(x)\n","        x = self.d(x)\n","\n","        return x\n","\n","\n","# Model\n","class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.ab = Layer_AB()\n","        self.cd = Layer_CD()\n","\n","    def forward(self, x):\n","        x = self.ab(x)\n","        x = self.cd(x)\n","\n","        return x\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hE_Tl4H_kSp3","executionInfo":{"status":"ok","timestamp":1627657254915,"user_tz":-540,"elapsed":282,"user":{"displayName":"hyunbyung Park","photoUrl":"","userId":"12748043846851568306"}},"outputId":"23682b1e-3e63-4421-8f83-3baceaa30178"},"source":["model = Model()\n","\n","\n","# TODO : Add Parameter b using apply!\n","def add_bias(module):\n","    module_name = module.__class__.__name__\n","\n","\n","# TODO : Please initialize the added b degree value to 1 using the application!\n","def weight_initialization(module):\n","    module_name = module.__class__.__name__\n","\n","    if module_name.split('_')[0] == \"Function\":\n","        module.W.data.fill_(1.)\n","\n","\n","# TODO : Use apply to change all functions to linear transformation!\n","\n","#        X @ W + b\n","def linear_transformation(module):\n","    module_name = module.__class__.__name__\n","\n","    if module_name == \"Function_A\":\n","        pass\n","\n","\n","returned_module = model.apply(add_bias)\n","returned_module = model.apply(weight_initialization)\n","returned_module = model.apply(linear_transformation)\n","\n","\n","\n","# 🦆 A friend of comparisons to the code and drew up!\n","\n","class FriendLinearModel(nn.Module):\n","    def __init__(self):\n","        super().__init__() \n","        self.linear = nn.Sequential(nn.Linear(2, 2),\n","                                    nn.Linear(2, 2),\n","                                    nn.Linear(2, 2),\n","                                    nn.Linear(2, 2))\n","\n","    def forward(self, x):\n","        return self.linear(x)\n","\n","def friends_init_weights(m):\n","    if type(m) == nn.Linear:\n","        m.weight.data.fill_(1.0)\n","        m.bias.data.fill_(1.0)\n","\n","friend_model = FriendLinearModel()\n","friend_model.apply(friends_init_weights)\n","\n","\n","# 🦆 체크해보세요!\n","grads = tester(model, friend_model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[31m[FAIL]\u001b[0m 두 모델이 다른 Parameter 갯수를 가지네요!\n","🦆 우리 모델 Parameter 갯수 : 4 🐦 친구 모델 Parameter 갯수 : 8\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"t_Ka8OvED4H4"},"source":["``` python\n","🦆\n","252 / 5000발음듣기복사하기필기인식기번역하기자동완성자동완성\t\n","영어열기/닫기 아이콘\n","Bear in mind this point!\n","\n","Hugh really hard!But I'm totally shocked!\n","Never risk angering the model code already been produced and into new models!\n","Even \"a nn linear\" models and fully carried out as of the pytorch!\n","All!, forward backward\n","\n","Is not only can do, but using apply using apply, I do it. \"\n","I feel increased readability and the function is under control!\n","\n","But Where is the use of it?\n","```\n","```python\n","🐦\n","\n","I heard you helped me a lot with this assignment!\n","As expected, there's no way that Boo-duk can do this alone!\n","\n","In the future, you'll be using a lot of pretrained models using PyTorch\n","There may be bugs in the model itself or things that need to be modified.\n","In this case, training to modify the model you practiced here today will be of great help!\n","\n","Honestly, I didn't know I'd solve it, but I was really surprised! I give you my compliments!\n","```"]},{"cell_type":"markdown","metadata":{"id":"aI-eQLReB_b0"},"source":["### 🎉🎉🎉 nn.Module 완료! 🎉🎉🎉\n","\n","```python\n","🦆\n","I can't believe I've come this far!\n","I didn't know anything about PyTorch, so now I can make the model I want!\n","I know I still have a lot to learn, but I'm so happy!\n","```\n","\n","To create a custom model\n","Congratulations on successfully finishing the show even though it was not a small amount! 🎉<br>\n","This chapter was as difficult as Documentation.<br>\n","But you've come all the way here after overcoming it all! This is a really great thing.\n","\n","I'm sure you're very tired! But don't worry! Now that we've come this far, it's all over<br>\n","It's about Github, but it's close to a resting corner.<br>\n","It doesn't take much time and the content is short, so you can relax now!<br>"]},{"cell_type":"markdown","metadata":{"id":"gsjw07-c6Vgf"},"source":["## 🚀 <font color='yellow'><b>[ Optional ]</b></font> See Github for Custom Model Creation\n","\n","\n","```\n","💡 How are other people creating custom models?\n","We will have time to visit Github and find out the answer.\n","```\n","\n","# 🌍🐣\n","We're ready to build custom models!<br>\n","Although it was not an easy journey, you made it and now you are ready to go on a trip.<br>\n","It's time to leave the Earth.\n","\n","# ⭐🐤\n","There are various and complex models in the world. The knowledge I learned here is that there aren't as many huge, complex, flashy models as there are stars in the universe, but there are so many. The knowledge I learned here isn't much, but it's now enough to stand up and face the models. If you want to back down because it's difficult to fill in the gaps, it's time to hold out and move on. To the shining stars!\n","\n","# 🚀\n","Shall we go meet the aliens who created the stars?\n","\n","- 🛸 Find the Github Model\n","- 🛸 Github Model License Check\n","- 🛸 Explore the Github Repository\n","- 🛸 Quote the Github model"]},{"cell_type":"markdown","metadata":{"id":"7hmoOk31nohg"},"source":["### 🛸 Github 모델 찾기\n","> Let's take a quick look at some of the ways to find the Github model you want.\n","\n","\n","- 📖 <font color='gold' ><b>[ 읽기 ]</b></font> 구글 고급 검색 (Google Advanced Search)\n","- 📖 <font color='gold' ><b>[ 읽기 ]</b></font> 깃헙 고급 검색 (Github Advanced Search)\n","- 📖 <font color='gold' ><b>[ 읽기 ]</b></font> Model Curation Site\n"]},{"cell_type":"markdown","metadata":{"id":"OhQbpvUgaT45"},"source":["#### 📖 <font color='gold' ><b>[ 읽기 ]</b></font> 구글 고급 검색 (Google Advanced Search)\n","``` python\n","🦆\n","I'm sure you thought of this chapter as soon as you came here!\n","Google is the must-see search tool of the day!\n","\n","But Google doesn't just search for the words it typed\n","Did you know that there are many different search options?\n","\n","Google Search is a program, too!\n","There's no way a well-made program doesn't have options!\n","The Google search window that you use is\n","In shell terms, it's an input box that takes commands!\n","\n","But in general, we just search for words and end it\n","I don't know what options Google Search has!\n","At times like these, the thing that anyone can use easily is\n","It's Google Advanced Search!\n","\n","Go to the link below and try it out!\n","If you fill in the items you want, you can enter them in the Google search box\n","Change it to a suitable query and search instead!\n","```\n","\n","- [Google Advanced Search](https://www.google.com/advanced_search)"]},{"cell_type":"markdown","metadata":{"id":"k0IQvtE8aUEY"},"source":["#### 📖 <font color='gold' ><b>[ 읽기 ]</b></font> 깃헙 고급 검색 (Github Advanced Search)\n","``` python\n","🦆\n","Did you know that Github is also capable of advanced search?\n","We offer a variety of options like Google, so let's take a look!\n","```\n","\n","- [Github Advanced Search](https://github.com/search/advanced)"]},{"cell_type":"markdown","metadata":{"id":"Bb_DEzPpaRc9"},"source":["#### 📖 <font color='gold' ><b>[ 읽기 ]</b></font> Model Curation Site\n","\n","``` python\n","🦆\n","If you're not looking for a particular model, you're looking at the overall trend of the model\n","Visiting a curation site is one way!\n","```\n","\n","- [Browse State-of-the-Art - Papers With Code](https://paperswithcode.com/sota)\n","- [labml.ai Annotated PyTorch Paper Implementations - labml.ai](https://nn.labml.ai/)\n","- [awesome-deeplearning-resources - endymecy](https://endymecy.github.io/awesome-deeplearning-resources/awesome_projects.html)"]},{"cell_type":"markdown","metadata":{"id":"aowwiHAz3I2c"},"source":["### 🛸 Github Model License Check\n","> Once you find the Github model, you must first verify your license. Check whether the original author allowed the model to be used freely, or whether the code was restricted to be used to prevent future legal problems.\n","\n","- 📖 <font color='gold' ><b>[ 읽기 ]</b></font> Open Source License Types\n","\n","- 📖 <font color='gold' ><b>[ 읽기 ]</b></font> Github Model License Check\n","\n","- 📖 <font color='gold' ><b>[ 읽기 ]</b></font> Can I use a model that doesn't show a license?\n"]},{"cell_type":"markdown","metadata":{"id":"EGO21TZ0N_Iu"},"source":["#### 📖 <font color='gold' ><b>[ 읽기 ]</b></font> Open Source License Types\n","\n","\n","``` python\n","🦆\n","Before you verify the license of the model found in Github,\n","It's important to know what kinds of open source licenses are first!\n","\n","It's well organized on the site below, so let's watch it together!\n","```\n","\n","- [Choosing the right license - Github Docs](https://docs.github.com/en/github/creating-cloning-and-archiving-repositories/creating-a-repository-on-github/licensing-a-repository#choosing-the-right-license)\n","- [Choose an open source license - Choose AI License](https://choosealicense.com/)\n","- [오픈소스를 사용하고 준비하는 개발자를 위한 가이드 - if(kakao) dev 2018](https://tv.kakao.com/channel/3150758/cliplink/391717603)"]},{"cell_type":"markdown","metadata":{"id":"q2IFscSgPqj0"},"source":["#### 📖 <font color='gold' ><b>[ 읽기 ]</b></font> Github 모델 라이센스 체크\n","\n","``` python\n","🦆\n","Hugging Face is a really famous library for natural language processing!\n","Shall we look at the licenses of the transformers model together?\n","```\n","\n","- [transformers - Hugging Face Github](https://github.com/huggingface/transformers)\n"]},{"cell_type":"markdown","metadata":{"id":"0oOO5qzH2vXq"},"source":["![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/hugging%20face%20license.png?raw=true)\n","![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/apache%20license%202.0.png?raw=true)"]},{"cell_type":"markdown","metadata":{"id":"tApDeubq27rZ"},"source":["``` python\n","🦆\n","\n","It's following Apache License 2.0!\n","It's a free license that's commercially available!\n","But if you take the source code and use it, you have to specify the license and copyright\n","If you modified the source code you took and used, you have to specify this as well!\n","\n","There are restrictions, but even if you make commercial products using the hugging face,\n","You don't have to reveal the code, so you can use it to make the product with confidence!\n","\n","Since we're talking about licenses, as above,\n","Is it legal to take screenshots of Github's products? Is it illegal?\n","\n","If you are curious, please find the link below for the screenshot!\n","```\n","\n","**✨ 유용한 자료 ✨**\n","- [Apache License 2.0 - OLIS](https://www.olis.or.kr/license/Detailselect.do?lId=1002&mapCode=010002)\n","- [Commons:Screenshots - Wikimedia Commons](https://commons.wikimedia.org/wiki/Commons:Screenshots)"]},{"cell_type":"markdown","metadata":{"id":"D1Jje0IwRejE"},"source":["#### 📖 <font color='gold' ><b>[ 읽기 ]</b></font> Can I use a model that doesn't show a license?\n","\n","\n","``` python\n","🦆\n","Github on license when looked in the various models when there was no!\n","May I use these models.?\n","\n","The following documents, find out together!\n","```\n","\n","- [No License - Choose AI License](https://choosealicense.com/no-permission/)"]},{"cell_type":"markdown","metadata":{"id":"C5EzHAPj3LW8"},"source":["### 🛸 Github Repository 탐색\n","> Github provides the ability to navigate Repository. Let's take a quick look at how to take advantage of it.\n","\n","- 📖 <font color='gold' ><b>[ 읽기 ]</b></font> Find models hidden in the Repository\n","\n","- 📖 <font color='gold' ><b>[ 읽기 ]</b></font> View transformers.py Internal Table of Contents\n"]},{"cell_type":"markdown","metadata":{"id":"rSyB0wutN_Oi"},"source":["#### 📖 <font color='gold' ><b>[ 읽기 ]</b></font> Find models hidden in the Repository\n","\n","\n","``` python\n","🦆\n","I'm trying to find the Transformer model code on the official Github code base of PyTorch\n","As soon as I enter the main page of PyTorch's official Github, I'm already dizzy with that huge amount of code!\n","\n","My friend who didn't see me told me to use the search function provided by Github!\n","```\n","\n","- [PyTorch - Github](https://github.com/pytorch/pytorch)"]},{"cell_type":"markdown","metadata":{"id":"K4TqNcE3PZbi"},"source":["``` python\n","🦆\n","Github 검색하는 곳을 찾았어요!\n","```\n","\n","![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/github%20-%20pytorch.png?raw=true)"]},{"cell_type":"markdown","metadata":{"id":"og22SSY0QHxY"},"source":["``` python\n","🦆\n","When I enter transformer, there are 3 types of searches!\n","\n","- In this repository\n","- In this organization\n","- All Github\n","\n","What we want is to search inside the Repository, so we pressed the top one!\n","```\n","\n","![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/github%20-%20pytorch%20-%20search%20bar.png?raw=true)"]},{"cell_type":"markdown","metadata":{"id":"upJpvsqvQna2"},"source":["``` python\n","🦆\n","The result of the transformer search appears in the PyTorch official code!\n","But what I want is not a transformer model with c++ code\n","It's a transformer model made of python!\n","\n","Should I scroll down a little bit?\n","```\n","\n","![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/github%20-%20pytorch%20-%20transformer.png?raw=true)"]},{"cell_type":"markdown","metadata":{"id":"FnRVVIycQ8Cj"},"source":["``` python\n","🦆\n","transformer.py! I found it! I think we can click and go in now!\n","\n","I can't believe me! What a nice search box!\n","```\n","\n","![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/github%20-%20pytorch%20-%20transformer%20found.png?raw=true)"]},{"cell_type":"markdown","metadata":{"id":"E5k7RfnzRRo9"},"source":["``` python\n","🦆\n","Class Transformer! This is exactly the model I wanted!\n","\n","Looking at the path, it`s pytorch/torch/nn/modules/transformer.py!\n","I'd be pretty lost if I tried to find it myself!\n","```\n","\n","![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/transformers.png?raw=true)"]},{"cell_type":"markdown","metadata":{"id":"pSIGoFyWRoJ2"},"source":["#### 📖 <font color='gold' ><b>[ 읽기 ]</b></font> View transformers.py Internal Table of Contents\n","\n","\n","``` python\n","🦆\n","If you want to check what classes and functions are available on transformer.py,\n","It would be troublesome to scroll down and check, right?\n","\n","Where can I find a table of contents inside transformers.py?\n","```\n","\n","- [transformer.py - Github](https://github.com/pytorch/pytorch/blob/35307b131df9d24bfa96103d6061cf14c797ee32/torch/nn/modules/transformer.py)"]},{"cell_type":"markdown","metadata":{"id":"gq6zcLvVRpXB"},"source":["``` python\n","🦆\n","빨간색 박스의 Jump to를 이용하면 좋아요!\n","```\n","\n","![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/transformer%20-%20jump%20to.png?raw=true)"]},{"cell_type":"markdown","metadata":{"id":"ZziNxuyzSNKE"},"source":["``` python\n","🦆\n","Each function and class is shown in the order, can you see it?\n","Scroll does not explore with the complex code table of contents can see!\n","```\n","\n","![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/transformers%20-%20insider%20search.png?raw=true)"]},{"cell_type":"markdown","metadata":{"id":"u7iF0gyR3dZa"},"source":["### 🛸 Github 모델 인용\n","> Github에서 레퍼런스(Reference) 모델을 성공적으로 찾은 이후 pip install, 복사 붙여넣기, 혹은 git clone 등 자신만의 방법으로 모델 코드를 가져왔을 것입니다.In general, we are often leave a link or let it go.However, in a direct quote is a courtesy for authorship in principle cited (cite) with precisely the time to see how lightly.\n","\n","- 📖 <font color='gold' ><b>[ 읽기 ]</b></font> If a Citation is provided\n","\n","- 📖 <font color='gold' ><b>[ 읽기 ]</b></font> If the Citation is not available\n"]},{"cell_type":"markdown","metadata":{"id":"HxAcbyy-axop"},"source":["#### 📖 <font color='gold' ><b>[ 읽기 ]</b></font>  If a Citation is provided\n","\n","``` python\n","🦆\n","Like PyTorch and Hugging Face, famous and official\n","Github projects usually provide Citations!\n","\n","However, the reference model is part of it\n","We don't offer Citations for each Github page!\n","\n","So here, I'm going to quote the Github model, which is where the Github model belongs\n","Please be careful to replace the Repository quote!\n","```\n","```python\n","🐦 It's Github Repository City Citation!\n","```\n","- [PyTorch/CITATION - Github](https://github.com/pytorch/pytorch/blob/master/CITATION)\n","- [Huggingface/Transformers/citation - Github](https://github.com/huggingface/transformers#citation)\n","\n","```python\n","🐦 Most of them follow the BibTex format, so use the conversion below!\n","\n","```\n","- [BibTeX Online Converter](https://bibtex.online/)"]},{"cell_type":"markdown","metadata":{"id":"PY5Rm509gNHe"},"source":["#### 📖 <font color='gold' ><b>[ 읽기 ]</b></font> Citation이 제공되지 않을 경우\n","\n","``` python\n","🦆\n","It's always tricky to make your own quotes!\n","There are different ways to quote and it's troublesome to match it!\n","So in general, people quote roughly and pass it over!\n","\n","But at least here, let's find out how to quote properly!\n","```\n","```python\n","🐦 If you want to create your own Citations, we recommend below!\n","```\n","\n","- [How to Cite a GitHub Repository - Wiki How](https://www.wikihow.com/Cite-a-GitHub-Repository)\n","\n","```python\n","🐦 If you want an auto-completed city, you can do it at the following site!\n","\n","```\n","- [Free Harvard Citation Generator - Cite This For Me](https://www.citethisforme.com/citation-generator/harvard)"]},{"cell_type":"markdown","metadata":{"id":"AjV4kPz449Qf"},"source":["### 🎉🎉🎉 Github 완료! 🎉🎉🎉\n","\n","```python\n","🦆\n","We're finally at the end! It's time to say goodbye!\n","I'll never forget studying together!\n","\n","See you again on Earth after the Boost Camp journey!\n","I'm going back to Earth now!\n","```"]},{"cell_type":"markdown","metadata":{"id":"Ixzc0txuqmDb"},"source":["## 🎉🎊🎉 축하드려요! 끝까지 해내셨군요! 🎉🎊🎉\n","> This assignment contained a variety of but never a small amount of information about the custom model! Now you know what it takes to create a custom model, and if you're lacking something, you can find it and fill it out, and you have the knowledge to build the model you want! The process of getting here may never have been easy, but I hope it was worth it. I wish you the best of luck."]},{"cell_type":"code","metadata":{"cellView":"form","id":"v_fiPQLq700o","executionInfo":{"status":"ok","timestamp":1647584139086,"user_tz":-540,"elapsed":6,"user":{"displayName":"hyunbyung Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12748043846851568306"}},"outputId":"adf6ec04-7a63-4fe1-e07b-3997aac2978f","colab":{"base_uri":"https://localhost:8080/"}},"source":["#@title 부덕이가 축하의 춤을 춘대요!\n","from IPython.display import Image\n","Image(url='https://post-phinf.pstatic.net/MjAxODEyMzFfMTAw/MDAxNTQ2MjE0OTg5NjAz.EHOabmOFRb9Sd4H1C8xJWAjDd-AalUHZ0mGRQc8nLJgg.QaKd2fe0gct3mQ-Ex-8qqSS1RVXjoC_-NLXo80sAQNsg.GIF/mug_obj_201812310909504083.gif?type=w1080')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.Image object>"],"text/html":["<img src=\"https://post-phinf.pstatic.net/MjAxODEyMzFfMTAw/MDAxNTQ2MjE0OTg5NjAz.EHOabmOFRb9Sd4H1C8xJWAjDd-AalUHZ0mGRQc8nLJgg.QaKd2fe0gct3mQ-Ex-8qqSS1RVXjoC_-NLXo80sAQNsg.GIF/mug_obj_201812310909504083.gif?type=w1080\"/>"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","metadata":{"cellView":"form","id":"Eo7wLf2p7x_q","executionInfo":{"status":"ok","timestamp":1647584142984,"user_tz":-540,"elapsed":4,"user":{"displayName":"hyunbyung Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12748043846851568306"}},"outputId":"f623bde3-882b-478f-ce5d-754f7b403d21","colab":{"base_uri":"https://localhost:8080/"}},"source":["#@title 브레이크댄스!\n","from IPython.display import Image\n","Image(url='https://www.wetrend.co.kr/data/editor2/wit_board/2102/07/1612656261_3c92e94dc4e55df68f76b46053008df8')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.Image object>"],"text/html":["<img src=\"https://www.wetrend.co.kr/data/editor2/wit_board/2102/07/1612656261_3c92e94dc4e55df68f76b46053008df8\"/>"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"cellView":"form","id":"_9eeUgvl7M3O","executionInfo":{"status":"ok","timestamp":1647584146852,"user_tz":-540,"elapsed":6,"user":{"displayName":"hyunbyung Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12748043846851568306"}},"outputId":"8a5fb9d7-846a-42e4-9655-461a52cc4110","colab":{"base_uri":"https://localhost:8080/"}},"source":["#@title 여기서 멈출 수 없지! 춤춰 친구들!\n","from IPython.display import Image\n","Image(url='https://i.pinimg.com/originals/29/04/24/29042493fb118029b9014e4cb800c7ee.gif')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.Image object>"],"text/html":["<img src=\"https://i.pinimg.com/originals/29/04/24/29042493fb118029b9014e4cb800c7ee.gif\"/>"]},"metadata":{},"execution_count":3}]}]}