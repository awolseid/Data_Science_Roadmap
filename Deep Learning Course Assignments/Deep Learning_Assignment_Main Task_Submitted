{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Deep Learning_Assignment_Main Task","provenance":[{"file_id":"1i56_UtG4CaTA1_uVD4-jYcSSgcEE7D9A","timestamp":1653973667238},{"file_id":"11ZbQpXb6jl5EkiDvrQ0VdzQX-RFsSabw","timestamp":1653356278847},{"file_id":"1We-9x7fHGwxvsiQPoFvAkLcdj1NHJDjL","timestamp":1653356232688}],"collapsed_sections":["95QrHvgqadqg"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"95QrHvgqadqg"},"source":["##### ‚úîÔ∏è Î™©Ï∞® (Index)\n","``` python\n","ü¶Ü\n","PyTorch has a lot of things in it\n","It will be well organized in the table of contents so that people can easily find the content!\n","I think there`s a table of contents on the left side of Documentation! Let's take a look together!\n","```\n","\n","- ‚úÖ  click `[ - ]` in `python API`\n","    - ![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/+%20-%20button.png?raw=true)\n","- ‚úÖ Check index\n","    - Notes\n","    - Language Bindings\n","    - Python API\n","    - Libraries\n","    - Community\n","- ‚úÖ Review the subtopic of the python API\n","- ‚úÖ Lightly read any subtopic of the Python API\n","    - ex) `torch.nn`\n","- ‚úÖ python API - To check the internal table of contents of a torch document\n","    - [TORCH - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/torch.html)\n","    - ![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/table%20of%20content%20-%20torch.png?raw=true)\n","    \n"]},{"cell_type":"markdown","metadata":{"id":"tSwYkTH_lgsz"},"source":["##### ‚úîÔ∏è Search\n","``` python\n","ü¶Ü\n","There`s a table of contents, so it looks easy to find what you want,\n","If you`re not familiar with it, you`ll be wandering for a long time to find what you want!\n","I think we can use search bar to find what we want right away!\n","```\n","\n","- ‚úÖ Check the search bar \n","    - ![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/pytorch%20search%20bar.png?raw=true)\n","- ‚úÖ Search any keyword you want\n","    - ex) duck\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VfkQ0jmGbSmX"},"source":["#### ‚ùì <font color='red'><b>[ ÌÄ¥Ï¶à ]</b></font> PyTorch Release Status (Î∞∞Ìè¨ ÏÉÅÌÉú)\n","``` python\n","ü¶Ü\n","There's a lot in PyTorch! Stop looking around\n","I'm back on the main page, and there's an explanation about the release status!\n","Stable, Beta, and Prototype. Please tell me what Beta is!\n","```\n","- [Documentation main - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/index.html)"]},{"cell_type":"markdown","metadata":{"id":"5X_RYE6szDXr"},"source":["```python\n","üòÆ\n","# TODO: It's a matter of absolute certainty. Please read the document and write down the answers freely\n","Uh, um, I mean, What is Beta?\n","\n","```\n","Depending on the feedback of users, the API may be changed for an improved performance. This change API is also expected to maintain backwards compatibility. Such a Beta level features, the value add has been proven and the feature generally works and is documented. Such experimental features are named as Beta."]},{"cell_type":"markdown","metadata":{"id":"JQsWM-vgqV17"},"source":["### üåì Navigating information in Documentation\n","\n","> Most solutions can be found right away through googling, and everyone who reads this now will already be using it well. However, not all of Documentation's information comes from googling all the time, so let's practice how to find information with Documentation only without googling!\n","\n","- ‚ùì <font color='red'><b>[ ÌÄ¥Ï¶à ]</b></font> Leverage the search capabilities provided by Documentation\n","\n","- üîé <font color='orange'><b>[ ÌÉêÏÉâ ]</b></font> Look at the table of contents and find the information you want"]},{"cell_type":"markdown","metadata":{"id":"33PuuiWGZhz5"},"source":["#### ‚ùì <font color='red'><b>[ ÌÄ¥Ï¶à ]</b></font> Leverage the search capabilities provided by Documentation\n","\n","\n","``` python\n","ü¶Ü\n","I want to find out what I`m curious about by using the search function provided by PyTorch!\n","\n","```\n","- [Documentation main - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/index.html)\n"]},{"cell_type":"markdown","metadata":{"id":"M1EGwkfCxDr7"},"source":["##### üíØ Whether the PyTorch functions as a Linear Algebra\n","\n","\n","``` python\n","ü¶Ü\n","Does PyTorch have functions related to linear algebra like NumPy?\n","```"]},{"cell_type":"markdown","metadata":{"id":"CmxHQsDxZUoK"},"source":["```python\n","üòâ\n","# TODO: Feel free to answer whether you have it or not!\n","\n","```\n","Yes, PyTorch has functions related to linear algebra. The main difference between Numpy and PyTorch is that NumPy is calling data (scalars, vectors, matrices and other high dimensional arrays) in arrays formats and PyTorch is calling every data in format of tensors."]},{"cell_type":"markdown","metadata":{"id":"D9JlxC5WyO7X"},"source":["##### üíØ Matrix Multiplication\n","\n","``` python\n","ü¶Ü\n","What function do you use when you want to do Matrix Multiplication in pytorch?\n","\n","```"]},{"cell_type":"markdown","metadata":{"id":"rHpU8WUZyO7f"},"source":["```python\n","üòâ\n","# TODO: No fixed format! Please feel free to answer!\n","\n","\n","```\n","The function `torch.nn()` cam be used to perform matrix multiplication provided that the order of the matrices is appropriate for multiplication. Example, consider `torch.nn(A,B)`. If A is axb, then B should be bxc.\n"]},{"cell_type":"markdown","metadata":{"id":"qXkF-1SC1Q0q"},"source":["##### üíØ Norm\n","> Note that norm is not normalization, but norm, which is the concept of the size of a vector or matrix!\n","\n","``` python\n","ü¶Ü\n","I think I'll use a lot of the norm of vectors and matrices when I make models!\n","What function should we use in this case?\n","\n","```"]},{"cell_type":"markdown","metadata":{"id":"orfjxQuq1Q0u"},"source":["```python\n","üòÉ\n","# TODO: No fixed format! Please feel free to answer!\n","\n","\n","```\n","The function `torch.linalg.vector_norm()` can be used to calculate the norm of a vector and the function `torch.linalg.matrix_norm()` can be used to calculate the norm of a matrix.\n"]},{"cell_type":"markdown","metadata":{"id":"oJ0ZuWycwsff"},"source":["#### üîé <font color='orange'><b>[ ÌÉêÏÉâ ]</b></font> Look at the table of contents and find the information you want\n","\n","> üí° Please follow the suggested items! It's not a quiz!\n","\n","``` python\n","ü¶Ü\n","When I get used to PyTorch later, I want to contribute my code to the library!\n","As with most libraries, PyTorch clearly identifies the contribution process\n","I'm sure there's a document you've written!\n","```\n","- [Documentation main - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/index.html)\n"]},{"cell_type":"markdown","metadata":{"id":"fUmgABsu8dSn"},"source":["``` python\n","ü¶Ü\n","Community (community) is on the table of contents, too!\n","Cord guide for those who want to contribute to the document is here!\n","```\n","\n","- ‚úÖ Explore the Community sub-table of contents\n","- ‚úÖ Open and browse the PyTorch Contribution Guide document\n","    - [PyTorch Contribution Guide - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/community/contribution_guide.html)\n","- ‚úÖ Check the internal table of contents of the document for PyTorch Contribution Guide \n","    - ![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/table%20of%20content%20-%20contribution.png?raw=true)\n","- ‚úÖ ÎÇ¥Î∂Ä Î™©Ï∞® - Read Common Mistakes to Avoid lightly\n","    - [PyTorch Contribution Guide - Common Mistakes To Avoid - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/community/contribution_guide.html#common-mistakes-to-avoid)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"5qM693v7A31v"},"source":["### üåì Understand and leverage the features found in Documentation\n","> Now you know how to find the information you want in PyTorch documentation! But it's no use just looking! It's really meaningful if you read the description of the function written in Documentation and know how to use it yourself. We will try PyTorch ourselves with a simple example!\n","\n","- ‚ùì <font color='red'><b>[ ÌÄ¥Ï¶à ]</b></font> PyTorch's basic component Tensor\n","\n","- üë®‚Äçüíª <font color='green'><b>[ ÏΩîÎî© ]</b></font> Calculating four fundamental arithmetic operations\n","\n","- üë®‚Äçüíª <font color='green'><b>[ ÏΩîÎî© ]</b></font> Indexing"]},{"cell_type":"markdown","metadata":{"id":"zfJJRMVx4uZU"},"source":["#### ‚ùì **PyTorch's basic component Tensor**\n","\n","PyTorch said that the *sensor* is the basic component of everything. \n","I looked it up to use, and I said, `torch.tensor` and `torch.Tensor`. \n","There are two kinds! What's the difference?\n"]},{"cell_type":"markdown","metadata":{"id":"JXqdRH8h4uZc"},"source":["The PyTorch documentation indicates that `torch.Tensor` is an alias for `torch.FloatTensor`. It happens to be very similar in name to `torch.tensor`, but, it has a very different behaviour. On the other hand, `torch.tensor` infers the` dtype` automatically, while `torch.Tensor` returns a `torch.FloatTensor`. For example, `print(torch.Tensor([1, 3]))` gives the output `tensor([1., 3.])` (data type = `torch.float32`) whereas `print(torch.tensor([1, 3]))` gives the output `tensor([1, 3])` (data type = `torch.int64`).\n"]},{"cell_type":"markdown","metadata":{"id":"f3MnmB0zE-TK"},"source":["#### Calculating the four fundamental arithmetic operations"]},{"cell_type":"markdown","metadata":{"id":"dgoOCMtbJHEL"},"source":["##### üí° ÎçîÌïòÍ∏∞ (add)\n","\n","```python\n","ü¶Ü\n","I'll calculate the 5+7 first!\n","\n","```\n","\n","- [torch.add - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.add.html?highlight=add#torch.add)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K5-9T-fjE3a_","executionInfo":{"status":"ok","timestamp":1654941065762,"user_tz":-540,"elapsed":2742,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"e4989689-3f80-4510-b9ba-fd9c2db9f15b"},"source":["import torch\n","\n","A = torch.Tensor([5])\n","B = torch.Tensor([7])\n","\n","torch.add(A, B)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([12.])"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9U9Wd_2oCLVR","executionInfo":{"status":"ok","timestamp":1654941065762,"user_tz":-540,"elapsed":38,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"c73e2299-a7aa-4e4d-b08a-33db50e5f25b"},"source":["# ü¶ÜYou can use torch.add through the + operator!\n","\n","A + B"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([12.])"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kq9h3ucECtoe","executionInfo":{"status":"ok","timestamp":1654941065763,"user_tz":-540,"elapsed":33,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"b3877364-3b64-4b96-843e-63dd66152e07"},"source":["# ü¶Ü When calculating, if any of the operand is entered as a tensor, the result comes out as a tensor!\n","A + 7"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([12.])"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"W-eAr6c7GEHl"},"source":["##### üí° Calculating the four fundamental arithmetic operations\n","What name does each rule operation use for the torch?\n","- `+` : [torch.add](https://pytorch.org/docs/stable/generated/torch.add.html?highlight=add#torch.add)\n","- `-` : [torch.sub](https://pytorch.org/docs/stable/generated/torch.sub.html)\n","- `*` : [torch.mul](https://pytorch.org/docs/stable/generated/torch.mul.html)\n","- `/` : [torch.div](https://pytorch.org/docs/stable/generated/torch.div.html)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a-1cyVz1CiCK","executionInfo":{"status":"ok","timestamp":1654941065763,"user_tz":-540,"elapsed":29,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"bbfffd36-3c90-4679-bf67-8abccb468c8f"},"source":["import torch\n","\n","A = torch.Tensor([3])\n","B = torch.Tensor([7])\n","C = torch.Tensor([2])\n","D = torch.Tensor([5])\n","E = torch.Tensor([10])\n","\n","# Use the TODO : torch function to calculate (3 + 7) * 2 - 5 / 10!\n","# The answer should be 19.5!\n","\n","output = torch.add(A, B) # Use only one torch function per line!\n","output1 = torch.mul(output, C)\n","output2 = torch.div(D, E)\n","output = torch.sub(output1, output2)\n","\n","# You do not need to modify the code below!\n","if output == 19.5:\n","    print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","else:\n","    print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n"]}]},{"cell_type":"markdown","metadata":{"id":"m7w_YfK6HXQ9"},"source":["#### (Indexing)\n"]},{"cell_type":"markdown","metadata":{"id":"LZ0zV31lX6zN"},"source":["##### üí° index_select\n","\n","\n","``` python\n","ü¶Ü\n","[[1 2]\n"," [3 4] I want to get [1 3] from a 2D tensor!\n","```\n","\n","- [torch.index_select - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.index_select.html?highlight=index#torch.index_select)\n","\n","üéÅ **ÌûåÌä∏** üéÅ\n","- Want when you want to change in the shape of a tensor [torch.Tensor.view](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html?highlight=view#torch.Tensor.view)ÎùºÎäî Ìï®ÏàòÎ•º ÏÇ¨Ïö©ÌïòÎ©¥ Îê©ÎãàÎã§!\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wIDKrXzXZs07","executionInfo":{"status":"ok","timestamp":1654941065763,"user_tz":-540,"elapsed":24,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"7b5eda7c-3b17-4167-b5b2-c23a25f5e93c"},"source":["import torch\n","\n","A = torch.Tensor([[1, 2],\n","                  [3, 4]])\n","\n","# TODO: Make [1, 3]!\n","\n","# # torch.Try using the index_select function!\n","output = A\n","indices = torch.tensor([0])\n","output = torch.index_select(output, 1, indices).reshape([1, -1]) \n","\n","        # Professors showed us using view() as follows also \n","# output = torch.index_select(output, 1, indices).view(-1,) \n","\n","# You do not need to modify the code below!\n","if torch.all(output == torch.Tensor([1, 3])):\n","    print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","else:\n","    print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Co8YFuVtaVZr","executionInfo":{"status":"ok","timestamp":1654941065764,"user_tz":-540,"elapsed":15,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"b198b517-fb66-4198-a48f-034823ab30f2"},"source":["# Do it in a similar way to Python List Indexing!\n","output = A\n","output = A[:, 0]\n","# You do not need to modify the code below!\n","if torch.all(output == torch.Tensor([1, 3])):\n","    print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","else:\n","    print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n"]}]},{"cell_type":"markdown","metadata":{"id":"TwdiREr_YLEa"},"source":["##### üí° Import diagonal elements from 2D sensor - 2D daughter\n","\n","``` python\n","ü¶Ü\n","[[1 2]\n"," [3 4] I want to make a 1D tensor by taking only diagonal elements from a 2D tensor\n","\n","I tried to do it through indexing, but somehow it didn't work!\n","Friend said, \"torch.He advised me to use the function \"gather\"!\n","```\n","- [torch.gather - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.gather.html#torch.gather)\n"]},{"cell_type":"code","source":["# Professor's hint about using the .gather function\n","import torch\n","matrix = torch.range(0,99).reshape(10,10)\n","print(matrix)\n","indices = [0,1,2,3,4,5,6,7,8,9]\n","print(indices)\n","indices = torch.tensor(indices)\n","print(indices)\n","indices = torch.tensor(indices).unsqueeze(axis=1)\n","print(indices)\n","\n","output = torch.gather(matrix, 1, indices).reshape([1, -1]) \n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D5OC-STDIPB_","executionInfo":{"status":"ok","timestamp":1654941066176,"user_tz":-540,"elapsed":421,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"1ca81ba0-7fe8-414a-e177-75b26b3077f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.],\n","        [10., 11., 12., 13., 14., 15., 16., 17., 18., 19.],\n","        [20., 21., 22., 23., 24., 25., 26., 27., 28., 29.],\n","        [30., 31., 32., 33., 34., 35., 36., 37., 38., 39.],\n","        [40., 41., 42., 43., 44., 45., 46., 47., 48., 49.],\n","        [50., 51., 52., 53., 54., 55., 56., 57., 58., 59.],\n","        [60., 61., 62., 63., 64., 65., 66., 67., 68., 69.],\n","        [70., 71., 72., 73., 74., 75., 76., 77., 78., 79.],\n","        [80., 81., 82., 83., 84., 85., 86., 87., 88., 89.],\n","        [90., 91., 92., 93., 94., 95., 96., 97., 98., 99.]])\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n","tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n","tensor([[0],\n","        [1],\n","        [2],\n","        [3],\n","        [4],\n","        [5],\n","        [6],\n","        [7],\n","        [8],\n","        [9]])\n","tensor([[ 0., 11., 22., 33., 44., 55., 66., 77., 88., 99.]])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n","  This is separate from the ipykernel package so we can avoid doing imports until\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  if __name__ == '__main__':\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kwx3LEqKbU9M","executionInfo":{"status":"ok","timestamp":1654941066177,"user_tz":-540,"elapsed":109,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"325a4d78-6919-498f-9ea4-101f69ce1a03"},"source":["import torch\n","\n","A = torch.Tensor([[1, 2],\n","                  [3, 4]])\n","\n","# torch.Try using the gather function!\n","\n","indices = torch.tensor([0, 1]).unsqueeze(axis=1)\n","output = torch.gather(A, 1, indices).reshape([1, -1]) \n","\n","# You do not need to modify the code below!\n","if torch.all(output == torch.Tensor([1, 4])):\n","    print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","else:\n","    print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n"]}]},{"cell_type":"markdown","metadata":{"id":"SHpq-zKFdQ8j"},"source":["##### üí° üî• <font color='yellow'><b>[ Optional ]</b></font> Import Diagonal Elements from 3D Sensor - 3D Gather üî•\n","> It's a little difficult for PyTorch skilled people. Most of the tensors covered in PyTorch are 3D or more, so I recommend you to practice them when you have time.\n","\n","``` python\n","ü¶Ü\n","\n","I'm so happy to have successfully collected diagonal elements in 2D!\n","I'd like to apply it to 3D, is it possible?\n","\n","[[[1 2]\n","  [3 4]]\n"," [[5 6] \n","  [7 8] I want to make a two-dimensional tensor called \n","\n","  [[1 4]\n","   [5 8] by taking only diagonal elements from the three-dimensional tensor\n","\n","```\n","- [torch.gather - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.gather.html#torch.gather)\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N7_WCGcpdQ81","executionInfo":{"status":"ok","timestamp":1654941066177,"user_tz":-540,"elapsed":103,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"8de30ca2-0cbc-49dc-dc6f-c9f4cbf41d9f"},"source":["import torch\n","\n","A = torch.Tensor([[[1, 2],\n","                   [3, 4]],\n","                  [[5, 6],\n","                   [7, 8]]])\n","\n","# torch.Try using the gather function!\n","indices = torch.tensor([\n","                        [[0],[1]],\n","                        [[0],[1]]\n","                        ])\n","output = torch.gather(A, 2, indices).reshape([2, 2])  #.view(2, 2)\n","\n","# You do not need to modify the code below!\n","if torch.all(output == torch.Tensor([[1, 4], [5, 8]])):\n","    print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","else:\n","    print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n"]}]},{"cell_type":"markdown","metadata":{"id":"VfmnV6cRuYf5"},"source":["##### üí° üî•üî•üî• <font color='yellow'><b>[ Optional ]</b></font>Collect diagonal elements from any size 3D sensor - 3D daughter üî•üî•üî•\n","> It's also a challenge for PyTorch experienced people. It is also a problem that you encounter in the process of creating a model that can respond robustly to inputs of various sizes. You should be familiar with the behavior of the gather and write flexible, scalable code.\n","\n","``` python\n","ü¶Ü\n","So far, we've taken diagonal elements from inputs of a given size\n","Can a 3D tensor of any size take diagonal elements and make a 2D tensor as well?\n","```\n","- [torch.gather - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.gather.html#torch.gather)\n","\n","üéÅ **ÌûåÌä∏** üéÅ\n","- to make the desired size of the [torch.Tensor.expand](https://pytorch.org/docs/stable/generated/torch.Tensor.expand.html?highlight=expand)is available!"]},{"cell_type":"code","metadata":{"id":"yg_byIzJxoPC"},"source":["import torch\n","\n","# TODO: Create a function that takes diagonal elements from a 3D sensor of any size and returns them in 2D!\n","def get_diag_element_3D(A):\n","  C, H, W = A.size()\n","  diag_size = min(H,W)\n","\n","  gather_index = torch.arange(diag_size).view(diag_size, -1).expand(C, diag_size, 1)\n","  output = torch.gather(A, 2, gather_index)\n","  output = output.view(C, diag_size)\n","  return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7q9gz0d5rYiG","executionInfo":{"status":"ok","timestamp":1654941066178,"user_tz":-540,"elapsed":98,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"26c9c003-7793-419a-a576-4ff3bd6a25c3"},"source":["# TODO: Make a 3D sensor of your size and test it to see if it works properly!\n","C = 1\n","H = 2\n","W = 3\n","\n","# You do not need to modify the code below!\n","A = torch.tensor([i for i in range(1, C*H*W + 1)])\n","A = A.view(C, H, W)\n","\n","print(f\"ÏõêÎ≥∏ 3D ÌñâÎ†¨\\n{A}\")\n","print(\"-\" * 50)\n","\n","print(f\"ÎåÄÍ∞ÅÏÑ† ÏöîÏÜåÎ•º Î™®ÏùÄ 2D ÌñâÎ†¨\")\n","get_diag_element_3D(A)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ÏõêÎ≥∏ 3D ÌñâÎ†¨\n","tensor([[[1, 2, 3],\n","         [4, 5, 6]]])\n","--------------------------------------------------\n","ÎåÄÍ∞ÅÏÑ† ÏöîÏÜåÎ•º Î™®ÏùÄ 2D ÌñâÎ†¨\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 5]])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ORBb-HPcJnCg","executionInfo":{"status":"ok","timestamp":1654941066179,"user_tz":-540,"elapsed":94,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"24232d84-b724-40ad-d5b7-8e8f6ed56391"},"source":["# You do not need to modify the code below!\n","A = torch.tensor([[[1]]])\n","\n","if torch.all(get_diag_element_3D(A) == torch.Tensor([[1]])):\n","    print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","else:\n","    print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pSbNIk3tyj8U","executionInfo":{"status":"ok","timestamp":1654941066180,"user_tz":-540,"elapsed":90,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"e9f55aa0-4098-4e47-8717-9b99f049d543"},"source":["# You do not need to modify the code below!\n","A = torch.Tensor([[[1, 2],\n","                   [3, 4]],\n","                  [[5, 6],\n","                   [7, 8]]])\n","\n","if torch.all(get_diag_element_3D(A) == torch.Tensor([[1, 4],\n","                                                     [5, 8]])):\n","    print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","else:\n","    print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H3ewV_sBJ-nm","executionInfo":{"status":"ok","timestamp":1654941066180,"user_tz":-540,"elapsed":86,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"db1449a1-db22-42d1-8d40-f9a73830a9f3"},"source":["# You do not need to modify the code below!\n","A = torch.Tensor([[[1, 2, 3],\n","                   [4, 5, 6]]])\n","\n","if torch.all(get_diag_element_3D(A) == torch.Tensor([[1, 5]])):\n","    print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","else:\n","    print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fueU_tOgIzDC","executionInfo":{"status":"ok","timestamp":1654941066181,"user_tz":-540,"elapsed":79,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"71f2e058-e416-4744-bb25-f923bbf795c2"},"source":["# You do not need to modify the code below!\n","A = torch.tensor([[[ 1,  2,  3,  4,  5],\n","                   [ 6,  7,  8,  9, 10],\n","                   [11, 12, 13, 14, 15]],\n","          \n","                  [[16, 17, 18, 19, 20],\n","                   [21, 22, 23, 24, 25],\n","                   [26, 27, 28, 29, 30]]])\n","\n","if torch.all(get_diag_element_3D(A) == torch.Tensor([[ 1,  7, 13],\n","                                                     [16, 22, 28]])):\n","    print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","else:\n","    print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1MKSgAWOJWvb","executionInfo":{"status":"ok","timestamp":1654941066183,"user_tz":-540,"elapsed":76,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"b84622d5-2eba-40cc-8edb-921a1403f4d9"},"source":["# You do not need to modify the code below!\n","A = torch.tensor([[[ 1,  2,  3],\n","                   [ 4,  5,  6],\n","                   [ 7,  8,  9],\n","                   [10, 11, 12],\n","                   [13, 14, 15]],\n","        \n","                  [[16, 17, 18],\n","                   [19, 20, 21],\n","                   [22, 23, 24],\n","                   [25, 26, 27],\n","                   [28, 29, 30]],\n","        \n","                  [[31, 32, 33],\n","                   [34, 35, 36],\n","                   [37, 38, 39],\n","                   [40, 41, 42],\n","                   [43, 44, 45]]])\n","\n","if torch.all(get_diag_element_3D(A) == torch.Tensor([[ 1,  5,  9],\n","                                                     [16, 20, 24],\n","                                                     [31, 35, 39]])):\n","    print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","else:\n","    print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n"]}]},{"cell_type":"markdown","metadata":{"id":"6h_5Q9Xejktd"},"source":["### üåì Read Documentation\n","> Find the information you want in PyTorch documentation and use it without any problems! But we still don't know what PyTorch has to offer. The more you know about PyTorch's capabilities in creating custom models, the more you know, the more diverse and cooler you can create! That's why we're going to have a time to read Documentation carefully in this section!\n","\n","- üìñ <font color='gold' ><b>[ ÏùΩÍ∏∞ ]</b></font> read torch document\n","- üìñ <font color='gold' ><b>[ ÏùΩÍ∏∞ ]</b></font> Read torch.linalg documentation\n","- üìñ <font color='gold' ><b>[ ÏùΩÍ∏∞ ]</b></font> Read torch.nn documentation\n","- üë®‚Äçüíª <font color='green'><b>[ ÏΩîÎî© ]</b></font> torch.nn `Linear Layers`\n","- ‚ùì <font color='red'><b>[ ÌÄ¥Ï¶à ]</b></font> Linear vs LazyLinear"]},{"cell_type":"markdown","metadata":{"id":"Ybvq8tz4769-"},"source":["#### üìñ <font color='gold' ><b>[ ÏùΩÍ∏∞ ]</b></font> Read torch documentation\n","``` python\n","ü¶Ü\n","I took a quick look at the documentation, and I found a torch file in the Python API table of contents\n","I think it's full of important and useful content!\n","\n","There are various functions that the developers worked hard on\n","I'd be really sad if it's not used because I don't know!\n","\n","Let's read it together!\n","```\n","\n","- [torch Î¨∏ÏÑú - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/torch.html)"]},{"cell_type":"markdown","metadata":{"id":"5d8rq3BlRjmH"},"source":["##### üíå Tensors\n","\n","``` python\n","ü¶Ü\n","I read the \"Tensors\" part first and organized it\n","I'll share how I read that part!\n","```\n","\n","- [Tensors - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/torch.html#tensors)"]},{"cell_type":"markdown","metadata":{"id":"XOvQP1sYUfci"},"source":["``` python\n","ü¶Ü\n","I've been looking at the name \"Tensors\" and I've been trying to figure out if you're creating a data structure for the sensor\n","I think there are functions that can extract related characteristics!\n","\n","First, I read the Tensors section and saw what functions there were!\n","The data structure is based on function names such as \"is_tensor\" and \"is_storage\"\n","I think it's a function of checking!\n","```\n","\n","![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/torch%20-%20tensors.png?raw=true)"]},{"cell_type":"markdown","metadata":{"id":"_EYZfH4CX7tT"},"source":["``` python\n","ü¶Ü\n","I wanted to know more about the function \"is_tensor\" so I went in on the link!\n","After reading the explanation on the blue box,\n","It is correct to check if the sensor data structure is correct!\n","\n","There was an example in the red box below!\n","I thought it'd be easier to understand if I played the chords myself\n","I've implemented an example myself with wings!\n","```\n","- [torch.is_tensor - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.is_tensor.html#torch.is_tensor)\n","![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/torch%20is%20tensor.png?raw=true)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-up9L8HlYzmm","executionInfo":{"status":"ok","timestamp":1654941066184,"user_tz":-540,"elapsed":72,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"a37e4e45-315c-4b39-a30f-3b378a1a6746"},"source":["import torch\n","\n","x = torch.tensor([1,2,3])\n","y = [1, 2, 3]\n","\n","# ü¶Ü It works so well! That's what I expected!\n","\n","torch.is_tensor(x), torch.is_tensor(y) "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(True, False)"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L-pYoFx5bYcj","executionInfo":{"status":"ok","timestamp":1654941066185,"user_tz":-540,"elapsed":69,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"ec4949b6-13b8-4478-de36-e71dd70e7e7c"},"source":["# ü¶Ü I also used the function numel once! It's working well!\n","\n","torch.numel(x)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"6wP5qfTMUYxq"},"source":["``` python\n","ü¶Ü\n","When I scroll down, these are functions that belong to the Tensor\n","They categorized it into the following details!\n","- \"Creation Ops\"\n","- \"Indexing, Slicing, Joining, Mutating Ops\"\n","\n","So I'm going to make a new section and organize it instead of organizing it here\n","```\n","\n","![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/torch%20-%20tensors%20-%20ops.png?raw=true)\n"]},{"cell_type":"markdown","metadata":{"id":"jpXu3zuOcjzO"},"source":["##### üíå Tensors - Creation Ops\n","\n","``` python\n","ü¶Ü\n","If it's part of Tensor, I want to organize it separately\n","It's divided into separate sections\n","```\n","- [Tensors - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/torch.html#tensors)"]},{"cell_type":"markdown","metadata":{"id":"rJZJuicGdHwm"},"source":["``` python\n","ü¶Ü\n","Ïù¥Î¶ÑÏùÑ Î≥¥Î©¥ \"Tensors\"ÎùºÎäî ÏûêÎ£åÍµ¨Ï°∞Î•º ÎßåÎìúÎäî Ìï®ÏàòÎì§Ïù¥ Î™®Ïó¨ÏûàÍ≤†Ï£†?\n","Ï†ÄÎäî Î®ºÏ†Ä ÏïÑÎûò Í∑∏Î¶ºÏóêÏÑú Îπ®Í∞Ñ Î∞ïÏä§ Ïπú Î∂ÄÎ∂ÑÏùÑ Ïú†Ïã¨Ìûà ÏùΩÏñ¥Î≥¥ÏïòÏñ¥Ïöî!\n","\"Ìï®ÏàòÎ™Ö\"Í≥º Ïö∞Ï∏°Ïóê \"Ìï®ÏàòÏóê ÎåÄÌïú ÏöîÏïΩ ÏÑ§Î™Ö\"ÏùÑ ÏùΩÏñ¥ÎÇòÍ∞îÏ£†!\n","```\n","\n","- ‚úÖ Ìï®ÏàòÏôÄ ÏöîÏïΩ ÏÑ§Î™ÖÏùÑ Í∞ÄÎ≥çÍ≤å ÌõëÏñ¥Î≥¥ÏÑ∏Ïöî!\n","\n","![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/torch%20-%20tensors%20-%20creation%20ops.png?raw=true)"]},{"cell_type":"markdown","metadata":{"id":"5b6lTFnCjQwc"},"source":["```python\n","ü¶Ü\n","Î≠êÎì†ÏßÄ ÏßÅÏ†ë ÏÜêÏúºÎ°ú Ï≥êÎ≥∏Í≤å Îçî Ïù¥Ìï¥Í∞Ä ÏûòÍ∞ÄÍ≥† Í∏∞ÏñµÏóê Ïò§Îûò ÎÇ®ÎçîÎùºÍµ¨Ïöî!\n","Í∑∏ÎûòÏÑú Ìï®ÏàòÎì§ÏùÑ Ï≠â ÎëòÎü¨Î≥¥Í≥† 3Í∞ÄÏßÄ Ìï®ÏàòÏùò ÏòàÏ†úÎ•º Íµ¨ÌòÑÌï¥Î≥¥ÏïòÏñ¥Ïöî!\n","```\n","\n","- ‚úÖ <font color='yellow'><b>[ Optional ]</b></font> ÏõêÌïòÎäî 3Í∞ú Ìï®ÏàòÎ•º Í≥®ÎùºÏÑú ÏòàÏ†ú ÏΩîÎìúÎ•º ÎèåÎ†§Î≥¥ÏÑ∏Ïöî!\n","    - from_numpy\n","    - zeros\n","    - zeros_like\n","\n","\n","- [torch.from_numpy - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.from_numpy.html#torch.from_numpy)\n","- [torch.zeros - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.zeros.html#torch.zeros)\n","- [torch.zeros_like - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.zeros_like.html#torch.zeros_like)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vhp7vsgE8FY4","executionInfo":{"status":"ok","timestamp":1654941066185,"user_tz":-540,"elapsed":65,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"15ad6ccc-a9ea-4b4b-c988-505f3266697f"},"source":["import torch\n","import numpy as np\n","\n","# ü¶Ü torch.from_numpy\n","a = np.array([1,2,3])\n","t = torch.from_numpy(a)\n","t"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1, 2, 3])"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1mzqAJDGm9Hd","executionInfo":{"status":"ok","timestamp":1654941066186,"user_tz":-540,"elapsed":59,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"1322a45c-e448-4ae9-cb71-f200a9aee876"},"source":["# ü¶Ü torch.zeros\n","torch.zeros(2, 3)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0., 0., 0.],\n","        [0., 0., 0.]])"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BA2pv3pFiu3M","executionInfo":{"status":"ok","timestamp":1654941066187,"user_tz":-540,"elapsed":55,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"16c99108-75fb-416c-ff76-e6bfb366d781"},"source":["# ü¶Ü torch.zeros_like\n","torch.zeros_like(t)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0, 0, 0])"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"yBmtQly_nqR7"},"source":["##### üíå Tensors - Indexing, Slicing, Joining, Mutating Ops\n","\n","``` python\n","ü¶Ü\n","This is the last detail of the Tensor's item!\n","Indexing, slicing, and other important functions will be gathered!\n","```\n","\n","- [Tensors - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/torch.html#tensors)"]},{"cell_type":"markdown","metadata":{"id":"h4iVxzyHnqR-"},"source":["``` python\n","ü¶Ü\n","As I read it, sometimes there are functions that don't have an example code!\n","In this case, I think I should read the description of the function more carefully and implement it!\n","```\n","\n","- ‚úÖ Skim through functions and summary descriptions!\n","- ‚úÖ <font color='yellow'><b>[ Optional ]</b></font> Choose the 3 functions you want and return the example code!\n","    - chunk\n","    - swapdims\n","    - zeros_like\n","\n","\n","- [torch.chunk - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.chunk.html#torch.chunk)\n","- [torch.swapdims - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.swapdims.html#torch.swapdims)\n","- [torch.Tensor.scatter_ - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_.html#torch.Tensor.scatter_)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nq9zOgoznqR_","executionInfo":{"status":"ok","timestamp":1654941066187,"user_tz":-540,"elapsed":51,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"1187b2fc-b864-4729-da27-dd31848c199e"},"source":["import torch\n","import numpy as np\n","\n","# ü¶Ü torch.chunk\n","t = torch.tensor([[1, 2, 3],\n","                  [4, 5, 6]])\n","\n","# ü¶Ü There is no example, but I read documentation and implemented it!\n","\n","print(torch.chunk(t, 2, 0))\n","print(torch.chunk(t, 2, 1))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(tensor([[1, 2, 3]]), tensor([[4, 5, 6]]))\n","(tensor([[1, 2],\n","        [4, 5]]), tensor([[3],\n","        [6]]))\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t7Qy8zEPnqSA","executionInfo":{"status":"ok","timestamp":1654941066187,"user_tz":-540,"elapsed":44,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"524b481d-4090-4763-9235-bc0986dfabfd"},"source":["# ü¶Ü torch.swapdims\n","x = torch.tensor([[[0,1],[2,3]],[[4,5],[6,7]]])\n","x"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[0, 1],\n","         [2, 3]],\n","\n","        [[4, 5],\n","         [6, 7]]])"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8o6mHeHeutTh","executionInfo":{"status":"ok","timestamp":1654941066193,"user_tz":-540,"elapsed":46,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"2a1ed202-e499-4aa0-9881-8703c9ff2e24"},"source":["torch.swapdims(x, 0, 1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[0, 1],\n","         [4, 5]],\n","\n","        [[2, 3],\n","         [6, 7]]])"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8TBo37wDu4xW","executionInfo":{"status":"ok","timestamp":1654941066194,"user_tz":-540,"elapsed":43,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"5bbfbb03-bcb9-428b-9806-ea5f13031f2e"},"source":["torch.swapdims(x, 0, 2)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[0, 4],\n","         [2, 6]],\n","\n","        [[1, 5],\n","         [3, 7]]])"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M08dZW2fnqSB","executionInfo":{"status":"ok","timestamp":1654941066195,"user_tz":-540,"elapsed":39,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"6fa75ba4-b4f8-4ad3-808a-4128830b391b"},"source":["# ü¶Ü torch.Tensor.scatter_\n","src = torch.arange(1, 11).reshape((2, 5))\n","src"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1,  2,  3,  4,  5],\n","        [ 6,  7,  8,  9, 10]])"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z6WstSp-wLU4","executionInfo":{"status":"ok","timestamp":1654941066655,"user_tz":-540,"elapsed":496,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"3c6a8d58-5930-4248-d02b-6e6758385de0"},"source":["# ü¶Ü It feels similar to the gather we studied together!\n","\n","index = torch.tensor([[0, 1, 2, 0]])\n","torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 0, 0, 4, 0],\n","        [0, 2, 0, 0, 0],\n","        [0, 0, 3, 0, 0]])"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R0yIEAw-xAdV","executionInfo":{"status":"ok","timestamp":1654941066656,"user_tz":-540,"elapsed":207,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"89c51671-30bb-438f-c673-c5236364747b"},"source":["index = torch.tensor([[0, 1, 2], [0, 1, 4]])\n","torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 2, 3, 0, 0],\n","        [6, 7, 0, 0, 8],\n","        [0, 0, 0, 0, 0]])"]},"metadata":{},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"jPvOek5YxfRg"},"source":["##### üíå Random sampling\n","\n","``` python\n","ü¶Ü\n","I think random functions can be used in various places such as initialization and sampling!\n","If you pay attention to it as much as it's useful, I think it'll be used well later on!\n","```\n","\n","- [Random sampling - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/torch.html#random-sampling)"]},{"cell_type":"markdown","metadata":{"id":"LAcT0HckxfR7"},"source":["- ‚úÖ Skim through functions and summary descriptions!\n","- ‚úÖ <font color='yellow'><b>[ Optional ]</b></font>hoose 3 functions you want and return the example code!\n","    - bernoulli\n","    - normal\n","    - poisson\n","\n","\n","\n","-  [torch.bernoulli](https://pytorch.org/docs/stable/generated/torch.bernoulli.html#torch.bernoulli): It returns a tensor of either 0 or 1 for a given probability value. Specifically, if the probability is 0, it will return 0. On the other hand if the probability is 1, it will return 1."]},{"cell_type":"code","source":["import torch\n","# Assuming all probabilities are 1\n","a = torch.ones(3, 3) # 3x3 tensor of 1\n","print(a)\n","success = torch.bernoulli(a)\n","print(success) # 3x3 tensor of 1\n","\n","# Assuming all probabilities are 1\n","a = torch.zeros(3, 3)  # 3x3 tensor of 0\n","print(a)\n","success = torch.bernoulli(a)\n","print(success) # 3x3 tensor of 0\n","\n","# Now generate a 3x3 tensor of random probabilities\n","a = torch.empty(3, 3).uniform_(0, 1) \n","print(a) # 3x3 tensor of random numbers between 0 and 1\n","success = torch.bernoulli(a)\n","print(success) # returns 3x3 tensor of either 0 or 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X5umU1PhMaIW","executionInfo":{"status":"ok","timestamp":1654941066657,"user_tz":-540,"elapsed":197,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"0224bfad-b027-4cc7-e3fd-cab756397182"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 1., 1.],\n","        [1., 1., 1.],\n","        [1., 1., 1.]])\n","tensor([[1., 1., 1.],\n","        [1., 1., 1.],\n","        [1., 1., 1.]])\n","tensor([[0., 0., 0.],\n","        [0., 0., 0.],\n","        [0., 0., 0.]])\n","tensor([[0., 0., 0.],\n","        [0., 0., 0.],\n","        [0., 0., 0.]])\n","tensor([[0.3696, 0.9752, 0.3903],\n","        [0.8095, 0.7564, 0.1095],\n","        [0.5581, 0.3121, 0.1206]])\n","tensor([[0., 0., 0.],\n","        [1., 1., 0.],\n","        [1., 0., 0.]])\n"]}]},{"cell_type":"markdown","source":["- [torch.normal](https://pytorch.org/docs/stable/generated/torch.normal.html#torch.normal): It returns a tensor of random numbers drawn from a distribution whose mean and standard deviation are given."],"metadata":{"id":"bvKDFzp7fpEP"}},{"cell_type":"code","source":["a = torch.normal(mean=torch.arange(1., 11.), std=torch.arange(1, 0, -0.1))\n","print(a)\n","b = torch.normal(mean=0.5, std=torch.arange(1., 6.))\n","print(b)\n","c = torch.normal(2, 3, size=(1, 4))\n","print(c)"],"metadata":{"id":"45Y7uu7nRR9N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654941066658,"user_tz":-540,"elapsed":190,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"510ec7ea-43df-49f0-ac97-c53499d3cf12"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 1.1483,  2.5431,  4.0992,  3.8410,  4.5530,  6.4675,  6.9869,  8.3658,\n","         8.8022, 10.0226])\n","tensor([ 2.0470,  3.6903,  2.1376, -2.0723, -7.6739])\n","tensor([[5.6841, 6.6300, 5.3605, 1.6692]])\n"]}]},{"cell_type":"markdown","source":["- [torch.poisson](https://pytorch.org/docs/stable/generated/torch.poisson.html#torch.poisson): It gives a tensor of discrete (whole numbers) values from a Poisson distribution for a given mean rate parameter."],"metadata":{"id":"y5PTEnLufrm-"}},{"cell_type":"code","source":["rates = torch.rand(4, 4) * 5  # rate parameter between 0 and 5\n","torch.poisson(rates)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BA71zIq3g5o8","executionInfo":{"status":"ok","timestamp":1654941066658,"user_tz":-540,"elapsed":181,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"f1d058ff-f9d8-4d6d-e04f-325ef5e0332c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[2., 4., 0., 1.],\n","        [3., 2., 1., 4.],\n","        [2., 2., 1., 2.],\n","        [1., 0., 1., 0.]])"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"VBC_HD024zT7"},"source":["##### üíå Math operations - Pointwise Ops\n","\n","``` python\n","ü¶Ü\n","There are various functions related to computation!\n","They must be functions that process with pointwise!\n","```\n","\n","- [Math operations - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/torch.html#math-operations)\n","- [Pointwise - Wikipedia](https://en.wikipedia.org/wiki/Pointwise)"]},{"cell_type":"markdown","metadata":{"id":"YQDWkg-S4zT9"},"source":["- ‚úÖ Skim through functions and summary descriptions!\n","- ‚úÖ <font color='yellow'><b>[ Optional ]</b></font> Choose 3 functions and return the example code!\n","    - [`torch.abs`](https://pytorch.org/docs/stable/generated/torch.abs.html#torch.abs): returns the abosolute value of each element of a tensor.\n","    - [`torch.ceil`](https://pytorch.org/docs/stable/generated/torch.ceil.html#torch.ceil): Returns the ceil of the elements of a tensor, the smallest integer greater than or equal to each element.\n","    - [`torch.exp`](https://pytorch.org/docs/stable/generated/torch.exp.html#torch.exp): Returns the exponential of the elements of a tensor."]},{"cell_type":"code","source":["a = torch.tensor([-1.9, -2.3, 3])\n","print(torch.abs(a))\n","print(torch.ceil(a))\n","print(torch.exp(a))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PdoboJgthxfF","executionInfo":{"status":"ok","timestamp":1654941066659,"user_tz":-540,"elapsed":175,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"cca0759b-5773-44f9-9c0f-c9a52756bf89"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1.9000, 2.3000, 3.0000])\n","tensor([-1., -2.,  3.])\n","tensor([ 0.1496,  0.1003, 20.0855])\n"]}]},{"cell_type":"markdown","metadata":{"id":"zLFA5jeb7dcB"},"source":["##### üíå Math operations - Reduction Ops\n","\n","``` python\n","ü¶Ü\n","The functions only take certain values from the tensor, depending on the conditions\n","Reduce the size of the given tensor, such as reducing the size through an operation\n","I think it's named reduction because it's printed out!\n","```\n","\n","- [Math operations - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/torch.html#math-operations)"]},{"cell_type":"markdown","metadata":{"id":"poy8CCOC7dcC"},"source":["- ‚úÖ Skim through functions and summary descriptions!\n","- ‚úÖ <font color='yellow'><b>[ Optional ]</b></font> Choose 3 functions and return the example code!\n","\n","  - [`torch.argmax`](https://pytorch.org/docs/stable/generated/torch.argmax.html#torch.argmax): returns the indices of the max value of all the elements of a tensor. \n","  - [`torch.mean`](https://pytorch.org/docs/stable/generated/torch.mean.html#torch.mean): returns the mean value of all the elements of a tensor.\n","  - [`torch.unique`](https://pytorch.org/docs/stable/generated/torch.exp.html#torch.exp): returns the unique elements of a tensor.\n"]},{"cell_type":"code","source":["a = torch.tensor([1, 2.3, 0.9])\n","print(torch.argmax(a))\n","print(torch.mean(a))\n","\n","a = torch.tensor ([-1, 2, -1, 0, 0.1, 0.1, 1, 0.1])\n","print(torch.unique(a))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iqQUF5Uuh4kf","executionInfo":{"status":"ok","timestamp":1654941066659,"user_tz":-540,"elapsed":167,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"a65edde4-bc70-4821-ec8b-75cd17e5dfd8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(1)\n","tensor(1.4000)\n","tensor([-1.0000,  0.0000,  0.1000,  1.0000,  2.0000])\n"]}]},{"cell_type":"markdown","metadata":{"id":"IJNyfmll_h_o"},"source":["##### üíå Math operations - Comparison Ops\n","\n","``` python\n","ü¶Ü\n","It looks like functions that involve these comparisons, small or large!\n","I think it'll be as useful as an ifelse door!\n","```\n","\n","- [Math operations - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/torch.html#math-operations)"]},{"cell_type":"markdown","metadata":{"id":"rOStUYzm_h_p"},"source":["- ‚úÖ Skim through functions and summary descriptions!\n","- ‚úÖ <font color='yellow'><b>[ Optional ]</b></font> Choose 3 functions and return the example code!\n","    - [`torch.eq`](https://pytorch.org/docs/stable/generated/torch.eq.html#torch.eq): computes element-wise equality between two tensors.\n","    - [`torch.equal`](https://pytorch.org/docs/stable/generated/torch.equal.html#torch.equal): returns 'True' if two tensors have the same size and elements.\n","    - [`torch.sort`](https://pytorch.org/docs/stable/generated/torch.sort.html#torch.sort): sorts the elements of the tensor along a given dimension in an increasing order of values."]},{"cell_type":"code","source":["a = torch.tensor([[1, 5], [5, 4]])\n","b = torch.tensor([[1, 2], [3, 3]])\n","\n","print(torch.eq(a, b))\n","print(torch.equal(a, b))\n","\n","print(torch.sort(a, 0)) # sort by row\n","print(torch.sort(a, 1)) # sort by column"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EFIwFjIOo84t","executionInfo":{"status":"ok","timestamp":1654941066660,"user_tz":-540,"elapsed":163,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"2efbc91c-c618-4d32-ccf4-2b3dd3ee4ec5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ True, False],\n","        [False, False]])\n","False\n","torch.return_types.sort(\n","values=tensor([[1, 4],\n","        [5, 5]]),\n","indices=tensor([[0, 1],\n","        [1, 0]]))\n","torch.return_types.sort(\n","values=tensor([[1, 5],\n","        [4, 5]]),\n","indices=tensor([[0, 1],\n","        [1, 0]]))\n"]}]},{"cell_type":"markdown","metadata":{"id":"qrEsHFT2FRDj"},"source":["##### üíå Math operations - Other Operations\n","\n","``` python\n","ü¶Ü\n","Specific details as hard to functions and must have it!\n","Some useful function that stands out!\n","Tensor useful for the calculation of unit and placement \"einsum\", in particular.\n","Do you remember for some reason, I will be custom, if you happened to be used when creating a model!\n","```\n","\n","- [Math operations - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/torch.html#math-operations)"]},{"cell_type":"markdown","metadata":{"id":"O9dwBl4SFRDk"},"source":["- ‚úÖ Skim through functions and summary descriptions!\n","- ‚úÖ <font color='yellow'><b>[ Optional ]</b></font> Choose 3 functions and return the example code!\n","    - [`torch.cov`](https://pytorch.org/docs/stable/generated/torch.cov.html#torch.cov): returns the covariance matrix of the varaibles given by a tensor matrix where the variables are represented along the rows and the observations are represented along the colums. \n","    - [`torch.trace`](https://pytorch.org/docs/stable/generated/torch.trace.html#torch.trace): returns the trace (sum of the diagonal elements) of a 2D matrix.\n","    - [`torch.view_as_real`](https://pytorch.org/docs/stable/generated/torch.view_as_real.html#torch.view_as_real): returns the view of a complex tensor as a real tensor."]},{"cell_type":"code","source":["a = torch.tensor([[1, 2, 3, 4, 5],\n","                 [5, 4, 3, 2, 1],\n","                 [10, 8, 6, 4, 1],\n","                 [5, 7, 8, -2, 6]])\n","print(torch.cov(a))\n","\n","a = torch.tensor([[3, 4],\n","                [4, 8]])\n","print(torch.trace(a))\n","\n","a = torch.tensor([[3, 4],\n","                [4, 8]], dtype=torch.cfloat)\n","print(a)\n","print(torch.view_as_real(a))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n8cSaRjmsKVY","executionInfo":{"status":"ok","timestamp":1654941066661,"user_tz":-540,"elapsed":155,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"04b4d247-135a-47db-c06a-c6e4a9ca3cad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 2.5000, -2.5000, -5.5000, -1.7500],\n","        [-2.5000,  2.5000,  5.5000,  1.7500],\n","        [-5.5000,  5.5000, 12.2000,  3.2000],\n","        [-1.7500,  1.7500,  3.2000, 15.7000]])\n","tensor(11)\n","tensor([[3.+0.j, 4.+0.j],\n","        [4.+0.j, 8.+0.j]])\n","tensor([[[3., 0.],\n","         [4., 0.]],\n","\n","        [[4., 0.],\n","         [8., 0.]]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"8r1QkKGGJobo"},"source":["##### üíå Math operations - BLAS and LAPACK Operations\n","\n","``` python\n","ü¶Ü\n","Surprised by the threatening name? I was surprised, too!\n","\n","- - \"BLAS\" - Basic Linear Algebra Subprograms\n","- - \"LAPACK\"‚Äâ- Linear Algebra PACKage\n","\n","I looked it up and it's all related to Linear Algebra!\n","When I look at the function, I can feel the familiarity!\n","```\n","\n","- [Math operations - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/torch.html#math-operations)\n","- [BLAS - netlib](http://www.netlib.org/blas/)\n","- [LAPACK - netlib](http://www.netlib.org/lapack/)"]},{"cell_type":"markdown","metadata":{"id":"3ZVGkAp5Jobp"},"source":["- ‚úÖ Skim through functions and summary descriptions!\n","- ‚úÖ <font color='yellow'><b>[ Optional ]</b></font> Choose 3 functions and return the example code!\n","    - [`torch.dot`](https://pytorch.org/docs/stable/generated/torch.dot.html#torch.dot): returns the dot product of two 1D tensors.\n","    - [`torch.eig`](https://pytorch.org/docs/stable/generated/torch.eig.html#torch.eig): returns the eigenvalues and eigenvectors of a real square matrix.\n","    - [`torch.matmul`](https://pytorch.org/docs/stable/generated/torch.matmul.html#torch.matmul): returns the matrix product of two tensors."]},{"cell_type":"code","source":["a = torch.tensor([3, 2, 4])\n","b = torch.tensor([1, 2, 2])\n","print(torch.dot(a,b))\n","\n","c = torch.tensor([[1, 2],\n","                  [4, 5]], dtype =torch.float32)\n","print(torch.eig(c))\n","\n","print(torch.matmul(a, b))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yDOL7n63wr2g","executionInfo":{"status":"ok","timestamp":1654941066663,"user_tz":-540,"elapsed":153,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"5c238c8e-6505-4206-b55b-1bc664ef36bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(15)\n","torch.return_types.eig(\n","eigenvalues=tensor([[-0.4641,  0.0000],\n","        [ 6.4641,  0.0000]]),\n","eigenvectors=tensor([]))\n","tensor(15)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: torch.eig is deprecated in favor of torch.linalg.eig and will be removed in a future PyTorch release.\n","torch.linalg.eig returns complex tensors of dtype cfloat or cdouble rather than real tensors mimicking complex tensors.\n","L, _ = torch.eig(A)\n","should be replaced with\n","L_complex = torch.linalg.eigvals(A)\n","and\n","L, V = torch.eig(A, eigenvectors=True)\n","should be replaced with\n","L_complex, V_complex = torch.linalg.eig(A) (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2910.)\n","  import sys\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qbzHU6WTJobq","executionInfo":{"status":"ok","timestamp":1654941066663,"user_tz":-540,"elapsed":145,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"0347762e-bfb9-47dc-b9b9-a6fb7ca625e9"},"source":["import torch\n","\n","M = torch.randn(2, 3)\n","mat1 = torch.randn(2, 3)\n","mat2 = torch.randn(3, 3)\n","torch.addmm(M, mat1, mat2)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[2.6166, 2.5139, 0.7228],\n","        [2.3000, 1.4983, 1.4462]])"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uRk9bcnqJobr","executionInfo":{"status":"ok","timestamp":1654941066664,"user_tz":-540,"elapsed":137,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"8d124950-06c8-414d-b54e-9c1de9856460"},"source":["a = torch.eye(10)\n","torch.matrix_rank(a)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: torch.matrix_rank is deprecated in favor of torch.linalg.matrix_rankand will be removed in a future PyTorch release. The parameter 'symmetric' was renamed in torch.linalg.matrix_rank to 'hermitian'. (Triggered internally at  ../aten/src/ATen/native/LinearAlgebra.cpp:618.)\n","  \n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(10)"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g5GegxahJobr","executionInfo":{"status":"ok","timestamp":1654941066664,"user_tz":-540,"elapsed":130,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"2fe86d31-a2a6-4621-e3b9-43dd95336dbb"},"source":["b = torch.eye(10)\n","b[0, 0] = 0\n","torch.matrix_rank(b)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(9)"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7_b9Xu6qJobs","executionInfo":{"status":"ok","timestamp":1654941066665,"user_tz":-540,"elapsed":107,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"5cad7710-7b4f-4b26-ec32-50c56036575c"},"source":["a = torch.tensor([[12., -51, 4],\n","                  [6, 167, -68],\n","                  [-4, 24, -41]])\n","q, r = torch.qr(a)\n","q"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n","The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n","Q, R = torch.qr(A, some)\n","should be replaced with\n","Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1980.)\n","  after removing the cwd from sys.path.\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.8571,  0.3943,  0.3314],\n","        [-0.4286, -0.9029, -0.0343],\n","        [ 0.2857, -0.1714,  0.9429]])"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W5mBhSmmJobs","executionInfo":{"status":"ok","timestamp":1654941066996,"user_tz":-540,"elapsed":407,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"3e637d35-96d2-4956-959f-eacc0cfb4ce6"},"source":["r"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ -14.0000,  -21.0000,   14.0000],\n","        [   0.0000, -175.0000,   70.0000],\n","        [   0.0000,    0.0000,  -35.0000]])"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e9SbUGKmJobs","executionInfo":{"status":"ok","timestamp":1654941066996,"user_tz":-540,"elapsed":96,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"8549e00a-2e95-43bb-dbb9-3b09e969d9da"},"source":["torch.mm(q, r).round()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 12., -51.,   4.],\n","        [  6., 167., -68.],\n","        [ -4.,  24., -41.]])"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C_2T-Q3EJobt","executionInfo":{"status":"ok","timestamp":1654941066997,"user_tz":-540,"elapsed":59,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"19e210ca-ba69-4d07-a10f-6a5a509e7c8c"},"source":["torch.allclose(torch.matmul(q, r), a)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","metadata":{"id":"GGZDh_Tw4tpS"},"source":["#### üìñ <font color='gold' ><b>[ ÏùΩÍ∏∞ ]</b></font> Read torch.linalg documentation\n","``` python\n","ü¶Ü\n","The functions related to linear algebra that I saw while reading the torch document,\n","It's newly organized as \"torch.linalg\" and it's a song that's part of \"torch\"\n","Linear algebraic functions seem to have been degraded!\n","\n","The directory has been moved, and the function name already feels familiar! Isn't it?\n","```\n","\n","- [torch.linalg Î¨∏ÏÑú - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/linalg.html#)"]},{"cell_type":"markdown","metadata":{"id":"tOg5zeq46J0A"},"source":["- ‚úÖ Check sub contents of torch.linalg \n","    - Matrix Properties\n","    - Decompositions\n","    - Solvers\n","    - Inverses\n","    - Matrix Products\n","    - Tensor Operations\n","    - Experimental Functions\n","- ‚úÖ Look through each sub-table of contents to see which functions belong!\n","    - ex) Matrix PropertiesÏóêÎäî `norm`, `vector_norm` Îì±Ïù¥ ÏûàÎã§\n","    - ex) DecompositionsÏóêÎäî `cholesky`, `qr`, `svd` Îì±Ïù¥ ÏûàÎã§\n","    - ex) InversesÏóêÎäî `inv`, `pinv` 2Í∞úÏùò Ìï®ÏàòÍ∞Ä ÏûàÎã§"]},{"cell_type":"markdown","metadata":{"id":"HXUIf4hw8R_A"},"source":["#### üìñ <font color='gold' ><b>[ ÏùΩÍ∏∞ ]</b></font> Read torch.nn documenrtation\n","``` python\n","ü¶Ü\n","The description says \"basic building block\" to make a graph!\n","\n","If you use the various functions that we've identified so far,\n","You can make a basic building block here, but it takes time\n","PyTorch pre-made it and said, \"torch.I think it's tied up with \"nn\"!\n","\n","If you use the blocks provided here well, I think you can make a deep learning model called a graph!\n","\n","It looks very important, but it has a lot of content!\n","You can't read all this, so just look through it!\n","It may seem unfamiliar and difficult now, but you'll get used to it gradually!\n","```\n","\n","- [torch.nn Î¨∏ÏÑú - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/nn.html)"]},{"cell_type":"markdown","metadata":{"id":"MQjpdQWB8R_S"},"source":["- ‚úÖ torch.Take a look at the sub-table of nn!\n","- ‚úÖ Explore which layers or functions belong to each sub-table of contents!\n"]},{"cell_type":"markdown","metadata":{"id":"R68OFoe8BzbF"},"source":["#### üë®‚Äçüíª <font color='green'><b>[ ÏΩîÎî© ]</b></font> torch.nn `Linear Layers`\n","\n","``` python\n","ü¶Ü\n","Be lightly rubbed for one or two, but it's still trying to be read only directly, I want to try the example!\n","Who frequently appear when you study dimneoning y officially do you remember? = + b wx\n","The linear transformation for a connecting to \"a nn linear\".\n","\"linear layers\" item for a moment as look at it!\n","```\n","\n","- [torch.nn Linear Layers - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/nn.html#linear-layers)"]},{"cell_type":"markdown","metadata":{"id":"rZmymVenGzXd"},"source":["##### üí° nn.Linear\n","\n","\n","``` python\n","ü¶Ü\n","I have a hunch that I'll run into this \"nn.Linear\" a lot in the future!\n","\n","```\n","\n","- [torch.nn.Linear - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)\n","\n","üéÅ **ÌûåÌä∏** üéÅ\n","- PyTorch has a function that returns the sensor size (or shape)! What is the size in English?\n"]},{"cell_type":"code","metadata":{"id":"tjHTIZdrGzXd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654941066997,"user_tz":-540,"elapsed":52,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"53bf09f7-72d3-4f3e-f7b9-db3163470656"},"source":["import torch\n","from torch import nn\n","\n","X = torch.Tensor([[1, 2],\n","                  [3, 4]])\n","\n","# TODO : The size of the sensor X is (2, 2)\n","#         nn.Use Linear to resize to (2, 5) and print this size!\n","linear = nn.Linear(2, 5)\n","print(linear)\n","result = linear(X)\n","print(result)\n","print(result.size())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Linear(in_features=2, out_features=5, bias=True)\n","tensor([[-2.4084,  0.5577,  1.2089,  0.6170,  0.0618],\n","        [-4.7513,  1.7594,  2.9729, -0.0825, -0.8098]],\n","       grad_fn=<AddmmBackward0>)\n","torch.Size([2, 5])\n"]}]},{"cell_type":"markdown","metadata":{"id":"eU_nhb1vKTi-"},"source":["##### üí° nn.Identity\n","> Believe it or not, this layer is also useful. However, you don't need to know where to use this layer because you rarely use it when you're just learning deep learning. However, I leave a link for those who are curious.\n","\n","``` python\n","ü¶Ü\n","What the hell is \"nn.Identity\"?\n","The input and output are the same, so why did they make it?\n","But... Try it!\n","```\n","\n","- [torch.nn.Identity - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.Identity.html#torch.nn.Identity)\n","\n","**‚ú® Ïú†Ïö©Ìïú ÏûêÎ£å ‚ú®**\n","- [What is the use of nn.Identity? - PyTorch Forum](https://discuss.pytorch.org/t/what-is-the-use-of-nn-identity/51781)\n","- [What is the idea behind using nn.Identity for residual learning? - Stack Overflow](https://stackoverflow.com/questions/64229717/what-is-the-idea-behind-using-nn-identity-for-residual-learning)"]},{"cell_type":"code","metadata":{"id":"Om5zRqyvKTjA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654941066997,"user_tz":-540,"elapsed":46,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"cf2336c4-5d52-47f3-97da-f7c8a224c485"},"source":["import torch\n","from torch import nn\n","\n","X = torch.Tensor([[1, 2],\n","                  [3, 4]])\n","\n","# TODO : nn identity x the input came after output value is equal and x!\n","identity = nn.Identity()\n","print(identity(X))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 2.],\n","        [3., 4.]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"ZRWBmAYkOYgy"},"source":["#### ‚ùì <font color='red'><b>[ ÌÄ¥Ï¶à ]</b></font> Linear vs LazyLinear\n","``` python\n","ü¶Ü\n","I was just trying to pass by, but it bothers me!\n","What`s the difference between Linear and Lazy Linear?!\n","```\n","\n","- [torch.nn.Linear - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)\n","- [torch.nn.LazyLinear - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.LazyLinear.html#torch.nn.LazyLinear)"]},{"cell_type":"markdown","metadata":{"id":"SIrfhKtCOYg6"},"source":["```python\n","üòÇ\n","# TODO :  Please read the document and write down the answers freely\n","\n","```\n","A linear neural network applies a linear transformation to the input data in which the learnable weights and bias are iniitalized from a uniform distribution $U(-\\sqrt{k}, \\sqrt{k})$ where $k$ is the inverse of the number of input features. On the other hand, in a lazy linear neural network the parameters are not initialized. Rather, the parameters will be iniitalized after the first forward pass. Once the first forward pass is completed, the lazy linear neural network becomes the usuall linear neural network."]},{"cell_type":"markdown","metadata":{"id":"PNriTnyfdI0-"},"source":["### üéâüéâüéâ Documentation complete! üéâüéâüéâ\n","\n","```python\n","\n","The documentation chapter was harder than you thought, right?<br>\n","Congratulations on successfully finishing the show even though it was not a small amount! üéâ<br> It's never easy.\n","\n","You are now ready to take advantage of Documentation.<br>\n","Now it's time to deal with the content related to our original purpose of modeling.<br>"]},{"cell_type":"markdown","metadata":{"id":"EYHm2O2t6Usd"},"source":["## ‚≠ê nn.Module class for custom model creation\n","\n","\n","```\n","üí° We will use the various functions provided \n","by the PyTorch library and nn.Module \n","to create and analyze models!\n","```\n","\n","Now that we've learned how to find and utilize the various features in Documentation, it's time to combine the features that PyTorch provides to create a great model. It would be messy if you simply listed the functions to make a model, right? So PyTorch brings these series of functions together and gives us a class to abstract them into one model.\n","\n","\n","```\n","üí° nn.Module\n","```\n","- [torch.nn.Module - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)\n","\n","The 'nn.Module' class acts as a box that brings together multiple functions.<br>\n","The box 'nn.Module' is another 'nn.Module' box can also be included!<br>\n","Depending on how you use it, \"nnn.The 'Module' box has a different meaning.\n","\n","- If the 'nn.Module' box is filled with 'functions', 'basic building block'\n","- In the box 'nn.Module', the 'basic building block' is called 'nn.'Deep learning model' if full of Module's\n","- In a box called 'nn.Module', the 'Deep Learning Model' 'nn.If you have a lot of Module's, it's a bigger deep learning model\n","\n","\" nn module ' how to use this just an empty that lights up and plays is fully the system architects will!<br>\n","' functional ' and ' basic building block of the ' model ' and ' dimneoning and at random and <br> a wall.\n","' functional ' is ' functional ' with \" the ` block block ' hierarchical with a wall with a number!\n","\n","We are here, nnModule \" Using the models manufactured and analyzed how models are configured at will!<br>\n","Additionally, custom models that can be useful in the function will have a look at some of the ` module, nn!\n","\n","\n","- ‚òÑÔ∏è nn.Module : Implementation model\n","- ‚òÑÔ∏è nn.Module : analyze model\n","- ‚òÑÔ∏è nn.Module : something that helps you\n"]},{"cell_type":"markdown","metadata":{"id":"yXCog9jT_MJt"},"source":["### ‚òÑÔ∏è nn.Module Implementation model\n","> After understanding what nn.Module is, we will have time to practice various ways of making models using it and to understand the important concepts in making custom models\n","\n","\n","- üìñ <font color='gold' ><b>[ ÏùΩÍ∏∞ ]</b></font> torch.nn.Module Î¨∏ÏÑú ÏùΩÍ∏∞\n","- üë®‚Äçüíª <font color='green'><b>[ ÏΩîÎî© ]</b></font> 1 + 2\n","- üë®‚Äçüíª <font color='green'><b>[ ÏΩîÎî© ]</b></font> Container\n","- ‚ùì <font color='red'><b>[ ÌÄ¥Ï¶à ]</b></font> Python List vs PyTorch ModuleList\n","- üë®‚Äçüíª <font color='green'><b>[ ÏΩîÎî© ]</b></font> a conditional statement\n","- üë®‚Äçüíª <font color='green'><b>[ ÏΩîÎî© ]</b></font> ModuleÎì§Ïùò ÌùêÎ¶Ñ ÎäêÍª¥Î≥¥Í∏∞\n","- üë®‚Äçüíª <font color='green'><b>[ ÏΩîÎî© ]</b></font> Parameter\n","- ‚ùì <font color='red'><b>[ ÌÄ¥Ï¶à ]</b></font> Tensor vs Parameter\n","- üë®‚Äçüíª <font color='green'><b>[ ÏΩîÎî© ]</b></font> Buffer"]},{"cell_type":"markdown","metadata":{"id":"mgJ38Rsiy2Tc"},"source":["#### üìñ <font color='gold' ><b>[ ÏùΩÍ∏∞ ]</b></font> torch.nn.Module Read Document\n","\n","\n","- [Documentation main - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/index.html)"]},{"cell_type":"markdown","metadata":{"id":"IoDjvw97y2Tr"},"source":["- ‚úÖ Search for nn.Module in Documentation and find it!\n","- ‚úÖ Read a description of the document, nn module!\n","\n","    - ![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/nn.Module.png?raw=true)\n","- ‚úÖ 41 / 5000Î∞úÏùåÎì£Í∏∞Î≥µÏÇ¨ÌïòÍ∏∞ÌïÑÍ∏∞Ïù∏ÏãùÍ∏∞Î≤àÏó≠ÌïòÍ∏∞ÏûêÎèôÏôÑÏÑ±ÏûêÎèôÏôÑÏÑ±\t\n","ÏòÅÏñ¥Ïó¥Í∏∞/Îã´Í∏∞ ÏïÑÏù¥ÏΩò\n","Take a quick look at the names and descriptions of the methods inside the nn.Module!\n","```\n","üîî It's not a time to memorize or understand!\n","If you can't see the explanation and it's awkward, it's very normal\n","You don't have to force yourself to read it! If you can't see it, just pass by!\n","As you study, you will get used to it\n","Just look at it lightly and see if there's something like this!\n","```\n","    - add_module\n","    - apply\n","    - bfloat16\n","    - buffers\n","    - children\n","    - cpu\n","    - cuda\n","    - double\n","    - dump_patches\n","    - eval\n","    - extra_repr\n","    - float\n","    - forward\n","    - get_buffer\n","    - get_parameter\n","    - get_submodule\n","    - half\n","    - load_state_dict\n","    - modules\n","    - named_buffers\n","    - named_children\n","    - named_modules\n","    - named_parameters\n","    - parameters\n","    - register_backward_hook\n","    - register_buffer\n","    - register_forward_hook\n","    - register_forward_pre_hook\n","    - register_full_backward_hook\n","    - register_parameter\n","    - requires_grad_\n","    - share_memory\n","    - state_dict\n","    - to\n","    - to_empty\n","    - train\n","    - type\n","    - xpu\n","    - zero_grad"]},{"cell_type":"markdown","metadata":{"id":"5OhWyjstxvUt"},"source":["#### üë®‚Äçüíª <font color='green'><b>[ ÏΩîÎî© ]</b></font> 1 + 2\n","\n","``` python\n","ü¶Ü\n","While reading the documentation, I'll use \"torch.add\"\n","Do you remember calculating the four rules?\n","\n","This time, let's make a model that uses \"nn.Module\" to do a plus operation!\n","```\n","\n","- [Documentation main - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/index.html)\n","- [torch.add - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.add.html?highlight=add#torch.add)"]},{"cell_type":"code","metadata":{"id":"lF5CCXcgxjWD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654941066999,"user_tz":-540,"elapsed":43,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"5519634a-ecf2-468c-c877-1ee35319b25b"},"source":["import torch\n","from torch import nn\n","\n","# TODO: Complete the Add model!\n","class Add(nn.Module):\n","    def __init__(self):\n","        # TODO :  There is a super related code that must be entered in the init process\n","        super(Add, self).__init__()\n","\n","    def forward(self, x1, x2):\n","        # TODO : Please do the addition operation by using functions, torch.add\n","        return torch.add(x1, x2)\n","\n","\n","# You do not need to modify the code below!\n","x1 = torch.tensor([1])\n","x2 = torch.tensor([2])\n","\n","add = Add()\n","output = add(x1, x2)\n","\n","if output == 3:\n","    print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","else:\n","    print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n"]}]},{"cell_type":"markdown","metadata":{"id":"ZfhwgR6kYy6i"},"source":["``` python\n","ü¶Ü\n","Why is it like that to do init through super?\n","\n","Reading the text on the link below, I think I'm solving some of the questions!\n","```\n","\n","**‚ú® Ïú†Ïö©Ìïú ÏûêÎ£å ‚ú®**\n","- [Why is the super constructor necessary in PyTorch custom modules? - Stack Overflow](https://stackoverflow.com/questions/63058355/why-is-the-super-constructor-necessary-in-pytorch-custom-modules)"]},{"cell_type":"markdown","metadata":{"id":"MpJ51jOZL1pm"},"source":["#### üë®‚Äçüíª <font color='green'><b>[ ÏΩîÎî© ]</b></font> Container\n","\n","``` python\n","ü¶Ü\n","We successfully made the module we wanted!\n","I don't know if it's half the start, but it's definitely a model!\n","\n","I want to use modules that are made like this together, how do I do it?\n","Should I keep the modules on Python's list?\n","\n","Oh! I found it!\n","I looked up Documentation and found out that the related functions\n","It's included in the Container entry in \"torch.nn\"!\n","```\n","\n","- [Documentation main - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/index.html)\n","- [Containers  - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/nn.html#containers)"]},{"cell_type":"markdown","metadata":{"id":"6a_OSRXMgc8j"},"source":["##### üí° torch.nn.Sequential\n","\n","``` python\n","ü¶Ü\n","When you want to combine modules into one and run them sequentially\n","torch.nn.It's using Sequential! Let's make it together!\n","```\n","\n","- [torch.nn.Sequential - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential)"]},{"cell_type":"code","metadata":{"id":"ZAzm120dL1p4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654941066999,"user_tz":-540,"elapsed":39,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"f2c8f4db-ff3d-4934-e6ac-9c369abde36c"},"source":["import torch\n","from torch import nn\n","\n","# TODO : Read and understand the following modules!\n","class Add(nn.Module):\n","    def __init__(self, value):\n","        super().__init__()\n","        self.value = value\n","\n","    def forward(self, x):\n","        return x + self.value\n","\n","# TODO : Module and nn above.Using Sequential,\n","#        Given an input of x, create a model that processes the following operations!\n","#        y = x + 3 + 2 + 5\n","calculator = nn.Sequential(\n","    Add(3),\n","    Add(2),\n","    Add(5))\n","\n","\n","# You do not need to modify the code below!\n","x = torch.tensor([1])\n","\n","output = calculator(x)\n","\n","if output == 11:\n","    print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","else:\n","    print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n"]}]},{"cell_type":"markdown","metadata":{"id":"a-Zs6pnh1925"},"source":["##### üí° torch.nn.ModuleList\n","\n","``` python\n","ü¶Ü\n","torch.nn.Sequential performs the modules tied up one by one\n","It looks good to bring together functions that have a fixed order of execution!\n","\n","But like Python's list, I'll just keep it together, and then I'll just keep what I want\n","To write through indexing, torch.Why don't we write nn.ModuleList?\n","```\n","\n","- [torch.nn.ModuleList - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#torch.nn.ModuleList)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7D3cK6pS193J","executionInfo":{"status":"ok","timestamp":1654941067000,"user_tz":-540,"elapsed":36,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"24fb54ba-fa9c-45d2-9fcc-eb0996815f0c"},"source":["import torch\n","from torch import nn\n","\n","# TODO : Read and understand the following modules!\n","\n","class Add(nn.Module):\n","    def __init__(self, value):\n","        super().__init__()\n","        self.value = value\n","\n","    def forward(self, x):\n","        return x + self.value\n","\n","\n","# TODO : Complete the Calculator Model!\n","\n","class Calculator(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.add_list = nn.ModuleList([Add(2), Add(3), Add(5)])\n","\n","    def forward(self, x):\n","        # TODO : self.add_listÏóê Îã¥Í∏¥ Î™®ÎìàÎì§ÏùÑ Ïù¥Ïö©ÌïòÏó¨ÏÑú\n","        #        y = ((x + 3) + 2) + 5 Ïùò Ïó∞ÏÇ∞ÏùÑ Íµ¨ÌòÑÌïòÏÑ∏Ïöî!\n","        for i, _ in enumerate(self.add_list):\n","            x = self.add_list[i](x)\n","        return x\n","\n","\n","# You do not need to modify the code below!\n","x = torch.tensor([1])\n","\n","calculator = Calculator()\n","output = calculator(x)\n","\n","if output == 11:\n","    print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","else:\n","    print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n"]}]},{"cell_type":"markdown","metadata":{"id":"XLOhs8I56dYA"},"source":["##### üí° torch.nn.ModuleDict\n","\n","``` python\n","ü¶Ü\n","torch.nn.ModuleLists are really convenient!\n","But if the size of the modules on the list gets really big,\n","I think it'll be really hard to find the module you want with indexing in the future!\n","\n","If you store a particular module using the key value like Python's dict,\n","Wouldn't it be easier to bring the module you want later?\n","I happened to get a torch for PyTorch.There's an nn.ModuleDict! Let's write it together!\n","```\n","\n","- [torch.nn.ModuleDict - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"suYi2pjj6dYK","executionInfo":{"status":"ok","timestamp":1654941067000,"user_tz":-540,"elapsed":31,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"d1d68ee4-6eb1-4d3b-a437-65b9e16f3f1d"},"source":["import torch\n","from torch import nn\n","\n","# TODO : Read and understand the following modules!\n","\n","class Add(nn.Module):\n","    def __init__(self, value):\n","        super().__init__()\n","        self.value = value\n","\n","    def forward(self, x):\n","        return x + self.value\n","\n","\n","# TODO : Complete the Calculator Model!\n","class Calculator(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.add_dict = nn.ModuleDict({'add2': Add(2),\n","                                       'add3': Add(3),\n","                                       'add5': Add(5)})\n","\n","    def forward(self, x):\n","        # TODO : self.add_dictÏóê Îã¥Í∏¥ Î™®ÎìàÎì§ÏùÑ Ïù¥Ïö©ÌïòÏó¨ÏÑú\n","        #        y = ((x + 3) + 2) + 5 Ïùò Ïó∞ÏÇ∞ÏùÑ Íµ¨ÌòÑÌïòÏÑ∏Ïöî!\n","        for key in self.add_dict.keys():\n","          x = self.add_dict[key](x)\n","        return x\n","\n","#  You do not need to modify the code below!\n","x = torch.tensor([1])\n","\n","calculator = Calculator()\n","output = calculator(x)\n","\n","if output == 11:\n","    print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","else:\n","    print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n"]}]},{"cell_type":"markdown","metadata":{"id":"CgV9Ntk38ieo"},"source":["#### ‚ùì <font color='red'><b>[ ÌÄ¥Ï¶à ]</b></font> Python List vs PyTorch ModuleList\n","``` python\n","ü¶Ü\n","But now that I think about it, there's a list on Python, too\n","Did PyTorch make the ModuleList separately?\n","\n","I wonder why!\n","```\n","\n","- [torch.nn.ModuleList - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#torch.nn.ModuleList)\n","\n","üéÅ **ÌûåÌä∏** üéÅ\n","- You can get a hint by executing the code written below!"]},{"cell_type":"code","metadata":{"id":"p0X4Bi7E9bjz"},"source":["# You do not need to modify the code below!\n","class Add(nn.Module):\n","    def __init__(self, value):\n","        super().__init__()\n","        self.value = value\n","\n","    def forward(self, x):\n","        return x + self.value\n","\n","\n","class PythonList(nn.Module):\n","    \"\"\"Python List\"\"\"\n","    def __init__(self):\n","        super().__init__()\n","\n","        # Python List\n","        self.add_list = [Add(2), Add(3), Add(5)]\n","\n","    def forward(self, x):\n","        x = self.add_list[1](x)\n","        x = self.add_list[0](x)\n","        x = self.add_list[2](x)\n","        \n","        return x\n","\n","class PyTorchList(nn.Module):\n","    \"\"\"PyTorch List\"\"\"\n","    def __init__(self):\n","        super().__init__()\n","\n","        # Pytorch ModuleList\n","        self.add_list = nn.ModuleList([Add(2), Add(3), Add(5)])\n","\n","    def forward(self, x):\n","        x = self.add_list[1](x)\n","        x = self.add_list[0](x)\n","        x = self.add_list[2](x)\n","        \n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wcZcR67F_MbE","executionInfo":{"status":"ok","timestamp":1654941067001,"user_tz":-540,"elapsed":26,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"50ecdc5f-6cca-449e-de4f-9f1b4b2092e4"},"source":["# You do not need to modify the code below!\n","x = torch.tensor([1])\n","\n","python_list = PythonList()\n","pytorch_list = PyTorchList()\n","\n","# Functional operation is the same!\n","\n","print(python_list(x), pytorch_list(x))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([11]) tensor([11])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o8qgY2EK_lMb","executionInfo":{"status":"ok","timestamp":1654941067002,"user_tz":-540,"elapsed":22,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"a26fb59d-e80b-4a28-e87c-ad80b88bbc0e"},"source":["# Python list their collection module with vanished into thin air!\n","\n","python_list"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PythonList()"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I-eFwdj7ABMH","executionInfo":{"status":"ok","timestamp":1654941067002,"user_tz":-540,"elapsed":18,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"df0bf6a9-8e00-4a2a-8e36-251128b6321c"},"source":["# But pytorch modulelist were salty! turned up in a collection module with!\n","pytorch_list"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PyTorchList(\n","  (add_list): ModuleList(\n","    (0): Add()\n","    (1): Add()\n","    (2): Add()\n","  )\n",")"]},"metadata":{},"execution_count":53}]},{"cell_type":"markdown","metadata":{"id":"8EZ7R-Js8ie5"},"source":["```python\n","üòå\n","# TODO : It's a question that's right and wrong. Please read the document and write down the answers freely\n","\n","\n","```\n","It is right because PyTorch module list holds other submodules in a list. PyTorch modules are properly registered, and are visible by all module methods. The indexing is also similar to like that of a regular Python list.\n"]},{"cell_type":"markdown","metadata":{"id":"6ARH3kXTPKEq"},"source":["#### üë®‚Äçüíª <font color='green'><b>[ ÏΩîÎî© ]</b></font> a conditional statement\n","\n","``` python\n","ü¶Ü\n","It's harder than I thought to learn so many things at onceüí¶\n","I'm sorry! I usually use human language, but if it's hard, I sometimes get a duck!\n","\n","When creating a model, PyTorch uses dynamic calculation graphs\n","I heard that it has the advantage of being able to use conditional statements such as if/else easily!\n","\n","I think it's really cool! Let's write it together!\n","```\n","\n","- [Documentation main - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/index.html)\n","\n","**‚ú® useful materials ‚ú®**\n","- [Can someone explain the use of a dynamic graph? - Reddit](https://www.reddit.com/r/pytorch/comments/8kpsjy/can_someone_explain_the_use_of_a_dynamic_graph/)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mDBSmecjPKE7","executionInfo":{"status":"ok","timestamp":1654941067002,"user_tz":-540,"elapsed":14,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"4c25cbdd-3113-4b50-82e8-b8b5690f7bfb"},"source":["import torch\n","from torch import nn\n","\n","# TODO : Îã§ÏùåÏùò Î™®Îìà(Module)ÏùÑ ÏùΩÍ≥† Ïù¥Ìï¥Ìï¥Î≥¥ÏÑ∏Ïöî!\n","class Add(nn.Module):\n","    def __init__(self, value):\n","        super().__init__()\n","        self.value = value\n","\n","    def forward(self, x):\n","        return x + self.value\n","\n","class Sub(nn.Module):\n","    def __init__(self, value):\n","        super().__init__()\n","        self.value = value\n","\n","    def forward(self, x):\n","        return x - self.value\n","\n","\n","# TODO : Calculator Î™®Îç∏ÏùÑ ÏôÑÏÑ±ÌïòÏÑ∏Ïöî!\n","class Calculator(nn.Module):\n","    def __init__(self, cal_type):\n","        super().__init__()\n","        self.cal_type = cal_type\n","        self.add = Add(3)\n","        self.sub = Sub(3)\n","\n","    def forward(self, x):\n","        # TODO : cal_typeÏóê \"add\"Í∞Ä ÏûÖÎ†•ÎêòÎ©¥ ÎçîÌïòÍ∏∞ Î™®Îç∏ y = x + 3\n","        #                   \"sub\"Í∞Ä ÏûÖÎ†•ÎêòÎ©¥ ÎπºÍ∏∞ Î™®Îç∏ y = x - 3\n","        #                   \"add\", \"sub\"Í∞Ä ÏïÑÎãå Îã§Î•∏ Î¨∏ÏûêÏó¥Ïù¥ ÏûÖÎ†•ÎêòÎ©¥ ValueErrorÏùÑ ÏùºÏúºÌÇ§ÏÑ∏Ïöî!\n","        #        if/elif/else Ï°∞Í±¥Î¨∏ÏùÑ ÏÇ¨Ïö©ÌïòÏÑ∏Ïöî! \n","        if self.cal_type == \"add\":\n","            x = self.add(x)\n","        elif self.cal_type == \"sub\":\n","          x = self.sub(x)\n","        else:\n","          raise ValueError\n","        return x\n","\n","\n","# ÏïÑÎûò ÏΩîÎìúÎäî ÏàòÏ†ïÌïòÏã§ ÌïÑÏöîÍ∞Ä ÏóÜÏäµÎãàÎã§!\n","x = torch.tensor([5])\n","\n","try:\n","    calculator = Calculator(\"none\")\n","    output = calculator(x)\n","\n","    print(\"ü¶Ü ÏûòÎ™ªÎêú Î¨∏ÏûêÏó¥ ÏûÖÎ†•ÏóêÎäî ÏóêÎü¨Î•º Î∞úÏÉùÏãúÌÇ§ÏÑ∏Ïöî!!\")\n","except ValueError:\n","    calculator = Calculator(\"add\")\n","    add_output = calculator(x)\n","\n","    calculator = Calculator(\"sub\")\n","    sub_output = calculator(x)\n","    \n","    if add_output == 8 and sub_output == 2:\n","        print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","    else:\n","        print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")\n","except:\n","    print(\"ü¶Ü ValueErrorÎ•º Î∞úÏÉùÏãúÌÇ§ÏÑ∏Ïöî!!\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n"]}]},{"cell_type":"markdown","metadata":{"id":"Pfdy2siYp4ua"},"source":["#### üë®‚Äçüíª <font color='green'><b>[ ÏΩîÎî© ]</b></font> To feel the flow of module.\n","\n","``` python\n","ü¶Ü\n","It's cool that a module can contain a module!\n","\n","- Function, which is the smallest functional unit\n","- a layer of functions\n","- Model with layers\n","\n","If you stack blocks from small parts one by one, then at some point,\n","We will be able to see a great tower called the giant deep learning model!\n","\n","Experience the flow of module-to-module connections!\n","What is the order of initialization for each module?\n","Take your time to think about when it starts and ends!\n","```\n","\n","- [Documentation main - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/index.html)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uGPSjEytp4um","executionInfo":{"status":"ok","timestamp":1654941067364,"user_tz":-540,"elapsed":373,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"9375a51d-ab65-45a8-dafe-a48e34cd94e2"},"source":["import torch\n","from torch import nn\n","\n","\n","# Function\n","class Function_A(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        print(f\"        Function A Initialized\")\n","\n","    def forward(self, x):\n","        print(f\"        Function A started\")\n","        print(f\"        Function A done\")\n","\n","class Function_B(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        print(f\"        Function B Initialized\")\n","\n","    def forward(self, x):\n","        print(f\"        Function B started\")\n","        print(f\"        Function B done\")\n","\n","class Function_C(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        print(f\"        Function C Initialized\")\n","\n","    def forward(self, x):\n","        print(f\"        Function C started\")\n","        print(f\"        Function C done\")\n","\n","class Function_D(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        print(f\"        Function D Initialized\")\n","\n","    def forward(self, x):\n","        print(f\"        Function D started\")\n","        print(f\"        Function D done\")\n","\n","\n","# Layer\n","class Layer_AB(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.a = Function_A()\n","        self.b = Function_B()\n","\n","        print(f\"    Layer AB Initialized\")\n","\n","    def forward(self, x):\n","        print(f\"    Layer AB started\")\n","        self.a(x)\n","        self.b(x)\n","        print(f\"    Layer AB done\")\n","\n","class Layer_CD(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.c = Function_C()\n","        self.d = Function_D()\n","\n","        print(f\"    Layer CD Initialized\")\n","\n","    def forward(self, x):\n","        print(f\"    Layer CD started\")\n","        self.c(x)\n","        self.d(x)\n","        print(f\"    Layer CD done\")\n","\n","\n","# Model\n","class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.ab = Layer_AB()\n","        self.cd = Layer_CD()\n","\n","        print(f\"Model ABCD Initialized\\n\")\n","\n","    def forward(self, x):\n","        print(f\"Model ABCD started\")\n","        self.ab(x)\n","        self.cd(x)\n","        print(f\"Model ABCD done\\n\")\n","\n","\n","x = torch.tensor([7])\n","\n","model = Model()\n","model(x)\n","\n","print(\"üéâüéâüéâ Î™®Îì† Îî•Îü¨Îãù Î™®Îç∏ÏùÄ Ïù¥Ï≤òÎüº ModuleÎì§Ïù¥ ÏåìÏù¥Í≥† ÏåìÏó¨ÏÑú ÎßåÎì§Ïñ¥ÏßëÎãàÎã§! üéâüéâüéâ\")\n","print(\"üéâüéâüéâ ÌùêÎ¶ÑÏùÑ ÎäêÍª¥Î≥¥ÏãúÍ≥† Ïù¥ ÌùêÎ¶ÑÏù¥ Ïù¥Ìï¥Í∞Ä ÎêòÏã† Î∂ÑÏùÄ Îã§ÏùåÏúºÎ°ú Í∞ÄÏãúÎ©¥ Îê©ÎãàÎã§! üéâüéâ\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["        Function A Initialized\n","        Function B Initialized\n","    Layer AB Initialized\n","        Function C Initialized\n","        Function D Initialized\n","    Layer CD Initialized\n","Model ABCD Initialized\n","\n","Model ABCD started\n","    Layer AB started\n","        Function A started\n","        Function A done\n","        Function B started\n","        Function B done\n","    Layer AB done\n","    Layer CD started\n","        Function C started\n","        Function C done\n","        Function D started\n","        Function D done\n","    Layer CD done\n","Model ABCD done\n","\n","üéâüéâüéâ Î™®Îì† Îî•Îü¨Îãù Î™®Îç∏ÏùÄ Ïù¥Ï≤òÎüº ModuleÎì§Ïù¥ ÏåìÏù¥Í≥† ÏåìÏó¨ÏÑú ÎßåÎì§Ïñ¥ÏßëÎãàÎã§! üéâüéâüéâ\n","üéâüéâüéâ ÌùêÎ¶ÑÏùÑ ÎäêÍª¥Î≥¥ÏãúÍ≥† Ïù¥ ÌùêÎ¶ÑÏù¥ Ïù¥Ìï¥Í∞Ä ÎêòÏã† Î∂ÑÏùÄ Îã§ÏùåÏúºÎ°ú Í∞ÄÏãúÎ©¥ Îê©ÎãàÎã§! üéâüéâ\n"]}]},{"cell_type":"markdown","metadata":{"id":"LYE0lhVK2Vow"},"source":["#### üë®‚Äçüíª <font color='green'><b>[ ÏΩîÎî© ]</b></font> Parameter\n","\n","``` python\n","ü¶Ü\n","I was thinking about linear transformation, Y = XW + b!\n","We're going to torch X.We make it with Tensor, but where do we make W and B?\n","\n","At first glance, I heard from a friend that the pre-made tensors in the nn.Module\n","I think I heard you can keep it! What did I say, I think I said Parameter!\n","```\n","\n","- [Documentation main - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/index.html)\n","- [torch.nn.parameter.Parameter - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html?highlight=parameter)\n","\n","üéÅ **ÌûåÌä∏** üéÅ\n","- [PyTorch linear.py L81 - L85 - PyTorch Í≥µÏãù Github](https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/linear.py#L81-L85)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wQoHSQcA2Vo3","executionInfo":{"status":"ok","timestamp":1654941067364,"user_tz":-540,"elapsed":61,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"1efd5919-7333-441c-ea9d-b2392a117520"},"source":["import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","\n","\n","# TODO : Complete the Linear Model!\n","\n","class Linear(nn.Module):\n","    def __init__(self, in_features, out_features):\n","        super().__init__()\n","\n","        # TODO : Create W, b parameters! Please initialize all to 1!\n","        self.W = Parameter(torch.ones((out_features, in_features)))\n","        self.b = Parameter(torch.ones((out_features)))\n","\n","    def forward(self, x):\n","        output = torch.addmm(self.b, x, self.W.T)\n","\n","        return output\n","\n","\n","# You do not need to modify the code below!\n","x = torch.Tensor([[1, 2],\n","                  [3, 4]])\n","\n","linear = Linear(2, 3)\n","output = linear(x)\n","\n","if torch.all(output == torch.Tensor([[4, 4, 4],\n","                                     [8, 8, 8]])):\n","    print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","else:\n","    print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n"]}]},{"cell_type":"markdown","metadata":{"id":"S8u8jNL8H_dN"},"source":["#### ‚ùì <font color='red'><b>[ ÌÄ¥Ï¶à ]</b></font> Tensor vs Parameter\n","``` python\n","ü¶Ü\n","If you think about it, shouldn't W and B also use a tensor?\n","Why do you have to use a separate class called Parameter?\n","```\n","üéÅ **ÌûåÌä∏** üéÅ\n","- If you drawn up under the code to run, you can get the hint!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ULF5STEQH_dO","executionInfo":{"status":"ok","timestamp":1654941067365,"user_tz":-540,"elapsed":54,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"6857ee59-5748-410a-fd06-232527fcdda1"},"source":["import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","\n","\n","class Linear_Parameter(nn.Module):\n","    def __init__(self, in_features, out_features):\n","        super().__init__()\n","\n","        # torch.nn.parameter.Parameter\n","        self.W = Parameter(torch.ones((out_features, in_features)))\n","        self.b = Parameter(torch.ones(out_features))\n","\n","    def forward(self, x):\n","        output = torch.addmm(self.b, x, self.W.T)\n","\n","        return output\n","\n","class Linear_Tensor(nn.Module):\n","    def __init__(self, in_features, out_features):\n","        super().__init__()\n","\n","        # torch.Tensor\n","        self.W = torch.ones((out_features, in_features))\n","        self.b = torch.ones(out_features)\n","\n","    def forward(self, x):\n","        output = torch.addmm(self.b, x, self.W.T)\n","\n","        return output\n","\n","\n","x = torch.Tensor([[1, 2],\n","                  [3, 4]])\n","\n","linear_parameter = Linear_Parameter(2, 3)\n","linear_tensor = Linear_Tensor(2, 3)\n","\n","output_parameter = linear_parameter(x)\n","output_tensor = linear_tensor(x)\n","\n","# You can see that the values are calculated the same!\n","# But if you look closely at the output, you can only use the parameter to make W, b\n","# Grad_fn, a function that calculates gradients, is created in the output tensor\n","print(output_parameter)\n","print(output_tensor)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[4., 4., 4.],\n","        [8., 8., 8.]], grad_fn=<AddmmBackward0>)\n","tensor([[4., 4., 4.],\n","        [8., 8., 8.]])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SCmHCEEWH_dP","executionInfo":{"status":"ok","timestamp":1654941067365,"user_tz":-540,"elapsed":47,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"fe9f401f-d453-4c01-aed5-962cb7d5d49e"},"source":["# W, b made of parameters are designated as the tensor to be stored\n","linear_parameter.state_dict()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('W', tensor([[1., 1.],\n","                      [1., 1.],\n","                      [1., 1.]])), ('b', tensor([1., 1., 1.]))])"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5obZKlPzH_dP","executionInfo":{"status":"ok","timestamp":1654941067366,"user_tz":-540,"elapsed":43,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"0b215fb5-2522-458d-fb05-caef35823bfe"},"source":["# # torch.W, b made with Tensor will not be saved\n","linear_tensor.state_dict()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict()"]},"metadata":{},"execution_count":59}]},{"cell_type":"markdown","metadata":{"id":"KH49yfoYH_dR"},"source":["```python\n","üòè\n","# TODO: It's a matter of absolute certainty. Please read the document and write down the answers freely\n","```\n","Parameter objects are Tensor objects that can be optimized. Unlike a parameter, a tensor does not calculate gradients. Hence, the value of a tensor is not updated. The value of a tensor cannot also be saved unlike a parameter when saving a model."]},{"cell_type":"markdown","metadata":{"id":"C3WfRph4AYrb"},"source":["#### üë®‚Äçüíª <font color='green'><b>[ ÏΩîÎî© ]</b></font> Buffer\n","\n","``` python\n","ü¶Ü\n","Friend says that most custom models are torches.The layers implemented on the nn\n","It's said that it's very rare to handle the Parameter yourself because it's taken away and used!\n","\n","If we're not going to write a new layer ourselves,\n","It's said that you rarely!\n","\n","But he praised me for saying that it's important to know how to use Parameters!\n","I also told her that there's a buffer!\n","\n","Unlike a parameter, a normal tensor does not calculate gradients\n","The value is not updated, and it is ignored when saving the model, right?\n","\n","However, even if the value is not updated because the parameter is not specified,\n","There might be a sensor that you want to save, right?\n","\n","In that case, you can register the tensor on the buffer!\n","When saving the model, not only the parameter but also the tensors registered as buffers are stored together!\n","\n","To sum up, it's\n","\n","- \"Tensor\"\n","  - ‚ùå Gradient calculation\n","  - ‚ùå Update the value\n","  - ‚ùå Save value when saving model\n","- \"Parameter\"\n","  - ‚úÖ Gradient calculation\n","  - ‚úÖ Update the value\n","  - ‚úÖ Save value when saving model\n","- \"Buffer\"\n","  - ‚ùå Gradient calculation\n","  - ‚ùå Update the  value\n","  - ‚úÖ Save value when saving model\n","```\n","\n","- [Documentation main - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/index.html)\n","- [register_buffer - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=register_buffer#torch.nn.Module.register_buffer)\n","\n","**‚ú® Ïú†Ïö©Ìïú ÏûêÎ£å ‚ú®**\n","- [What is the difference between `register_buffer` and `register_parameter` of `nn.Module` - PyTorch Forum](https://discuss.pytorch.org/t/what-is-the-difference-between-register-buffer-and-register-parameter-of-nn-module/32723)"]},{"cell_type":"code","metadata":{"id":"xU_FYpsgAYri","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654941067366,"user_tz":-540,"elapsed":37,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"33c794c2-915f-45ca-a3a1-fe787e2d7bdb"},"source":["import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","\n","\n","# TODO : Complete the Model Model!\n","class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.parameter = Parameter(torch.Tensor([7]))\n","        self.tensor = torch.Tensor([7])\n","        # TODO : torch.Tensor([7])Î•º bufferÏù¥ÎùºÎäî Ïù¥Î¶ÑÏúºÎ°ú bufferÏóê Îì±Î°ùÌï¥Î≥¥ÏÑ∏Ïöî!\n","        self.register_buffer('buffer', self.tensor)\n","\n","# You do not need to modify the code below!\n","model = Model()\n","\n","try:\n","    buffer = model.get_buffer('buffer')\n","    if buffer == 7:\n","        print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\\n\")\n","        print(\"üéâ Ïù¥Ï†ú bufferÏóê Îì±Î°ùÎêú tensorÎäî Î™®Îç∏Ïù¥ Ï†ÄÏû•Îê† Îïå Í∞ôÏù¥ Ï†ÄÏû•Îê†Í±∞ÏòàÏöî! üéâ\")\n","        print(model.state_dict())\n","    else:\n","        print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")\n","except:\n","    print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n","\n","üéâ Ïù¥Ï†ú bufferÏóê Îì±Î°ùÎêú tensorÎäî Î™®Îç∏Ïù¥ Ï†ÄÏû•Îê† Îïå Í∞ôÏù¥ Ï†ÄÏû•Îê†Í±∞ÏòàÏöî! üéâ\n","OrderedDict([('parameter', tensor([7.])), ('buffer', tensor([7.]))])\n"]}]},{"cell_type":"markdown","metadata":{"id":"HY5I6ZQbScV2"},"source":["``` python\n","üò©\n","Ah, it's so hard... So where do you use this?\n","```\n","\n","``` python\n","ü¶Ü\n","I knew you'd say that I prepared it!\n","One good example is used in BatchNorm!\n","I have attached the link below, so please read it for more information!\n","\n","I think it's rare to use this buffer just like Parameter!\n","But if you know it, one day you'll use it here, right?\n","```\n","\n","\n","**‚ú® Ïú†Ïö©Ìïú ÏûêÎ£å ‚ú®**\n","- [torch.nn.BatchNorm1d - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html?highlight=buffer)\n","- [PyTorch batchnorm.py L51 - L52 - PyTorch Í≥µÏãù Github](https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/batchnorm.py#L51-L52)"]},{"cell_type":"markdown","metadata":{"id":"jr6BwccdiH5s"},"source":["### ‚òÑÔ∏è nn.Module Î∂ÑÏÑùÌïòÍ∏∞\n","> I understand the basic concepts that are important in building a model. Now we have the power to build the model we want. But how do we know how the interior of the custom model is constructed after making it? If it's a custom model that you made, it's okay because I can remember it somehow. So how do you analyze the inside of a model when you bring it to refer to someone else's model? We will have time to take a quick look at the method.\n","\n","\n","- üë®‚Äçüíª <font color='green'><b>[ ÏΩîÎî© ]</b></font> Analyzing the Model of Mudeok\n","\n","- üë®‚Äçüíª <font color='green'><b>[ ÏΩîÎî© ]</b></font> Modifying a Mudeok Model - Remove a module reference\n","- üë®‚Äçüíª <font color='green'><b>[ ÏΩîÎî© ]</b></font> Modifying the Mudeok Model - Modifying the Module Output\n","- üë®‚Äçüíª <font color='green'><b>[ ÏΩîÎî© ]</b></font> Modifying the Mudeok Model - Creating a Docstring\n","- üë®‚Äçüíª <font color='green'><b>[ ÏΩîÎî© ]</b></font> Analyze BatchNorm1d\n","\n","\n","    \n"]},{"cell_type":"markdown","metadata":{"id":"P0rBcgFOdVTL"},"source":["#### üë®‚Äçüíª <font color='green'><b>[ ÏΩîÎî© ]</b></font> Î∂ÄÎçïÏù¥ Î™®Îç∏ Î∂ÑÏÑùÌï¥Î≥¥Í∏∞\n","\n","``` python\n","ü¶Ü\n","I didn't know anything about PyTorch\n","I can't believe you can make your own models! It's like a dream!\n","\n","I'm looking at the code that I wrote to feel the flow of modules\n","I can't stop the wing dance because I'm so proud of myself\n","\n","But after making the model, which module and parameter did you use?\n","How do you know?\n","\n","I think the \"nn.Module\" documentation will show you how to do it!\n","\n","I brought the code that I wrote before! It's a bit different from when you saw it, right?\n","I changed it little by little to apply what I learned!\n","Let's analyze this model I made together!\n","```\n","\n","- [Documentation main - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/index.html)\n","- [torch.nn.Module - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0wIMxj_7cxSH","executionInfo":{"status":"ok","timestamp":1654941067366,"user_tz":-540,"elapsed":31,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"f85c2215-c798-40c5-dbe3-3dcb7ae17167"},"source":["import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","\n","\n","# You do not need to modify the code below!\n","# But look at the code below and understand it as much as you can before you do the task below!\n","\n","# Function\n","class Function_A(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","\n","    def forward(self, x):\n","        x = x * 2\n","        return x\n","\n","class Function_B(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.W1 = Parameter(torch.Tensor([10]))\n","        self.W2 = Parameter(torch.Tensor([2]))\n","\n","    def forward(self, x):\n","        x = x / self.W1\n","        x = x / self.W2\n","\n","        return x\n","\n","class Function_C(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.register_buffer('duck', torch.Tensor([7]), persistent=True)\n","\n","    def forward(self, x):\n","        x = x * self.duck\n","        \n","        return x\n","\n","class Function_D(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.W1 = Parameter(torch.Tensor([3]))\n","        self.W2 = Parameter(torch.Tensor([5]))\n","        self.c = Function_C()\n","\n","    def forward(self, x):\n","        x = x + self.W1\n","        x = self.c(x)\n","        x = x / self.W2\n","\n","        return x\n","\n","\n","# Layer\n","class Layer_AB(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.a = Function_A('duck')\n","        self.b = Function_B()\n","\n","    def forward(self, x):\n","        x = self.a(x) / 5\n","        x = self.b(x)\n","\n","        return x\n","\n","class Layer_CD(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.c = Function_C()\n","        self.d = Function_D()\n","\n","    def forward(self, x):\n","        x = self.c(x)\n","        x = self.d(x) + 1\n","\n","        return x\n","\n","\n","# Model\n","class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.ab = Layer_AB()\n","        self.cd = Layer_CD()\n","\n","    def forward(self, x):\n","        x = self.ab(x)\n","        x = self.cd(x)\n","\n","        return x\n","\n","x = torch.tensor([7])\n","\n","model = Model()\n","model(x)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([6.5720], grad_fn=<AddBackward0>)"]},"metadata":{},"execution_count":61}]},{"cell_type":"markdown","metadata":{"id":"SvtNG5hkeb2G"},"source":["##### üí° named_children vs named_modules\n","> ü¶Ü Î∂ÄÎçïÏù¥Í∞Ä ÏΩîÎìúÎ•º ÏûëÏÑ±Ìï¥Ï£ºÏóàÏñ¥Ïöî\n","\n","``` python\n","ü¶Ü\n","I don't remember which modules were in the model I made!\n","So I want to see the list of modules inside the model!\n","\n","I looked up the documentation and found out that it was named children or module\n","I think the function has the function I want!\n","\n","But what's the difference between these two?\n","As expected, I'll have to check it out through the code myself!\n","```\n","\n","- [named_children - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=child#torch.nn.Module.named_children)\n","- [named_modules - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=named#torch.nn.Module.named_modules)\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zSZh9S6SjCSQ","executionInfo":{"status":"ok","timestamp":1654941067744,"user_tz":-540,"elapsed":399,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"dfaea945-ed8c-4eb6-c43d-9cdbbcd7be13"},"source":["for name, module in model.named_modules():\n","    print(f\"[ Name ] : {name}\\n[ Module ]\\n{module}\")\n","    print(\"-\" * 30)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[ Name ] : \n","[ Module ]\n","Model(\n","  (ab): Layer_AB(\n","    (a): Function_A()\n","    (b): Function_B()\n","  )\n","  (cd): Layer_CD(\n","    (c): Function_C()\n","    (d): Function_D(\n","      (c): Function_C()\n","    )\n","  )\n",")\n","------------------------------\n","[ Name ] : ab\n","[ Module ]\n","Layer_AB(\n","  (a): Function_A()\n","  (b): Function_B()\n",")\n","------------------------------\n","[ Name ] : ab.a\n","[ Module ]\n","Function_A()\n","------------------------------\n","[ Name ] : ab.b\n","[ Module ]\n","Function_B()\n","------------------------------\n","[ Name ] : cd\n","[ Module ]\n","Layer_CD(\n","  (c): Function_C()\n","  (d): Function_D(\n","    (c): Function_C()\n","  )\n",")\n","------------------------------\n","[ Name ] : cd.c\n","[ Module ]\n","Function_C()\n","------------------------------\n","[ Name ] : cd.d\n","[ Module ]\n","Function_D(\n","  (c): Function_C()\n",")\n","------------------------------\n","[ Name ] : cd.d.c\n","[ Module ]\n","Function_C()\n","------------------------------\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IKfekNTn3D3n","executionInfo":{"status":"ok","timestamp":1654941067746,"user_tz":-540,"elapsed":118,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"ff30937e-9889-4156-dab7-d03efed7eaca"},"source":["for name, child in model.named_children():\n","    print(f\"[ Name ] : {name}\\n[ Children ]\\n{child}\")\n","    print(\"-\" * 30)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[ Name ] : ab\n","[ Children ]\n","Layer_AB(\n","  (a): Function_A()\n","  (b): Function_B()\n",")\n","------------------------------\n","[ Name ] : cd\n","[ Children ]\n","Layer_CD(\n","  (c): Function_C()\n","  (d): Function_D(\n","    (c): Function_C()\n","  )\n",")\n","------------------------------\n"]}]},{"cell_type":"markdown","metadata":{"id":"Fc5uZnP929pS"},"source":["``` python\n","ü¶Ü\n","Aha! I got it now!\n","\n","\"children\" means to display only one submodule below the level\n","\"modules\" means to display all the submodules that belong to you!\n","\n","\"named_modules\", \"named_children\" returns the name of the module\n","If you just need a module, you can use \"modules\" or \"children\"!\n","\n","No, but why is \"Function_D\" referring to \"Function_C\"?\n","The same basic unit should be independent of each other, but I think there will be a problem!\n","I'll have to fix it when I'm done analyzing it!\n","```"]},{"cell_type":"markdown","metadata":{"id":"bC4XBN5k5g53"},"source":["##### üí° get_submodule\n","\n","``` python\n","ü¶Ü\n","What I made the model! know whether there are module\n","Now, I want! I want to bring certain module\n","\n","Could you bring  Function_A?\n","\n","```\n","\n","- [get_submodule - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=get_submodule#torch.nn.Module.get_submodule)\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MSYN3x5hl4Wf","executionInfo":{"status":"ok","timestamp":1654941067746,"user_tz":-540,"elapsed":61,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"3913e863-96e1-4ee8-fe8f-61c619e16f3d"},"source":["# TODO : Bring Function_A!\n","submodule = model.get_submodule('ab.a')\n","\n","\n","# You do not need to modify the code below!\n","if submodule.__class__.__name__  == 'Function_A':\n","    print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","else:\n","    print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n"]}]},{"cell_type":"markdown","metadata":{"id":"87fdrrUW_Eyg"},"source":["##### üí° Parameter\n","\n","``` python\n","ü¶Ü\n","Now I have confidence in module!\n","But thinking about it, while studying about Parameters,\n","I think I created a parameter on a module!\n","\n","We'll look at the module list in the module and see the specific module\n","Let's do the same with Parameters, as we've found!\n","```\n","\n","- [parameters - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=parameters#torch.nn.Module.parameters)\n","- [named_parameters - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=named#torch.nn.Module.named_parameters)\n","- [get_parameter - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=get#torch.nn.Module.get_parameter)\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5HZk5-vlly_P","executionInfo":{"status":"ok","timestamp":1654941067747,"user_tz":-540,"elapsed":54,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"154e7a52-4be8-4f95-b7e4-a2e3c696eaa1"},"source":["# ü¶Ü I made four parameters!\n","for name, parameter in model.named_parameters():\n","    print(f\"[ Name ] : {name}\\n[ Parameter ]\\n{parameter}\")\n","    print(\"-\" * 30)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[ Name ] : ab.b.W1\n","[ Parameter ]\n","Parameter containing:\n","tensor([10.], requires_grad=True)\n","------------------------------\n","[ Name ] : ab.b.W2\n","[ Parameter ]\n","Parameter containing:\n","tensor([2.], requires_grad=True)\n","------------------------------\n","[ Name ] : cd.d.W1\n","[ Parameter ]\n","Parameter containing:\n","tensor([3.], requires_grad=True)\n","------------------------------\n","[ Name ] : cd.d.W2\n","[ Parameter ]\n","Parameter containing:\n","tensor([5.], requires_grad=True)\n","------------------------------\n"]}]},{"cell_type":"markdown","metadata":{"id":"lWwtgIOBD5-0"},"source":["``` python\n","ü¶Ü\n","Aha! I made four parameters!\n","It's so nice to see where the parameter belongs by displaying the name!\n","\n","- \"Function_B\" has two W1, W2 parameters\n","- \"Function_D\" has two W1, W2 parameters\n","\n","You can use \"parameters\" to check the list\n","It doesn't show the name, so it's a part of a module\n","It's going to be so hard to tell if it's a parameter!\n","\n","I want to use Parameter W1, which is part of Function_B\n","Can you bring me this?\n","```"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hIhreLUX_Eyj","executionInfo":{"status":"ok","timestamp":1654941067747,"user_tz":-540,"elapsed":47,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"f44c696f-4426-45b3-c217-8fe312f19517"},"source":["# TODO :  Bring parameter W1 belonging to Function_B!\n","parameter = model.get_parameter('ab.b.W1')\n","\n","\n","# You do not need to modify the code below!\n","if parameter  == 10:\n","    print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","else:\n","    print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n"]}]},{"cell_type":"markdown","metadata":{"id":"1ZC6RK20H8iC"},"source":["##### üí° Buffer\n","\n","``` python\n","ü¶Ü\n","Come to think of it, I think I added a buffer\n","Let's analyze the buffer together!\n","```\n","\n","- [buffers - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=buffers#torch.nn.Module.buffers)\n","- [named_buffers - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=named_buffers#torch.nn.Module.named_buffers)\n","- [get_buffer - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=get_buffer#torch.nn.Module.get_buffer)\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4AxUn_jgH8iE","executionInfo":{"status":"ok","timestamp":1654941067748,"user_tz":-540,"elapsed":39,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"d619c3a6-e470-49a1-d2d0-51a2924b03bb"},"source":["#  TODO : to get a complete list of buffers belonging to the model by using named_buffers !\n","for name, buffer in model.named_buffers():\n","    print(f\"[ Name ] : {name}\\n[ Buffer ] : {buffer}\")\n","    print(\"-\" * 30)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[ Name ] : cd.c.duck\n","[ Buffer ] : tensor([7.])\n","------------------------------\n","[ Name ] : cd.d.c.duck\n","[ Buffer ] : tensor([7.])\n","------------------------------\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xWjaJqgWI5r-","executionInfo":{"status":"ok","timestamp":1654941067748,"user_tz":-540,"elapsed":32,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"67713c5b-da59-44d6-fa12-7bf0da73b48c"},"source":["# TODO : Use buffers to get a complete list of buffers belonging to a model!\n","for buffer in model.buffers():\n","    print(f\"[ Buffer ] : {buffer}\")\n","    print(\"-\" * 30)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[ Buffer ] : tensor([7.])\n","------------------------------\n","[ Buffer ] : tensor([7.])\n","------------------------------\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B2ePuoOWH8iF","executionInfo":{"status":"ok","timestamp":1654941067749,"user_tz":-540,"elapsed":27,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"71488e36-9276-4d1a-c16b-6826bfd21da4"},"source":["# TODO : Bring the buffer that belongs to Function_C!\n","buffer = model.get_buffer('cd.c.duck')\n","\n","\n","# You do not need to modify the code below!\n","if buffer == 7:\n","    print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","else:\n","    print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n"]}]},{"cell_type":"markdown","metadata":{"id":"JfrjK8Q5tNH6"},"source":["##### üí° Docstring\n","\n","``` python\n","ü¶Ü\n","Oops! I forgot!\n","\n","All functions and classes provided by PyTorch are written with Docstring!\n","But I don't really use Documentation because it's more convenient!\n","\n","I'm creating a custom model and I'm going to use this custom model\n","Writing Docstring is a must for other developers and for themselves in the future!\n","If you have this Docstring when you make Documentation later, it will be easy to make, right?\n","\n","You made a basic mistake!\n","I should add Docstring later!\n","```\n","- [Docstring - Wikipedia](https://en.wikipedia.org/wiki/Docstring)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tCkBRdsItfTQ","executionInfo":{"status":"ok","timestamp":1654941067749,"user_tz":-540,"elapsed":21,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"f779b536-d1a8-40f2-c7c4-aa8e1dc612c2"},"source":["print(model.__doc__)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["None\n"]}]},{"cell_type":"markdown","metadata":{"id":"VeIqAIk1NTUh"},"source":["#### üë®‚Äçüíª <font color='green'><b>[ ÏΩîÎî© ]</b></font> Î∂ÄÎçïÏù¥ Î™®Îç∏ ÏàòÏ†ïÌïòÍ∏∞ - module Ï∞∏Ï°∞ Ï†úÍ±∞\n","\n","``` python\n","ü¶Ü\n","When I analyzed my model, I found out that \"Function_D\" which I made as the most basic unit contains \"Function_C\"!\n","\n","I don't want modules to refer to each other as basic units!\n","\n","And even if you remove \"Function_C\" from \"Function_D\",\n","I want to make the whole operation the same!\n","\n","Let's fix it together!\n","```\n","\n","- [Documentation main - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/index.html)\n","- [torch.nn.Module - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A95FtG-1Px7k","executionInfo":{"status":"ok","timestamp":1654941068049,"user_tz":-540,"elapsed":314,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"69f96470-83fa-46f3-df03-e13312d31cb5"},"source":["import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","\n","\n","# Function\n","class Function_A(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","\n","    def forward(self, x):\n","        x = x * 2\n","        return x\n","\n","class Function_B(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.W1 = Parameter(torch.Tensor([10]))\n","        self.W2 = Parameter(torch.Tensor([2]))\n","\n","    def forward(self, x):\n","        x = x / self.W1\n","        x = x / self.W2\n","\n","        return x\n","\n","class Function_C(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.register_buffer('duck', torch.Tensor([7]), persistent=True)\n","        \n","    def forward(self, x):\n","        x = x * self.duck\n","        \n","        return x\n","\n","# TODO : Remove the reference to Function_C and add an alternative operation!\n","#        The computational results of the entire model must not change!\n","class Function_D(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.W1 = Parameter(torch.Tensor([3]))\n","        self.W2 = Parameter(torch.Tensor([5]))\n","        self.register_buffer('duck', torch.Tensor([7]), persistent=True)\n","\n","    def forward(self, x):\n","        x = x + self.W1\n","        x = x * self.duck\n","        x = x / self.W2\n","\n","        return x\n","\n","\n","# Layer\n","class Layer_AB(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.a = Function_A('duck')\n","        self.b = Function_B()\n","\n","    def forward(self, x):\n","        x = self.a(x) / 5\n","        x = self.b(x)\n","\n","        return x\n","\n","class Layer_CD(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.c = Function_C()\n","        self.d = Function_D()\n","\n","    def forward(self, x):\n","        x = self.c(x)\n","        x = self.d(x) + 1\n","\n","        return x\n","\n","\n","# Model\n","class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.ab = Layer_AB()\n","        self.cd = Layer_CD()\n","\n","    def forward(self, x):\n","        x = self.ab(x)\n","        x = self.cd(x)\n","\n","        return x\n","\n","\n","\n","# ÏïÑÎûò ÏΩîÎìúÎäî ÏàòÏ†ïÌïòÏã§ ÌïÑÏöîÍ∞Ä ÏóÜÏäµÎãàÎã§!\n","x = torch.tensor([7])\n","\n","model = Model()\n","output = model(x)\n","\n","fixed = 1\n","for name, _ in model.named_modules():\n","    if 'cd.d.c' == name:\n","        print(\"ü¶Ü ÏïÑÏßÅ Function_DÍ∞Ä Function_CÎ•º Ï∞∏Ï°∞ÌïòÍ≥† ÏûàÎÑ§Ïöî!\")\n","        fixed = 0\n","\n","if fixed:\n","    if output == 6.5720:\n","        print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","    else:\n","        print(\"ü¶Ü The reference between modules was successfully modified, but the model operation has changed!\")\n","        print(\"ü¶Ü Add a replacement operation to Function_D as you remove Function_C!\")\n","else:\n","    print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n"]}]},{"cell_type":"markdown","metadata":{"id":"ij7zgUmsUwD6"},"source":["#### üë®‚Äçüíª <font color='green'><b>[ ÏΩîÎî© ]</b></font> Î∂ÄÎçïÏù¥ Î™®Îç∏ ÏàòÏ†ïÌïòÍ∏∞ - module Ï∂úÎ†• ÎÇ¥Ïö© Î≥ÄÍ≤ΩÌïòÍ∏∞\n","\n","``` python\n","ü¶Ü\n","In the case of \"Function_A\" which is a function unit module,\n","To create an instance, you have to enter a name!\n","So we created the \"Function_A\" as follows!\n","\n","# Function_A('duck')\n","\n","I wanted to print out the completed model and it would look like this!\n","\n","‚úÖ The ideal output that Boo-duk wants\n","\n","Model(\n","  (ab): Layer_AB(\n","    (a): Function_A(name=duck)\n","    (b): Function_B()\n","  )\n","  (cd): Layer_CD(\n","    (c): Function_C()\n","    (d): Function_D()\n","  )\n",")\n","\n","But when I actually printed it out, it looked like this.\n","\n","‚ùå Actual Output Results\n","\n","Model(\n","  (ab): Layer_AB(\n","    (a): Function_A()\n","    (b): Function_B()\n","  )\n","  (cd): Layer_CD(\n","    (c): Function_C()\n","    (d): Function_D()\n","  )\n",")\n","\n","What should I do with this? Tightly! üí¶\n","```\n","\n","- [Documentation main - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/index.html)\n","- [extra_repr - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=repr#torch.nn.Module.extra_repr)\n","\n","üéÅ **ÌûåÌä∏** üéÅ\n","- Find repr-related methods in the nn.Module class!\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"enxjXUKNUwD9","executionInfo":{"status":"ok","timestamp":1654941068368,"user_tz":-540,"elapsed":324,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"aa837b19-e831-40ff-da9c-f18f2f2dc106"},"source":["import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","\n","\n","# Function\n","\n","# TODO : Please modify Function_A so that the right output comes out!\n","\n","class Function_A(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","\n","    def extra_repr(self):\n","        return 'name=' + self.name\n","\n","    def forward(self, x):\n","        x = x * 2\n","        return x\n","\n","class Function_B(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.W1 = Parameter(torch.Tensor([10]))\n","        self.W2 = Parameter(torch.Tensor([2]))\n","\n","    def forward(self, x):\n","        x = x / self.W1\n","        x = x / self.W2\n","\n","        return x\n","\n","class Function_C(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.register_buffer('duck', torch.Tensor([7]), persistent=True)\n","\n","    def forward(self, x):\n","        x = x * self.duck\n","        \n","        return x\n","\n","class Function_D(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.W1 = Parameter(torch.Tensor([3]))\n","        self.W2 = Parameter(torch.Tensor([5]))\n","        self.register_buffer('duck', torch.Tensor([7]), persistent=True)\n","\n","    def forward(self, x):\n","        x = x + self.W1\n","        x = x * self.duck\n","        x = x / self.W2\n","\n","        return x\n","\n","\n","# Layer\n","class Layer_AB(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.a = Function_A('duck')\n","        self.b = Function_B()\n","\n","    def forward(self, x):\n","        x = self.a(x) / 5\n","        x = self.b(x)\n","\n","        return x\n","\n","class Layer_CD(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.c = Function_C()\n","        self.d = Function_D()\n","\n","    def forward(self, x):\n","        x = self.c(x)\n","        x = self.d(x) + 1\n","\n","        return x\n","\n","\n","# Model\n","class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.ab = Layer_AB()\n","        self.cd = Layer_CD()\n","\n","    def forward(self, x):\n","        x = self.ab(x)\n","        x = self.cd(x)\n","\n","        return x\n","\n","\n","# You do not need to modify the code below!\n","\n","model = Model()\n","model_repr = repr(model)\n","\n","print(\"Î™®Îç∏ Ï∂úÎ†• Í≤∞Í≥º\")\n","print(\"-\" * 30)\n","print(model_repr)\n","print(\"-\" * 30)\n","\n","answer = \"Model(\\n  (ab): Layer_AB(\\n    (a): Function_A(name=duck)\\n    (b): Function_B()\\n  )\\n  (cd): Layer_CD(\\n    (c): Function_C()\\n    (d): Function_D()\\n  )\\n)\"\n","\n","if model_repr == answer:\n","    print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","    print(\"ü¶Ü ÎÑàÎ¨¥ Í≥†ÎßàÏõåÏöî ÍΩâÍΩâ!\")\n","else:\n","    print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Î™®Îç∏ Ï∂úÎ†• Í≤∞Í≥º\n","------------------------------\n","Model(\n","  (ab): Layer_AB(\n","    (a): Function_A(name=duck)\n","    (b): Function_B()\n","  )\n","  (cd): Layer_CD(\n","    (c): Function_C()\n","    (d): Function_D()\n","  )\n",")\n","------------------------------\n","üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n","ü¶Ü ÎÑàÎ¨¥ Í≥†ÎßàÏõåÏöî ÍΩâÍΩâ!\n"]}]},{"cell_type":"markdown","metadata":{"id":"B6lHaqZqvnb5"},"source":["#### üë®‚Äçüíª <font color='green'><b>[ ÏΩîÎî© ]</b></font> Î∂ÄÎçïÏù¥ Î™®Îç∏ ÏàòÏ†ïÌïòÍ∏∞ - Docstring ÏûëÏÑ±\n","\n","``` python\n","ü¶Ü\n","Let's write a docstring lightly!\n","There are various styles like Numpy, Pydoc, Google, and so on, so if you're curious,\n","Let's read the link below and study!\n","\n","For now, let's just add something called Docstring regardless of style!\n","```\n","\n","- [Documentation main - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/index.html)\n","\n","**‚ú® Ïú†Ïö©Ìïú ÏûêÎ£å ‚ú®**\n","- [Docstrings in Python - Data Camp](https://www.datacamp.com/community/tutorials/docstrings-python)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X8_KUU4AvncC","executionInfo":{"status":"ok","timestamp":1654941068369,"user_tz":-540,"elapsed":39,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"da29eb5c-fc19-451d-e2de-19039f493ebf"},"source":["import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","\n","# TODO : Add Docstring!\n","class Model(nn.Module):\n","    \"\"\" This is an example of Docstring.\"\"\"\n","    def __init__(self):\n","        super().__init__()\n","\n","\n","\n","# You do not need to modify the code below!\n","model = Model()\n","\n","if model.__doc__:\n","    print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","else:\n","    print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n"]}]},{"cell_type":"markdown","metadata":{"id":"tka7VMeekxd7"},"source":["#### üë®‚Äçüíª <font color='green'><b>[ ÏΩîÎî© ]</b></font> BatchNorm1d Î∂ÑÏÑùÌï¥Î≥¥Í∏∞\n","\n","``` python\n","ü¶Ü\n","I think I have confidence now!\n","\n","Analyze one of the modules that PyTorch made in advance\n","I want to know how much I've grown!\n","\n","Well, what's good? Try BatchNorm1d!\n","```\n","\n","- [Documentation main - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/index.html)\n","- [torch.nn.BatchNorm1d - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html#torch.nn.BatchNorm1d)"]},{"cell_type":"code","metadata":{"id":"WUshguoBlTNm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654941068369,"user_tz":-540,"elapsed":30,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"2fa4a876-e7b0-4497-edf8-bb6a32b81c78"},"source":["import torch\n","import torch.nn\n","\n","module = nn.BatchNorm1d(10)\n","\n","# TODO : nn.Parameter d and 1 batchnorm buffer the number!\n","parameter_n = 0\n","for name, param in module.named_parameters():\n","    parameter_n += 1\n","buffer_n = 0\n","\n","# TODO : nn.Find out the buffer name of BatchNorm1d!\n","#           [Name, name, name] Please save it in the form\n","buffer_names = set([])\n","for name, buffer in module.named_buffers():\n","    buffer_names.add(name)\n","    buffer_n += 1\n","\n","\n","\n","# You do not need to modify the code below!\n","\n","answer = set(['running_mean', 'running_var', 'num_batches_tracked'])\n","\n","if parameter_n == 2 and buffer_n == 3 and answer == set(buffer_names):\n","    print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","else:\n","    print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n"]}]},{"cell_type":"markdown","metadata":{"id":"lFLQWT3w0m4v"},"source":["``` python\n","ü¶Ü\n","It's much more convenient to look at the official PyTorch document than the Docstring\n","BatchNorm1d didn't watch Docstring separately!\n","\n","But if you're using a model that doesn't have Documentation,\n","Think of Docstring as Documentation and look carefully!\n","```"]},{"cell_type":"markdown","metadata":{"id":"2clV-zzGiH-v"},"source":["### ‚òÑÔ∏è nn.Module ÏïåÏì∏Ïã†Ïû°\n","> Although not covered on the nn module. If you know of the ability to provide useful look at!\n","\n","- üë®‚Äçüíª <font color='green'><b>[ ÏΩîÎî© ]</b></font> hook\n","- üë®‚Äçüíª <font color='green'><b>[ ÏΩîÎî© ]</b></font> apply\n"]},{"cell_type":"markdown","metadata":{"id":"7tJVT5Mp9I4S"},"source":["#### üë®‚Äçüíª <font color='green'><b>[ ÏΩîÎî© ]</b></font> hook\n","\n","``` python\n","ü¶Ü\n","I've never heard of the unfamiliar term hook!\n","What is this? I'm scared for some reason!\n","\n","I looked it up on the internet, and found that other programmers in packaged code\n","This interface is designed to execute custom code in the middle!\n","\n","- Analyze the execution logic of a program or\n","- When you want to add additional functionality to a program\n","\n","It's said that used!\n","\n","It's not like I know! My friend is helping me, so let's learn together!\n","```\n","\n","- [Documentation main - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/index.html)\n","- [hook - WhatIs](https://whatis.techtarget.com/definition/hook)"]},{"cell_type":"markdown","metadata":{"id":"5HujUYII-wih"},"source":["##### üí° hookÏùò ÏõêÎ¶¨\n","> ü¶Ü Î∂ÄÎçïÏù¥ ÏπúÍµ¨Í∞Ä ÏΩîÎìúÎ•º ÏûëÏÑ±Ìï¥Ï£ºÏóàÏñ¥Ïöî\n","\n","``` python\n","ü¶Ü\n","My friend wrote me the code because I said I really don't know what hook is!\n","They say it'll be easier to understand after seeing this code!\n","```\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nok5e_w1PjwS","executionInfo":{"status":"ok","timestamp":1654941068370,"user_tz":-540,"elapsed":25,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"f2b54f20-1fda-456a-bc41-64d8c6362086"},"source":["def program_A(x):\n","    print('program A processing!')\n","    return x + 3\n","\n","def program_B(x):\n","    print('program B processing!')\n","    return x - 3\n","\n","class Package(object):\n","    \"\"\"Package code tied to program A and B\"\"\"\n","    def __init__(self):\n","        self.programs = [program_A, program_B]\n","        self.hooks = []\n","\n","    def __call__(self, x):\n","        for program in self.programs:\n","            x = program(x)\n","\n","            #  re-created interface hooks for package users to register their own custom programs\n","            if self.hooks:\n","                for hook in self.hooks:\n","                    output = hook(x)\n","\n","                    # Update x only for hooks with return values\n","                    if output:\n","                        x = output\n","\n","        return x\n","\n","# Ìå®ÌÇ§ÏßÄ ÏÉùÏÑ±\n","package = Package()\n","\n","# Ìå®ÌÇ§ÏßÄ Ïã§Ìñâ\n","input = 3\n","output = package(input)\n","\n","# Ìå®ÌÇ§ÏßÄ Í≤∞Í≥º\n","print(f\"Package Process Result! [ input {input} ] [ output {output} ]\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["program A processing!\n","program B processing!\n","Package Process Result! [ input 3 ] [ output 3 ]\n"]}]},{"cell_type":"markdown","metadata":{"id":"0KIn1D59SxDf"},"source":["``` python\n","ü¶Ü\n","I think I'm starting to get the hang of it after I saw the chords\n","\n","Package originally had a variable called self.hooks!\n","So when you run the package, you can see the programs that are included in the package one by one\n","In the middle of running, you check if there is a function registered in self.hooks!\n","\n","- Run if any function registered in self.hooks ‚úÖ\n","- Ignore functions registered in self.hooks ‚ùå\n","\n","Developers who use the package can use their custom code in the middle of the package\n","It's an interface made in advance by the developers who made the package so that it can be executed!\n","\n","```\n","```python\n","üòØ\n","Oh my god! We've been using various packages\n","So that we can execute the custom code inside the package,\n","You could have had an interface called \"hook\"!\n","```\n","\n","``` python\n","ü¶Ü\n","I think I need to know everything to use it\n","\n","Let's take a look at the example of using the hook that my friend gave me!\n","```"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aMmA-BQdeYfi","executionInfo":{"status":"ok","timestamp":1654941068370,"user_tz":-540,"elapsed":20,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"823f99e4-ed25-492f-892d-6235638ab9ad"},"source":["# Hook - Example of using a program's execution logic analysis\n","def hook_analysis(x):\n","    print(f'hook for analysis, current value is {x}')\n","\n","# Add hook to generated package\n","package.hooks = []\n","package.hooks.append(hook_analysis)\n","\n","# Ìå®ÌÇ§ÏßÄ Ïã§Ìñâ\n","input = 3\n","output = package(input)\n","\n","# Ìå®ÌÇ§ÏßÄ Í≤∞Í≥º\n","print(f\"Package Process Result! [ input {input} ] [ output {output} ]\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["program A processing!\n","hook for analysis, current value is 6\n","program B processing!\n","hook for analysis, current value is 3\n","Package Process Result! [ input 3 ] [ output 3 ]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ijgpx3s6fLAO","executionInfo":{"status":"ok","timestamp":1654941068705,"user_tz":-540,"elapsed":348,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"4dcb0b86-18ec-4805-ff6a-557a5478b3d3"},"source":["# Hook - Example of adding features to a program\n","def hook_multiply(x):\n","    print('hook for multiply')\n","    return x * 3\n","\n","# Add hook to generated package\n","package.hooks = []\n","package.hooks.append(hook_multiply)\n","\n","# Ìå®ÌÇ§ÏßÄ Ïã§Ìñâ\n","input = 3\n","output = package(input)\n","\n","# Ìå®ÌÇ§ÏßÄ Í≤∞Í≥º\n","print(f\"Package Process Result! [ input {input} ] [ output {output} ]\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["program A processing!\n","hook for multiply\n","program B processing!\n","hook for multiply\n","Package Process Result! [ input 3 ] [ output 45 ]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RxWqcHgBg2PU","executionInfo":{"status":"ok","timestamp":1654941068706,"user_tz":-540,"elapsed":61,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"d29f190a-14c2-4fcb-cccd-e9663442d005"},"source":["# Ïó¨Îü¨Í∞úÏùò hookÏùÑ ÎÑ£ÏùÑ Ïàò ÏûàÎã§\n","package.hooks = []\n","package.hooks.append(hook_multiply)\n","package.hooks.append(hook_analysis)\n","\n","# Ìå®ÌÇ§ÏßÄ Ïã§Ìñâ\n","input = 3\n","output = package(input)\n","\n","# Ìå®ÌÇ§ÏßÄ Í≤∞Í≥º\n","print(f\"Package Process Result! [ input {input} ] [ output {output} ]\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["program A processing!\n","hook for multiply\n","hook for analysis, current value is 18\n","program B processing!\n","hook for multiply\n","hook for analysis, current value is 45\n","Package Process Result! [ input 3 ] [ output 45 ]\n"]}]},{"cell_type":"markdown","metadata":{"id":"sVflo4JVhIHV"},"source":["``` python\n","ü¶Ü\n","In the example hook given by a friend, only after the program runs\n","You can use the hook function!\n","\n","When designing a package, if you put a hook in front of or behind the program,\n","We can execute our custom function both before and after the program runs!\n","\n","So that you can use hook before running the program\n","I created an interface called pre_hook!\n","```"]},{"cell_type":"code","metadata":{"id":"o1iz3uPh9I4b"},"source":["def program_A(x):\n","    print('program A processing!')\n","    return x + 3\n","\n","def program_B(x):\n","    print('program B processing!')\n","    return x - 3\n","\n","class Package(object):\n","    \"\"\"ÌîÑÎ°úÍ∑∏Îû® AÏôÄ BÎ•º Î¨∂Ïñ¥ÎÜìÏùÄ Ìå®ÌÇ§ÏßÄ ÏΩîÎìú\"\"\"\n","    def __init__(self):\n","        self.programs = [program_A, program_B]\n","\n","        # hooks\n","        self.pre_hooks = []\n","        self.hooks = []\n","\n","    def __call__(self, x):\n","        for program in self.programs:\n","            \n","            # pre_hook\n","            if self.pre_hooks:\n","                for hook in self.pre_hooks:\n","                    output = hook(x)\n","                    if output:\n","                        x = output\n","\n","            x = program(x)\n","\n","            # hook\n","            if self.hooks:\n","                for hook in self.hooks:\n","                    output = hook(x)\n","                    if output:\n","                        x = output\n","\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YvZi6GDLh9iJ"},"source":["``` python\n","ü¶Ü\n","I sent the above code to my friend and he complimented me!\n","\n","It's up to the designer to decide where to put the hook!\n","In the example you sent me, I made a hook interface on the package,\n","They said that we could create a hook interface inside the program!\n","\n","In this case, you can use different hooks for each program\n","They said it's better to customize!\n","```"]},{"cell_type":"markdown","metadata":{"id":"70LM7F_OjMqB"},"source":["##### üí° PyTorchÏùò hook\n","> ü¶Ü Î∂ÄÎçïÏù¥Í∞Ä ÏΩîÎìúÎ•º ÏûëÏÑ±Ìï¥Ï£ºÏóàÏñ¥Ïöî\n","\n","``` python\n","ü¶Ü\n","After I understood the hook, I looked at what kind of hook is in PyTorch!\n","It was divided into two main categories!\n","\n","- Hook applied to Tensor\n","- Hook to apply to Module\n","```"]},{"cell_type":"markdown","metadata":{"id":"pR6xLrKogJoy"},"source":["```python\n","ü¶Ü\n","Tensor can enter can be found at \"_ _ backward hooks\" in!\n","\n","Unlike module tensor, backward hook million!\n","Forward hook and find out, but there isn`t!\n","\n","```\n","- [register_hook - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.Tensor.register_hook.html#torch.Tensor.register_hook)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N75CZzOwie3a","executionInfo":{"status":"ok","timestamp":1654941068707,"user_tz":-540,"elapsed":39,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"a07bddd5-60a7-40c3-f7b6-f3a7da5ca4f4"},"source":["import torch\n","\n","tensor = torch.rand(1, requires_grad=True)\n","\n","def tensor_hook(grad):\n","    pass\n","\n","tensor.register_hook(tensor_hook)\n","\n","# ü¶Ü The tensor only has a backup hook!\n","\n","tensor._backward_hooks"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict([(0, <function __main__.tensor_hook>)])"]},"metadata":{},"execution_count":80}]},{"cell_type":"markdown","metadata":{"id":"dJ_ll23vibx-"},"source":["```python\n","ü¶Ü\n","All hooks registered in nn.Module can be checked at once by using \"__dict__\"!\n","\n","```\n","\n","- [register_forward_pre_hook - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=hook#torch.nn.Module.register_forward_pre_hook)\n","- [register_forward_hook - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=hook#torch.nn.Module.register_forward_hook)\n","- [register_backward_hook - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=hook#torch.nn.Module.register_backward_hook)\n","- [register_full_backward_hook - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=register_full#torch.nn.Module.register_full_backward_hook)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f522pSdWXgGA","executionInfo":{"status":"ok","timestamp":1654941068708,"user_tz":-540,"elapsed":31,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"998d2a60-be79-410d-9732-977290a1ef0b"},"source":["from torch import nn\n","\n","class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","def module_hook(grad):\n","    pass\n","\n","model = Model()\n","model.register_forward_pre_hook(module_hook)\n","model.register_forward_hook(module_hook)\n","model.register_full_backward_hook(module_hook)\n","\n","# ü¶Ü __dict__ contains all variables of the module and important information such as parameters and hooks!\n","# Don't forget to use the module when you need it in the future as it is a space for storing information\n","model.__dict__"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'_backward_hooks': OrderedDict([(3, <function __main__.module_hook>)]),\n"," '_buffers': OrderedDict(),\n"," '_forward_hooks': OrderedDict([(2, <function __main__.module_hook>)]),\n"," '_forward_pre_hooks': OrderedDict([(1, <function __main__.module_hook>)]),\n"," '_is_full_backward_hook': True,\n"," '_load_state_dict_pre_hooks': OrderedDict(),\n"," '_modules': OrderedDict(),\n"," '_non_persistent_buffers_set': set(),\n"," '_parameters': OrderedDict(),\n"," '_state_dict_hooks': OrderedDict(),\n"," 'training': True}"]},"metadata":{},"execution_count":81}]},{"cell_type":"markdown","metadata":{"id":"UxX-trOlrvjh"},"source":["```python\n","ü¶Ü\n","When I checked \"__dict__\", I found the following 5 things!\n","\n","- - forward_pre_hooks\n","- - forward_hooks\n","- - backward_hooks # deprecated\n","- - full_backward_hooks\n","- - state_dict_hooks # used internally\n","\n","I think I know when you use it by looking at the name\n","Hooks are called at the time of forward and backward, right?\n","\n","- For forward, there are pre_hooks and hooks\n","- There's only a hook in the poem for backward!\n","- In the case of state_dict, there's a hook, but we don't use it\n","The \"load_state_dict\" function is used internally!\n","The contents are written in the attached link below!\n","\n","I didn't know that nn.Module made this space called hook!\n","Since we got to know each other well, let's use it if we have a chance!\n","\n","Every time I run the module, the module checks whether there is a registered hook or not\n","Wouldn't module be sad if there's no hook registered every time?\n","\n","I think I'll be so sad.\n","```\n","- [Invoking Time of nn.Module _register_state_dict_hook() - PyTorch Forum](https://discuss.pytorch.org/t/invoking-time-of-nn-module-register-state-dict-hook/108163)"]},{"cell_type":"markdown","metadata":{"id":"1r2HJhPzCqZM"},"source":["##### üí° forward hook\n","``` python\n","ü¶Ü\n","You'll understand better if you use it yourself, right?\n","\n","It's a forward hook that can only be applied to modules! Let's use it together!\n","```\n","\n","**Module**\n","- [register_forward_pre_hook - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=hook#torch.nn.Module.register_forward_pre_hook)\n","- [register_forward_hook - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=hook#torch.nn.Module.register_forward_hook)"]},{"cell_type":"markdown","metadata":{"id":"RfanMq-Et5gc"},"source":["``` python\n","ü¶Ü\n","Let's find out what values are propagated to the Add model!\n","I'm sure you'll find out if it's a list and a forward hook that you made in advance!\n","```"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AMmXBTDhtOIc","executionInfo":{"status":"ok","timestamp":1654941068708,"user_tz":-540,"elapsed":24,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"1d68b47c-86c3-4561-fb9f-c7ead482b00b"},"source":["import torch\n","from torch import nn\n","\n","\n","# Do not modify the Add model!\n","\n","class Add(nn.Module):\n","    def __init__(self):\n","        super().__init__() \n","\n","    def forward(self, x1, x2):\n","        output = torch.add(x1, x2)\n","\n","        return output\n","\n","# Î™®Îç∏ ÏÉùÏÑ±\n","add = Add()\n","\n","# TODO:Put the answers in the list in order of x1, x2, and output\n","answer = [1, 2, 3]\n","\n","\n","\n","# TODO : Use pre_hook to find out the values of x1, x2 and save them in answer\n","def pre_hook(module, input):\n","    answer[0] = input[0]\n","    answer[1] = input[1]\n","    return input\n","\n","# TODO : Use the hook to find the output value and save it to the answer\n","def hook(module, input, output):\n","    answer[2] = output\n","    return output\n","\n","add.register_forward_pre_hook(pre_hook)\n","add.register_forward_hook(hook)\n","\n","# ÏïÑÎûò ÏΩîÎìúÎäî ÏàòÏ†ïÌïòÏã§ ÌïÑÏöîÍ∞Ä ÏóÜÏäµÎãàÎã§!\n","x1 = torch.rand(1)\n","x2 = torch.rand(1)\n","\n","output = add(x1, x2)\n","\n","if answer == [x1, x2, output]:\n","    print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","else:\n","    print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n"]}]},{"cell_type":"markdown","metadata":{"id":"OyygsrsQD_4E"},"source":["``` python\n","ü¶Ü\n","Phew, I think it was harder than I thought!\n","Maybe it's because I'm not used to it yet!\n","\n","We just saved the values that are spread through the model using hook\n","Not only this, but I heard that it is possible to modify the propagation value!\n","\n","Let's see if it's really possible!\n","```"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dj7hpOeCEv5-","executionInfo":{"status":"ok","timestamp":1654941068709,"user_tz":-540,"elapsed":18,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"5ff3e035-2f0c-4652-84d4-84845a2f01ad"},"source":["import torch\n","from torch import nn\n","\n","# Do not modify the Add model!\n","\n","class Add(nn.Module):\n","    def __init__(self):\n","        super().__init__() \n","\n","    def forward(self, x1, x2):\n","        output = torch.add(x1, x2)\n","\n","        return output\n","\n","# Î™®Îç∏ ÏÉùÏÑ±\n","add = Add()\n","\n","\n","#  TODO : Use hook to add 5 to the output value that is propagated!\n","\n","def hook(module, input, output):\n","    return output + 5\n","\n","add.register_forward_hook(hook)\n","\n","# You do not need to modify the code below!\n","\n","x1 = torch.rand(1)\n","x2 = torch.rand(1)\n","\n","output = add(x1, x2)\n","\n","if output == x1 + x2 + 5:\n","    print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","else:\n","    print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n"]}]},{"cell_type":"markdown","metadata":{"id":"XdSszPOlFg2C"},"source":["``` python\n","ü¶Ü\n","We did it! We modified the propagation value!\n","\n","Hook, that's very powerful!\n","I think it'll be really useful if you use it well!\n","\n","Where else can I use it?\n","I read the comments below out of curiosity, and I think there are good examples!\n","\n","There's also a topic related to the background hook\n","I need to practice the backup hook and finish reading this part!\n","```\n","\n","**‚ú® Ïú†Ïö©Ìïú ÏûêÎ£å ‚ú®**\n","- [How to Use PyTorch Hooks - Medium](https://medium.com/the-dl/how-to-use-pytorch-hooks-5041d777f904)\n","- [PyTorch 101, Part 5: Understanding Hooks - Paperspace blog](https://blog.paperspace.com/pytorch-hooks-gradient-clipping-debugging/)"]},{"cell_type":"markdown","metadata":{"id":"IA_-_-XdtJwT"},"source":["##### üí° backward hook\n","``` python\n","ü¶Ü\n","The forward hook can only be applied to modules,\n","The backward hook can be applied to the sensor and module!\n","\n","Let's use it together!\n","```\n","\n","**Tensor**\n","- [register_hook - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.Tensor.register_hook.html#torch.Tensor.register_hook)\n","\n","**Module**\n","- [register_backward_hook - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=hook#torch.nn.Module.register_backward_hook)\n","- [register_full_backward_hook - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=register_full#torch.nn.Module.register_full_backward_hook)"]},{"cell_type":"markdown","metadata":{"id":"3qIlAHSCy19v"},"source":["``` python\n","ü¶Ü\n","Now! you start to deal with gradientI am so excited!\n","In the model radio back when backpropagation gradient value that is find out together!\n","\n","Forward list and like they've done in backward hook, must be possible!\n","```"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BT96uu7WYURO","executionInfo":{"status":"ok","timestamp":1654941069064,"user_tz":-540,"elapsed":366,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"0291d841-a4ae-4997-c0df-c350f05145cf"},"source":["import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","\n","\n","# Model Î™®Îç∏ÏùÑ ÏàòÏ†ïÌïòÏßÄ ÎßàÏÑ∏Ïöî! \n","class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.W = Parameter(torch.Tensor([5]))\n","\n","    def forward(self, x1, x2):\n","        output = x1 * x2\n","        output = output * self.W\n","\n","        return output\n","\n","# Î™®Îç∏ ÏÉùÏÑ±\n","model = Model()\n","\n","\n","# TODO: The answer, 1, 2 ; grad x grad x grad, output list in order to put one by one!\n","answer = []\n","\n","# TODO : hookÎ•º Ïù¥Ïö©Ìï¥ÏÑú x1.grad, x2.grad, output.grad Í∞íÏùÑ ÏïåÏïÑÎÇ¥ answerÏóê Ï†ÄÏû•ÌïòÏÑ∏Ïöî\n","# Using hook x1.grad x2.grad output.grad answer out to the store. a value, grad output\n","def module_hook(module, grad_input, grad_output):\n","    answer.append(grad_input[0])\n","    answer.append(grad_input[1])\n","    answer.append(grad_output[0])\n","\n","model.register_full_backward_hook(module_hook)\n","# You do not need to modify the code below!\n","x1 = torch.rand(1, requires_grad=True)\n","x2 = torch.rand(1, requires_grad=True)\n","\n","output = model(x1, x2)\n","output.retain_grad()\n","output.backward()\n","\n","if answer == [x1.grad, x2.grad, output.grad]:\n","    print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","else:\n","    print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n"]}]},{"cell_type":"markdown","metadata":{"id":"bHkgQGZm35q4"},"source":["``` python\n","ü¶Ü\n","The module-by-module backward hook is really good,\n","Based on the module, only the input, output gradient values are taken\n","The gradient value of the sensor inside the module cannot be determined!\n","\n","So I want to know the gradient value of Parameter W of the model,\n","I can't figure it out with module unit backward hook!\n","\n","I should use the tensor backup hook!\n","```"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PG0_rueTaYj3","executionInfo":{"status":"ok","timestamp":1654941069065,"user_tz":-540,"elapsed":28,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"80ba0968-aba0-4fd8-9076-5fc7be3df1c2"},"source":["import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","\n","class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.W = Parameter(torch.Tensor([5]))\n","\n","    def forward(self, x1, x2):\n","        output = x1 * x2\n","        output = output * self.W\n","\n","        return output\n","\n","# Î™®Îç∏ ÏÉùÏÑ±\n","model = Model()\n","\n","\n","# TODO: Save the gradient value of Parameter W in the model!\n","answer = []\n","\n","# TODO : Use the hook to find the gradient value of W and store it in the answer\n","\n","def tensor_hook(grad):\n","    answer.append(grad)\n","\n","model.W.register_hook(tensor_hook)\n","# You do not need to modify the code below!\n","\n","x1 = torch.rand(1, requires_grad=True)\n","x2 = torch.rand(1, requires_grad=True)\n","\n","output = model(x1, x2)\n","output.backward()\n","\n","if answer == [model.W.grad]:\n","    print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","else:\n","    print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n"]}]},{"cell_type":"markdown","metadata":{"id":"EQtbwyLO6Z7p"},"source":["``` python\n","ü¶Ü\n","Now, we're going to use any of the models' sensors\n","I was able to figure out the gradient value I wanted!\n","\n","By the way, can the backward hook also affect the flow of gradient values?\n","```"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J-C4I5fX6AE8","executionInfo":{"status":"ok","timestamp":1654941069406,"user_tz":-540,"elapsed":359,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"1d12bc7a-3b5b-43f3-9414-1015f797eee3"},"source":["import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","\n","class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.W = Parameter(torch.Tensor([5]))\n","\n","    def forward(self, x1, x2):\n","        output = x1 * x2\n","        output = output * self.W\n","\n","        return output\n","\n","# Model generation\n","model = Model()\n","\n","\n","# TODO : Use the hook to make the sum of the gradient outputs of the module equal to 1!\n","#        ex) (1.5, 0.5) -> (0.75, 0.25)\n","def module_hook(module, grad_input, grad_output):\n","    total = 0\n","    for grad in grad_input:\n","      total+=grad\n","    grad_input = torch.divide(grad_input[0],total), torch.divide(grad_input[1],total)\n","    return grad_input\n","\n","model.register_full_backward_hook(module_hook)   \n","# You do not need to modify the code below!\n","\n","x1 = torch.rand(1, requires_grad=True)\n","x2 = torch.rand(1, requires_grad=True)\n","\n","output = model(x1, x2)\n","output.backward()\n","\n","if x1.grad + x2.grad == 1:\n","    print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","else:\n","    print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n"]}]},{"cell_type":"markdown","metadata":{"id":"rOY2fP6aR1d8"},"source":["``` python\n","ü¶Ü\n","\n","We've covered both the `forward hook` and the `backward hooks`!\n","Phew! It was really hard!\n","\n","But I'm very happy that I learned a useful function!\n","I think I can do the next thing!\n","\n","- Visualize changes in gradient values\n","- Gradient exporting alert notification when gradient exceeds a certain threshold\n","- If the gradient value of a particular sensor is observed to become too large or too small,\n","Gradient clipping for the corresponding tensor only\n","\n","Oh! Come to think of it, I was practicing and reading the forward hook and it reminded me of the document!\n","I'll have to finish reading about the backup hook!\n","\n","I found a video clip and it explains the hook in detail well!\n","I'll have to see it when I want to know more about the principles of hook\n","```\n","\n","**‚ú® Ïú†Ïö©Ìïú ÏûêÎ£å ‚ú®**\n","- [How to Use PyTorch Hooks - Medium](https://medium.com/the-dl/how-to-use-pytorch-hooks-5041d777f904)\n","- [PyTorch 101, Part 5: Understanding Hooks - Paperspace blog](https://blog.paperspace.com/pytorch-hooks-gradient-clipping-debugging/)\n","- [PyTorch Hooks Explained - In-depth Tutorial - YouTube](https://www.youtube.com/watch?v=syLFCVYua6Q)"]},{"cell_type":"markdown","metadata":{"id":"tz48RlN1_6t_"},"source":["#### üë®‚Äçüíª <font color='green'><b>[ ÏΩîÎî© ]</b></font> apply\n","\n","``` python\n","ü¶Ü\n","This is my drill I think I can explain!Study hard!\n","\n","We are of the pytorch nn module is box that I learned together!\n","That is why module module may include the other module can go into!\n","\n","When all of those module the other in one module.\n","We call a set of model these huge module!\n","\n","The model with numerous module module a complex mix with each other.\n","(tree) or graphs can be seen as a (graph) tree!\n","\n","Something to the model is applied, not just at the top one of the module.\n","All shall be applied to models that make up the entire module.\n","A nn module method of the mostly internal support for it!\n","\n","We don't care. if applied \"cpu ().\" as an example for the top module\n","To all that exists at the bottom of the module module with \"cpu ().\"!\n","\n","Then module the already been implemented, not a method nn.\n","What if you want to apply to the model the function of our own custom?\n","Belonging to the model every function shall be applied to all module?\n","\n","The use of \"apply\" is what someone working!\n","Cot to apply the function is not did well to come home?They can be used with!\n","```\n","\n","- [Documentation main - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/index.html)\n","- [apply - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=apply#torch.nn.Module.apply)\n"]},{"cell_type":"markdown","metadata":{"id":"5kOCk33KLR8i"},"source":["##### üí° apply ÏòàÏ†ú\n","\n","``` python\n","ü¶Ü\n","I can understand the functions that I've never seen before by using the example of Documentation!\n","I brought the example written in the apply function\n","```\n","- [apply - PyTorch Í≥µÏãù Î¨∏ÏÑú](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=apply#torch.nn.Module.apply)"]},{"cell_type":"code","metadata":{"id":"P7tUi0q0CVap","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654941069408,"user_tz":-540,"elapsed":24,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"46c97b24-9bbf-4fcb-f716-5dd294a2a438"},"source":["import torch\n","from torch import nn\n","\n","@torch.no_grad()\n","def init_weights(m):\n","    print(m)\n","    if type(m) == nn.Linear:\n","        m.weight.fill_(1.0)\n","        print(m.weight)\n","\n","net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n","net.apply(init_weights)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Linear(in_features=2, out_features=2, bias=True)\n","Parameter containing:\n","tensor([[1., 1.],\n","        [1., 1.]], requires_grad=True)\n","Linear(in_features=2, out_features=2, bias=True)\n","Parameter containing:\n","tensor([[1., 1.],\n","        [1., 1.]], requires_grad=True)\n","Sequential(\n","  (0): Linear(in_features=2, out_features=2, bias=True)\n","  (1): Linear(in_features=2, out_features=2, bias=True)\n",")\n"]},{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): Linear(in_features=2, out_features=2, bias=True)\n","  (1): Linear(in_features=2, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":87}]},{"cell_type":"markdown","metadata":{"id":"kdSFfplQPgg9"},"source":["```python\n","ü¶Ü\n","Aha! So the function that is applied through apply receives module as input!\n","I think all the modules of the model are input and processed sequentially!\n","\n","The apply function is commonly used for weight initialization!\n","I think it means that the value of the sensor specified by Parameter is specified as the desired value!\n","But I'm still unfamiliar with it, so I don't know if it's accurate!\n","When I saw the chords like \"m.weight.fill_\", I suddenly had a headache.\n","```"]},{"cell_type":"markdown","metadata":{"id":"b7RtvqiWNGen"},"source":["##### üí° Î∂ÄÎçïÏù¥ Î™®Îç∏ apply - Module Ï∂úÎ†•Ìï¥Î≥¥Í∏∞\n","\n","\n","``` python\n","ü¶Ü\n","I don't understand something just from the examples!\n","I'll have to bring back the model I made before and apply it!\n","```"]},{"cell_type":"code","metadata":{"id":"wBfaXAWNN6-C"},"source":["import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","\n","\n","# You do not need to modify the code below!\n","# But look at the code below and understand it as much as you can before you do the task below!\n","\n","# Function\n","class Function_A(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(1))\n","\n","    def forward(self, x):\n","        return x + self.W\n","\n","class Function_B(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(1))\n","\n","    def forward(self, x):\n","        return x - self.W\n","\n","class Function_C(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(1))\n","\n","    def forward(self, x):\n","        return x * self.W\n","\n","class Function_D(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(1))\n","\n","    def forward(self, x):\n","        return x / self.W\n","\n","\n","# Layer\n","class Layer_AB(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.a = Function_A('plus')\n","        self.b = Function_B('substract')\n","\n","    def forward(self, x):\n","        x = self.a(x)\n","        x = self.b(x)\n","\n","        return x\n","\n","class Layer_CD(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.c = Function_C('multiply')\n","        self.d = Function_D('divide')\n","\n","    def forward(self, x):\n","        x = self.c(x)\n","        x = self.d(x)\n","\n","        return x\n","\n","\n","# Model\n","class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.ab = Layer_AB()\n","        self.cd = Layer_CD()\n","\n","    def forward(self, x):\n","        x = self.ab(x)\n","        x = self.cd(x)\n","\n","        return x\n","\n","\n","model = Model()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I-3cdt8TR3_v","executionInfo":{"status":"ok","timestamp":1654941069410,"user_tz":-540,"elapsed":18,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"082531b6-145b-4593-8b37-bdd167f336f3"},"source":["def print_module(module):\n","    print(module)\n","    print(\"-\" * 30)\n","\n","# ü¶Ü Please return the module that has been applied!\n","\n","returned_module = model.apply(print_module)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Function_A()\n","------------------------------\n","Function_B()\n","------------------------------\n","Layer_AB(\n","  (a): Function_A()\n","  (b): Function_B()\n",")\n","------------------------------\n","Function_C()\n","------------------------------\n","Function_D()\n","------------------------------\n","Layer_CD(\n","  (c): Function_C()\n","  (d): Function_D()\n",")\n","------------------------------\n","Model(\n","  (ab): Layer_AB(\n","    (a): Function_A()\n","    (b): Function_B()\n","  )\n","  (cd): Layer_CD(\n","    (c): Function_C()\n","    (d): Function_D()\n","  )\n",")\n","------------------------------\n"]}]},{"cell_type":"markdown","metadata":{"id":"4oFU67qIS-KA"},"source":["``` python\n","ü¶Ü\n","Aha! Apply applies functions to modules using Postorder Traversal method!\n","I think I understand now!\n","```\n","\n","- [4 Types of Tree Traversal Algorithms - Towards Data Science](https://towardsdatascience.com/4-types-of-tree-traversal-algorithms-d56328450846)"]},{"cell_type":"markdown","metadata":{"id":"RX9s5bAEZR81"},"source":["##### üí° model apply - weight initialization\n","\n","\n","``` python\n","ü¶Ü\n","The term weight initialization is unfamiliar\n","As expected, it was right to initialize the parameter value!\n","\n","The model I made has a total of 4 parameters, so let's reset all the values to 1!\n","```\n","\n","üéÅ **ÌûåÌä∏** üéÅ\n","- [How to initialize weights in PyTorch? - Stack Overflow](https://stackoverflow.com/questions/49433936/how-to-initialize-weights-in-pytorch)"]},{"cell_type":"code","metadata":{"id":"FJHv20B8ZR9E"},"source":["import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","\n","\n","# You do not need to modify the code below!\n","# Just do it and move on to the next cell!\n","\n","# Function\n","class Function_A(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(1))\n","\n","    def forward(self, x):\n","        return x + self.W\n","\n","class Function_B(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(1))\n","\n","    def forward(self, x):\n","        return x - self.W\n","\n","class Function_C(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(1))\n","\n","    def forward(self, x):\n","        return x * self.W\n","\n","class Function_D(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(1))\n","\n","    def forward(self, x):\n","        return x / self.W\n","\n","\n","# Layer\n","class Layer_AB(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.a = Function_A('plus')\n","        self.b = Function_B('substract')\n","\n","    def forward(self, x):\n","        x = self.a(x)\n","        x = self.b(x)\n","\n","        return x\n","\n","class Layer_CD(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.c = Function_C('multiply')\n","        self.d = Function_D('divide')\n","\n","    def forward(self, x):\n","        x = self.c(x)\n","        x = self.d(x)\n","\n","        return x\n","\n","\n","# Model\n","class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.ab = Layer_AB()\n","        self.cd = Layer_CD()\n","\n","    def forward(self, x):\n","        x = self.ab(x)\n","        x = self.cd(x)\n","\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_jifkSJbZR9F","executionInfo":{"status":"ok","timestamp":1654941069703,"user_tz":-540,"elapsed":17,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"8cf0420a-158c-4061-a038-7432bc6da111"},"source":["model = Model()\n","\n","# TODO : Use apply to set all parameter values to 1\n","\n","def weight_initialization(module):\n","    module_name = module.__class__.__name__\n","    module.W = Parameter(torch.Tensor(1))\n","\n","\n","# ü¶Ü Please return the module that has been applied!\n","\n","returned_module = model.apply(weight_initialization)\n","\n","\n","# You do not need to modify the code below!\n","x = torch.rand(1)\n","\n","output = model(x)\n","\n","if torch.isclose(output, x):\n","    print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","else:\n","    print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n"]}]},{"cell_type":"markdown","metadata":{"id":"tXUDj5guCimd"},"source":["``` python\n","ü¶Ü\n","When you take the Pretrained model and use it, use the parameter that you want\n","I think it's possible to add a backup hook!\n","```"]},{"cell_type":"markdown","metadata":{"id":"g_Aa_VhGg5ds"},"source":["##### üí° <font color='yellow'><b>[ Optional ]</b></font> üî•  Model apply - Modify repr üî•\n","\n","``` python\n","ü¶Ü\n","If you print out the current model, it looks like this!\n","\n","‚ùå Ïã§Ï†ú Ï∂úÎ†• Í≤∞Í≥º\n","Model(\n","  (ab): Layer_AB(\n","    (a): Function_A()\n","    (b): Function_B()\n","  )\n","  (cd): Layer_CD(\n","    (c): Function_C()\n","    (d): Function_D()\n","  )\n",")\n","\n","I want to make it printed as follows.\n","\n","‚úÖ ideal output\n","\n","Model(\n","  (ab): Layer_AB(\n","    (a): Function_A(name=plus)\n","    (b): Function_B(name=substract)\n","  )\n","  (cd): Layer_CD(\n","    (c): Function_C(name=multiply)\n","    (d): Function_D(name=divide)\n","  )\n",")\n","\n","Let's modify repr output message using apply!\n","```\n","\n","üéÅ **ÌûåÌä∏** üéÅ\n","- [Any elegant way to add a method to an existing object in python? - Stack Overflow](https://stackoverflow.com/questions/30294458/any-elegant-way-to-add-a-method-to-an-existing-object-in-python/30294947)"]},{"cell_type":"code","metadata":{"id":"UR1C9k7-g-my"},"source":["#@title Î∂ÄÎçïÏù¥ Î™®Îç∏\n","import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","\n","\n","# You do not need to modify the code below!\n","# Just do it and move on to the next cell!\n","\n","\n","# Function\n","class Function_A(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(1))\n","\n","    def forward(self, x):\n","        return x + self.W\n","\n","class Function_B(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(1))\n","\n","    def forward(self, x):\n","        return x - self.W\n","\n","class Function_C(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(1))\n","\n","    def forward(self, x):\n","        return x * self.W\n","\n","class Function_D(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(1))\n","\n","    def forward(self, x):\n","        return x / self.W\n","\n","\n","# Layer\n","class Layer_AB(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.a = Function_A('plus')\n","        self.b = Function_B('substract')\n","\n","    def forward(self, x):\n","        x = self.a(x)\n","        x = self.b(x)\n","\n","        return x\n","\n","class Layer_CD(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.c = Function_C('multiply')\n","        self.d = Function_D('divide')\n","\n","    def forward(self, x):\n","        x = self.c(x)\n","        x = self.d(x)\n","\n","        return x\n","\n","\n","# Model\n","class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.ab = Layer_AB()\n","        self.cd = Layer_CD()\n","\n","    def forward(self, x):\n","        x = self.ab(x)\n","        x = self.cd(x)\n","\n","        return x\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OOq-Hv_ruX-y","executionInfo":{"status":"ok","timestamp":1654941070036,"user_tz":-540,"elapsed":337,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"d78da1ac-a7b3-47b1-e9eb-c3202474ac29"},"source":["model = Model()\n","\n","# TODO : Use apply to modify the repr output as Budeok wants!\n","from functools import partial\n","\n","def function_repr(self):\n","    return f'name={self.name}'\n","\n","def add_repr(module):\n","    module_name = module.__class__.__name__\n","    try:\n","      print(function_repr(module))\n","      initial_repr = lambda repr:repr\n","      module.extra_repr = partial(initial_repr, function_repr(module))\n","    except:\n","      pass\n","\n","\n","# ü¶Ü Please return the module that has been `apply`!\n","\n","returned_module = model.apply(add_repr)\n","\n","\n","# The following code is a modification aren't necessary!\n","\n","model_repr = repr(model)\n","\n","print(\"Î™®Îç∏ Ï∂úÎ†• Í≤∞Í≥º\")\n","print(\"-\" * 30)\n","print(model_repr)\n","print(\"-\" * 30)\n","\n","answer = \"Model(\\n  (ab): Layer_AB(\\n    (a): Function_A(name=plus)\\n    (b): Function_B(name=substract)\\n  )\\n  (cd): Layer_CD(\\n    (c): Function_C(name=multiply)\\n    (d): Function_D(name=divide)\\n  )\\n)\"\n","\n","if model_repr == answer:\n","    print(\"üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","    print(\"ü¶Ü ÎÑàÎ¨¥ Í≥†ÎßàÏõåÏöî ÍΩâÍΩâ!\")\n","else:\n","    print(\"ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["name=plus\n","name=substract\n","name=multiply\n","name=divide\n","Î™®Îç∏ Ï∂úÎ†• Í≤∞Í≥º\n","------------------------------\n","Model(\n","  (ab): Layer_AB(\n","    (a): Function_A(name=plus)\n","    (b): Function_B(name=substract)\n","  )\n","  (cd): Layer_CD(\n","    (c): Function_C(name=multiply)\n","    (d): Function_D(name=divide)\n","  )\n",")\n","------------------------------\n","üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n","ü¶Ü ÎÑàÎ¨¥ Í≥†ÎßàÏõåÏöî ÍΩâÍΩâ!\n"]}]},{"cell_type":"markdown","metadata":{"id":"RYMJgAEQZR9G"},"source":["``` python\n","ü¶Ü\n","Can be! at any time want to add to the model desired module method\n","Something where, and applications will be a lot!\n","```"]},{"cell_type":"markdown","metadata":{"id":"dim6OGlSD4Hk"},"source":["##### üí° <font color='yellow'><b>[ Optional ]</b></font> üî•üî•üî• Î∂ÄÎçïÏù¥ Î™®Îç∏ apply - Modify `Function` (Black Magic)\n","üî•üî•üî•\n","\n","``` python\n","ü¶Ü\n","My friend looked at my model's code and gave me a question!\n","\n","There are currently four functions A, B, C, and D!\n","\n","- A : x + W\n","- B : x - W\n","- C : x * W\n","- D : x / W\n","\n","Change it to act like linear transformation like this!\n","\n","\n","- A : x @ W + b\n","- B : x @ W + b\n","- C : x @ W + b\n","- D : x @ W + b\n","\n","W is the parameter already created for each function\n","B is a new parameter!\n","\n","They say the calculation formula doesn't have to be the same, but the calculation should be the same!\n","They're going to verify that they made it using the \"nn.Linear\" model themselves!\n","\n","In order to compare the results, both W and B initialize the values to 1!\n","\n","Oh, now of value is to tensor scalar, not.\n","The size of 2 * 2! be careful on the fact that matrix\n","For some reason, I went and I never tease me that I can solve with!üí¢\n","```\n","\n","üéÅ **ÌûåÌä∏** üéÅ\n","- forward hook"]},{"cell_type":"code","metadata":{"id":"POOWtst-zqip"},"source":["#@title Test ÏΩîÎìú\n","\n","# code is under revision aren't necessary!\n","\n","def tester(model, friend_model):\n","    x = torch.rand(2, 2, requires_grad=True)\n","\n","    # The model we created\n","    output = model(x)\n","    output = output.sum()\n","    output.backward()\n","\n","    our_grad = x.grad.clone()\n","    grads = [(name, param.grad) for name, param in model.named_parameters()]\n","\n","    x.grad = None\n","\n","    # A friend-generated model\n","    friend_output = friend_model(x)\n","    friend_output = friend_output.sum()\n","    friend_output.backward()\n","\n","    friend_grad = x.grad.clone()\n","    friend_grads = [(name, param.grad) for name, param in friend_model.named_parameters()]\n","\n","    # a total result\n","    total_result = 0\n","\n","    # Compare the number of parameters\n","    if len(grads) == len(friend_grads):\n","        print(\"\\x1b[32m[PASS]\\x1b[0m Îëê Î™®Îç∏Ïù¥ Í∞ôÏùÄ Parameter Í∞ØÏàòÎ•º Í∞ÄÏßÄÎÑ§Ïöî!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m Îëê Î™®Îç∏Ïù¥ Îã§Î•∏ Parameter Í∞ØÏàòÎ•º Í∞ÄÏßÄÎÑ§Ïöî!\")\n","        print(f\"ü¶Ü Ïö∞Î¶¨ Î™®Îç∏ Parameter Í∞ØÏàò : {len(grads)} üê¶ ÏπúÍµ¨ Î™®Îç∏ Parameter Í∞ØÏàò : {len(friend_grads)}\")\n","        return\n","\n","    print(\"-\" * 50)\n","\n","    # Parameter name check\n","    params = []\n","    for grad in grads:\n","        param = ''.join(grad[0].split('.')[1:])\n","        params.append(param)\n","\n","    if 'ab' in params:\n","        print(\"\\x1b[32m[PASS]\\x1b[0m Function_AÏóê Parameter bÎ•º ÎßåÎìúÏÖ®ÎÑ§Ïöî!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m Function_AÏóê Parameter bÍ∞Ä ÏóÜÏñ¥Ïöî!\")\n","        return\n","    print(\"-\" * 50)\n","\n","    if 'bb' in params:\n","        print(\"\\x1b[32m[PASS]\\x1b[0m Function_BÏóê Parameter bÎ•º ÎßåÎìúÏÖ®ÎÑ§Ïöî!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m Function_BÏóê Parameter bÍ∞Ä ÏóÜÏñ¥Ïöî!\")\n","        return\n","    print(\"-\" * 50)\n","\n","    if 'cb' in params:\n","        print(\"\\x1b[32m[PASS]\\x1b[0m Function_CÏóê Parameter bÎ•º ÎßåÎìúÏÖ®ÎÑ§Ïöî!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m Function_CÏóê Parameter bÍ∞Ä ÏóÜÏñ¥Ïöî!\")\n","        return\n","    print(\"-\" * 50)\n","\n","    if 'db' in params:\n","        print(\"\\x1b[32m[PASS]\\x1b[0m Function_DÏóê Parameter bÎ•º ÎßåÎìúÏÖ®ÎÑ§Ïöî!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m Function_DÏóê Parameter bÍ∞Ä ÏóÜÏñ¥Ïöî!\")\n","        return\n","    print(\"-\" * 50)\n","\n","    # Parameter initialization check\n","    if torch.all(torch.stack([torch.all(param == 1) for param in model.parameters()])):\n","        print(\"\\x1b[32m[PASS]\\x1b[0m Parameter W, bÎ•º Î™®Îëê 1Î°ú Ï¥àÍ∏∞ÌôîÏãúÌÇ§ÏÖ®ÎÑ§Ïöî!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m Parameter W, bÎ•º Î™®Îëê 1Î°ú Ï¥àÍ∏∞ÌôîÏãúÌÇ§ÏÑ∏Ïöî!\")\n","        return\n","    print(\"-\" * 50)\n","\n","    # Check the model output value\n","    if torch.isclose(output, friend_output):\n","        print(\"\\x1b[32m[PASS]\\x1b[0m Îëê Î™®Îç∏Ïù¥ ÎèôÏùºÌïú Ï∂úÎ†•Í∞íÏùÑ Í∞ÄÏßÄÎÑ§Ïöî!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m Îëê Î™®Îç∏Ïù¥ Îã§Î•∏ Ï∂úÎ†•Í∞íÏùÑ Í∞ÄÏßÄÎÑ§Ïöî!\")\n","        print(f\"ü¶Ü Ïö∞Î¶¨ Î™®Îç∏ Ï∂úÎ†•Í∞í : {output:.2f} üê¶ ÏπúÍµ¨ Î™®Îç∏ Ï∂úÎ†•Í∞í : {friend_output:.2f}\")\n","    print(\"-\" * 50)\n","\n","    # Input value x gradient check\n","    if torch.all(torch.isclose(our_grad, friend_grad)):\n","        print(\"\\x1b[32m[PASS]\\x1b[0m ÏûÖÎ†•Ïóê ÏÇ¨Ïö©Îêú xÍ∞Ä ÎèôÏùºÌïú Gradient Í∞íÏùÑ Í∞ÄÏßÄÎÑ§Ïöî!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m ÏûÖÎ†•Ïóê ÏÇ¨Ïö©Îêú xÍ∞Ä Îã§Î•∏ Gradient Í∞íÏùÑ Í∞ÄÏßÄÎÑ§Ïöî!\")\n","        print(f\"ü¶Ü Ïö∞Î¶¨ Î™®Îç∏ x grad Í∞í\\n{our_grad}\\nüê¶ ÏπúÍµ¨ Î™®Îç∏ x grad Í∞í\\n{friend_grad}\")\n","    print(\"-\" * 50)\n","\n","    # Function A gradient check\n","    if torch.all(torch.isclose(grads[0][1], friend_grads[0][1])):\n","        print(\"\\x1b[32m[PASS]\\x1b[0m Function_A Parameter WÍ∞Ä ÎèôÏùºÌïú Gradient Í∞íÏùÑ Í∞ÄÏßÄÎÑ§Ïöî!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m Parameter WÍ∞Ä Îã§Î•∏ Gradient Í∞íÏùÑ Í∞ÄÏßÄÎÑ§Ïöî!\")\n","        print(f\"ü¶Ü Ïö∞Î¶¨ Î™®Îç∏ Function_A Parameter W grad Í∞í\\n{grads[0][1]}\\nüê¶ ÏπúÍµ¨ Î™®Îç∏ nn.Linear Parameter W grad Í∞í\\n{friend_grads[0][1]}\")\n","    print(\"-\" * 50)\n","\n","    if torch.all(torch.isclose(grads[1][1], friend_grads[1][1])):\n","        print(\"\\x1b[32m[PASS]\\x1b[0m Function_A Parameter bÍ∞Ä ÎèôÏùºÌïú Gradient Í∞íÏùÑ Í∞ÄÏßÄÎÑ§Ïöî!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m Parameter bÍ∞Ä Îã§Î•∏ Gradient Í∞íÏùÑ Í∞ÄÏßÄÎÑ§Ïöî!\")\n","        print(f\"ü¶Ü Ïö∞Î¶¨ Î™®Îç∏ Function_A Parameter b grad Í∞í\\n{grads[1][1]}\\nüê¶ ÏπúÍµ¨ Î™®Îç∏ nn.Linear Parameter b grad Í∞í\\n{friend_grads[1][1]}\")\n","    print(\"-\" * 50)\n","\n","    # Function B gradient check\n","    if torch.all(torch.isclose(grads[2][1], friend_grads[2][1])):\n","        print(\"\\x1b[32m[PASS]\\x1b[0m Function_B Parameter WÍ∞Ä ÎèôÏùºÌïú Gradient Í∞íÏùÑ Í∞ÄÏßÄÎÑ§Ïöî!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m Parameter WÍ∞Ä Îã§Î•∏ Gradient Í∞íÏùÑ Í∞ÄÏßÄÎÑ§Ïöî!\")\n","        print(f\"ü¶Ü Ïö∞Î¶¨ Î™®Îç∏ Function_B Parameter W grad Í∞í\\n{grads[2][1]}\\nüê¶ ÏπúÍµ¨ Î™®Îç∏ nn.Linear Parameter W grad Í∞í\\n{friend_grads[2][1]}\")\n","    print(\"-\" * 50)\n","\n","    if torch.all(torch.isclose(grads[3][1], friend_grads[3][1])):\n","        print(\"\\x1b[32m[PASS]\\x1b[0m Function_B Parameter bÍ∞Ä ÎèôÏùºÌïú Gradient Í∞íÏùÑ Í∞ÄÏßÄÎÑ§Ïöî!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m Parameter bÍ∞Ä Îã§Î•∏ Gradient Í∞íÏùÑ Í∞ÄÏßÄÎÑ§Ïöî!\")\n","        print(f\"ü¶Ü Ïö∞Î¶¨ Î™®Îç∏ Function_B Parameter b grad Í∞í\\n{grads[3][1]}\\nüê¶ ÏπúÍµ¨ Î™®Îç∏ nn.Linear Parameter b grad Í∞í\\n{friend_grads[3][1]}\")\n","    print(\"-\" * 50)\n","\n","    # Function C gradient check\n","    if torch.all(torch.isclose(grads[4][1], friend_grads[4][1])):\n","        print(\"\\x1b[32m[PASS]\\x1b[0m Function_C Parameter WÍ∞Ä ÎèôÏùºÌïú Gradient Í∞íÏùÑ Í∞ÄÏßÄÎÑ§Ïöî!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m Parameter WÍ∞Ä Îã§Î•∏ Gradient Í∞íÏùÑ Í∞ÄÏßÄÎÑ§Ïöî!\")\n","        print(f\"ü¶Ü Ïö∞Î¶¨ Î™®Îç∏ Function_C Parameter W grad Í∞í\\n{grads[4][1]}\\nüê¶ ÏπúÍµ¨ Î™®Îç∏ nn.Linear Parameter W grad Í∞í\\n{friend_grads[4][1]}\")\n","    print(\"-\" * 50)\n","\n","    if torch.all(torch.isclose(grads[5][1], friend_grads[5][1])):\n","        print(\"\\x1b[32m[PASS]\\x1b[0m Function_C Parameter bÍ∞Ä ÎèôÏùºÌïú Gradient Í∞íÏùÑ Í∞ÄÏßÄÎÑ§Ïöî!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m Parameter bÍ∞Ä Îã§Î•∏ Gradient Í∞íÏùÑ Í∞ÄÏßÄÎÑ§Ïöî!\")\n","        print(f\"ü¶Ü Ïö∞Î¶¨ Î™®Îç∏ Function_C Parameter b grad Í∞í\\n{grads[5][1]}\\nüê¶ ÏπúÍµ¨ Î™®Îç∏ nn.Linear Parameter b grad Í∞í\\n{friend_grads[5][1]}\")\n","    print(\"-\" * 50)\n","\n","    # Function D gradient check\n","    if torch.all(torch.isclose(grads[6][1], friend_grads[6][1])):\n","        print(\"\\x1b[32m[PASS]\\x1b[0m Function_D Parameter WÍ∞Ä ÎèôÏùºÌïú Gradient Í∞íÏùÑ Í∞ÄÏßÄÎÑ§Ïöî!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m Parameter WÍ∞Ä Îã§Î•∏ Gradient Í∞íÏùÑ Í∞ÄÏßÄÎÑ§Ïöî!\")\n","        print(f\"ü¶Ü Ïö∞Î¶¨ Î™®Îç∏ Function_D Parameter W grad Í∞í\\n{grads[6][1]}\\nüê¶ ÏπúÍµ¨ Î™®Îç∏ nn.Linear Parameter W grad Í∞í\\n{friend_grads[6][1]}\")\n","    print(\"-\" * 50)\n","\n","    if torch.all(torch.isclose(grads[7][1], friend_grads[7][1])):\n","        print(\"\\x1b[32m[PASS]\\x1b[0m Function_D Parameter bÍ∞Ä ÎèôÏùºÌïú Gradient Í∞íÏùÑ Í∞ÄÏßÄÎÑ§Ïöî!\")\n","        total_result += 1\n","    else:\n","        print(\"\\x1b[31m[FAIL]\\x1b[0m Parameter bÍ∞Ä Îã§Î•∏ Gradient Í∞íÏùÑ Í∞ÄÏßÄÎÑ§Ïöî!\")\n","        print(f\"ü¶Ü Ïö∞Î¶¨ Î™®Îç∏ Function_D Parameter b grad Í∞í\\n{grads[7][1]}\\nüê¶ ÏπúÍµ¨ Î™®Îç∏ nn.Linear Parameter b grad Í∞í\\n{friend_grads[7][1]}\")\n","    print(\"-\" * 50)\n","\n","\n","    if total_result == 16:\n","        print(f\"\\x1b[32m[ALL PASS {total_result}/16]\\x1b[0m üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\")\n","    else:\n","        print(f\"\\x1b[31m[FAIL {total_result}/16]\\x1b[0m ü¶Ü Îã§Ïãú ÎèÑÏ†ÑÌï¥Î¥êÏöî!\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9fvtuqHDD4H2"},"source":["#@title Î∂ÄÎçïÏù¥ Î™®Îç∏\n","import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","\n","\n","# You do not need to modify the code below!\n","# Just do it and move on to the next cell!\n","\n","# Function\n","class Function_A(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(2, 2))\n","\n","    def forward(self, x):\n","        return x + self.W\n","\n","class Function_B(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(2, 2))\n","\n","    def forward(self, x):\n","        return x - self.W\n","\n","class Function_C(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(2, 2))\n","\n","    def forward(self, x):\n","        return x * self.W\n","\n","class Function_D(nn.Module):\n","    def __init__(self, name):\n","        super().__init__()\n","        self.name = name\n","        self.W = Parameter(torch.rand(2, 2))\n","\n","    def forward(self, x):\n","        return x / self.W\n","\n","\n","# Layer\n","class Layer_AB(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.a = Function_A('plus')\n","        self.b = Function_B('substract')\n","\n","    def forward(self, x):\n","        x = self.a(x)\n","        x = self.b(x)\n","\n","        return x\n","\n","class Layer_CD(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.c = Function_C('multiply')\n","        self.d = Function_D('divide')\n","\n","    def forward(self, x):\n","        x = self.c(x)\n","        x = self.d(x)\n","\n","        return x\n","\n","\n","# Model\n","class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.ab = Layer_AB()\n","        self.cd = Layer_CD()\n","\n","    def forward(self, x):\n","        x = self.ab(x)\n","        x = self.cd(x)\n","\n","        return x\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hE_Tl4H_kSp3","executionInfo":{"status":"ok","timestamp":1654941070930,"user_tz":-540,"elapsed":339,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"da75d645-f290-40ff-9ce0-3925c1871498"},"source":["model = Model()\n","\n","\n","# TODO : Add Parameter b using apply!\n","def add_bias(module):\n","    module_name = module.__class__.__name__\n","    if module_name.split('_')[0] == \"Function\":\n","      module.b = Parameter(torch.rand(2,1))\n","\n","# TODO : Please initialize the added b degree value to 1 using the application!\n","def weight_initialization(module):\n","    module_name = module.__class__.__name__\n","    add_bias(module)\n","\n","    if module_name.split('_')[0] == \"Function\":\n","        module.W.data.fill_(1.)\n","        module.b.data.fill_(1.0)\n","\n","def hook(module, input, output):\n","    module_name = module.__class__.__name__  \n","    output = input[0] @ module.W.T # = torch.mul(input[0],module.W.T)\n","    output = torch.add(output, module.b)\n","    return output\n","\n","\n","# TODO : Use apply to change all functions to linear transformation!\n","\n","#        X @ W + b\n","def linear_transformation(module):\n","    module_name = module.__class__.__name__\n","\n","    if module_name.split('_')[0] == \"Function\":\n","      module.register_forward_hook(hook)\n","\n","\n","returned_module = model.apply(add_bias)\n","returned_module = model.apply(weight_initialization)\n","returned_module = model.apply(linear_transformation)\n","\n","\n","\n","# ü¶Ü A friend of comparisons to the code and drew up!\n","\n","class FriendLinearModel(nn.Module):\n","    def __init__(self):\n","        super().__init__() \n","        self.linear = nn.Sequential(nn.Linear(2, 2),\n","                                    nn.Linear(2, 2),\n","                                    nn.Linear(2, 2),\n","                                    nn.Linear(2, 2))\n","\n","    def forward(self, x):\n","        return self.linear(x)\n","\n","def friends_init_weights(m):\n","    if type(m) == nn.Linear:\n","        m.weight.data.fill_(1.0)\n","        m.bias.data.fill_(1.0)\n","\n","def friends_init_weights(m):\n","    if type(m) == nn.Linear:\n","        m.weight.data.fill_(1.0)\n","        m.bias.data.fill_(1.0)\n","\n","friend_model = FriendLinearModel()\n","friend_model.apply(friends_init_weights)\n","\n","\n","# ü¶Ü Ï≤¥ÌÅ¨Ìï¥Î≥¥ÏÑ∏Ïöî!\n","grads = tester(model, friend_model)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[32m[PASS]\u001b[0m Îëê Î™®Îç∏Ïù¥ Í∞ôÏùÄ Parameter Í∞ØÏàòÎ•º Í∞ÄÏßÄÎÑ§Ïöî!\n","--------------------------------------------------\n","\u001b[32m[PASS]\u001b[0m Function_AÏóê Parameter bÎ•º ÎßåÎìúÏÖ®ÎÑ§Ïöî!\n","--------------------------------------------------\n","\u001b[32m[PASS]\u001b[0m Function_BÏóê Parameter bÎ•º ÎßåÎìúÏÖ®ÎÑ§Ïöî!\n","--------------------------------------------------\n","\u001b[32m[PASS]\u001b[0m Function_CÏóê Parameter bÎ•º ÎßåÎìúÏÖ®ÎÑ§Ïöî!\n","--------------------------------------------------\n","\u001b[32m[PASS]\u001b[0m Function_DÏóê Parameter bÎ•º ÎßåÎìúÏÖ®ÎÑ§Ïöî!\n","--------------------------------------------------\n","\u001b[32m[PASS]\u001b[0m Parameter W, bÎ•º Î™®Îëê 1Î°ú Ï¥àÍ∏∞ÌôîÏãúÌÇ§ÏÖ®ÎÑ§Ïöî!\n","--------------------------------------------------\n","\u001b[32m[PASS]\u001b[0m Îëê Î™®Îç∏Ïù¥ ÎèôÏùºÌïú Ï∂úÎ†•Í∞íÏùÑ Í∞ÄÏßÄÎÑ§Ïöî!\n","--------------------------------------------------\n","\u001b[32m[PASS]\u001b[0m ÏûÖÎ†•Ïóê ÏÇ¨Ïö©Îêú xÍ∞Ä ÎèôÏùºÌïú Gradient Í∞íÏùÑ Í∞ÄÏßÄÎÑ§Ïöî!\n","--------------------------------------------------\n","\u001b[32m[PASS]\u001b[0m Function_A Parameter WÍ∞Ä ÎèôÏùºÌïú Gradient Í∞íÏùÑ Í∞ÄÏßÄÎÑ§Ïöî!\n","--------------------------------------------------\n","\u001b[32m[PASS]\u001b[0m Function_A Parameter bÍ∞Ä ÎèôÏùºÌïú Gradient Í∞íÏùÑ Í∞ÄÏßÄÎÑ§Ïöî!\n","--------------------------------------------------\n","\u001b[32m[PASS]\u001b[0m Function_B Parameter WÍ∞Ä ÎèôÏùºÌïú Gradient Í∞íÏùÑ Í∞ÄÏßÄÎÑ§Ïöî!\n","--------------------------------------------------\n","\u001b[32m[PASS]\u001b[0m Function_B Parameter bÍ∞Ä ÎèôÏùºÌïú Gradient Í∞íÏùÑ Í∞ÄÏßÄÎÑ§Ïöî!\n","--------------------------------------------------\n","\u001b[32m[PASS]\u001b[0m Function_C Parameter WÍ∞Ä ÎèôÏùºÌïú Gradient Í∞íÏùÑ Í∞ÄÏßÄÎÑ§Ïöî!\n","--------------------------------------------------\n","\u001b[32m[PASS]\u001b[0m Function_C Parameter bÍ∞Ä ÎèôÏùºÌïú Gradient Í∞íÏùÑ Í∞ÄÏßÄÎÑ§Ïöî!\n","--------------------------------------------------\n","\u001b[32m[PASS]\u001b[0m Function_D Parameter WÍ∞Ä ÎèôÏùºÌïú Gradient Í∞íÏùÑ Í∞ÄÏßÄÎÑ§Ïöî!\n","--------------------------------------------------\n","\u001b[32m[PASS]\u001b[0m Function_D Parameter bÍ∞Ä ÎèôÏùºÌïú Gradient Í∞íÏùÑ Í∞ÄÏßÄÎÑ§Ïöî!\n","--------------------------------------------------\n","\u001b[32m[ALL PASS 16/16]\u001b[0m üéâüéâüéâ ÏÑ±Í≥µ!!! üéâüéâüéâ\n"]}]},{"cell_type":"markdown","metadata":{"id":"t_Ka8OvED4H4"},"source":["``` python\n","ü¶Ü\n","252 / 5000Î∞úÏùåÎì£Í∏∞Î≥µÏÇ¨ÌïòÍ∏∞ÌïÑÍ∏∞Ïù∏ÏãùÍ∏∞Î≤àÏó≠ÌïòÍ∏∞ÏûêÎèôÏôÑÏÑ±ÏûêÎèôÏôÑÏÑ±\t\n","ÏòÅÏñ¥Ïó¥Í∏∞/Îã´Í∏∞ ÏïÑÏù¥ÏΩò\n","Bear in mind this point!\n","\n","Hugh really hard!But I'm totally shocked!\n","Never risk angering the model code already been produced and into new models!\n","Even \"a nn linear\" models and fully carried out as of the pytorch!\n","All!, forward backward\n","\n","Is not only can do, but using apply using apply, I do it. \"\n","I feel increased readability and the function is under control!\n","\n","But Where is the use of it?\n","```\n","```python\n","üê¶\n","\n","I heard you helped me a lot with this assignment!\n","As expected, there's no way that Boo-duk can do this alone!\n","\n","In the future, you'll be using a lot of pretrained models using PyTorch\n","There may be bugs in the model itself or things that need to be modified.\n","In this case, training to modify the model you practiced here today will be of great help!\n","\n","Honestly, I didn't know I'd solve it, but I was really surprised! I give you my compliments!\n","```"]},{"cell_type":"markdown","metadata":{"id":"aI-eQLReB_b0"},"source":["### üéâüéâüéâ nn.Module ÏôÑÎ£å! üéâüéâüéâ\n","\n","```python\n","ü¶Ü\n","I can't believe I've come this far!\n","I didn't know anything about PyTorch, so now I can make the model I want!\n","I know I still have a lot to learn, but I'm so happy!\n","```\n","\n","To create a custom model\n","Congratulations on successfully finishing the show even though it was not a small amount! üéâ<br>\n","This chapter was as difficult as Documentation.<br>\n","But you've come all the way here after overcoming it all! This is a really great thing.\n","\n","I'm sure you're very tired! But don't worry! Now that we've come this far, it's all over<br>\n","It's about Github, but it's close to a resting corner.<br>\n","It doesn't take much time and the content is short, so you can relax now!<br>"]},{"cell_type":"markdown","metadata":{"id":"gsjw07-c6Vgf"},"source":["## üöÄ <font color='yellow'><b>[ Optional ]</b></font> See Github for Custom Model Creation\n","\n","\n","```\n","üí° How are other people creating custom models?\n","We will have time to visit Github and find out the answer.\n","```\n","\n","# üåçüê£\n","We're ready to build custom models!<br>\n","Although it was not an easy journey, you made it and now you are ready to go on a trip.<br>\n","It's time to leave the Earth.\n","\n","# ‚≠êüê§\n","There are various and complex models in the world. The knowledge I learned here is that there aren't as many huge, complex, flashy models as there are stars in the universe, but there are so many. The knowledge I learned here isn't much, but it's now enough to stand up and face the models. If you want to back down because it's difficult to fill in the gaps, it's time to hold out and move on. To the shining stars!\n","\n","# üöÄ\n","Shall we go meet the aliens who created the stars?\n","\n","- üõ∏ Find the Github Model\n","- üõ∏ Github Model License Check\n","- üõ∏ Explore the Github Repository\n","- üõ∏ Quote the Github model"]},{"cell_type":"markdown","metadata":{"id":"7hmoOk31nohg"},"source":["### üõ∏ Github Î™®Îç∏ Ï∞æÍ∏∞\n","> Let's take a quick look at some of the ways to find the Github model you want.\n","\n","\n","- üìñ <font color='gold' ><b>[ ÏùΩÍ∏∞ ]</b></font> Íµ¨Í∏Ä Í≥†Í∏â Í≤ÄÏÉâ (Google Advanced Search)\n","- üìñ <font color='gold' ><b>[ ÏùΩÍ∏∞ ]</b></font> ÍπÉÌóô Í≥†Í∏â Í≤ÄÏÉâ (Github Advanced Search)\n","- üìñ <font color='gold' ><b>[ ÏùΩÍ∏∞ ]</b></font> Model Curation Site\n"]},{"cell_type":"markdown","metadata":{"id":"OhQbpvUgaT45"},"source":["#### üìñ <font color='gold' ><b>[ ÏùΩÍ∏∞ ]</b></font> Íµ¨Í∏Ä Í≥†Í∏â Í≤ÄÏÉâ (Google Advanced Search)\n","``` python\n","ü¶Ü\n","I'm sure you thought of this chapter as soon as you came here!\n","Google is the must-see search tool of the day!\n","\n","But Google doesn't just search for the words it typed\n","Did you know that there are many different search options?\n","\n","Google Search is a program, too!\n","There's no way a well-made program doesn't have options!\n","The Google search window that you use is\n","In shell terms, it's an input box that takes commands!\n","\n","But in general, we just search for words and end it\n","I don't know what options Google Search has!\n","At times like these, the thing that anyone can use easily is\n","It's Google Advanced Search!\n","\n","Go to the link below and try it out!\n","If you fill in the items you want, you can enter them in the Google search box\n","Change it to a suitable query and search instead!\n","```\n","\n","- [Google Advanced Search](https://www.google.com/advanced_search)"]},{"cell_type":"markdown","metadata":{"id":"k0IQvtE8aUEY"},"source":["#### üìñ <font color='gold' ><b>[ ÏùΩÍ∏∞ ]</b></font> ÍπÉÌóô Í≥†Í∏â Í≤ÄÏÉâ (Github Advanced Search)\n","``` python\n","ü¶Ü\n","Did you know that Github is also capable of advanced search?\n","We offer a variety of options like Google, so let's take a look!\n","```\n","\n","- [Github Advanced Search](https://github.com/search/advanced)"]},{"cell_type":"markdown","metadata":{"id":"Bb_DEzPpaRc9"},"source":["#### üìñ <font color='gold' ><b>[ ÏùΩÍ∏∞ ]</b></font> Model Curation Site\n","\n","``` python\n","ü¶Ü\n","If you're not looking for a particular model, you're looking at the overall trend of the model\n","Visiting a curation site is one way!\n","```\n","\n","- [Browse State-of-the-Art - Papers With Code](https://paperswithcode.com/sota)\n","- [labml.ai Annotated PyTorch Paper Implementations - labml.ai](https://nn.labml.ai/)\n","- [awesome-deeplearning-resources - endymecy](https://endymecy.github.io/awesome-deeplearning-resources/awesome_projects.html)"]},{"cell_type":"markdown","metadata":{"id":"aowwiHAz3I2c"},"source":["### üõ∏ Github Model License Check\n","> Once you find the Github model, you must first verify your license. Check whether the original author allowed the model to be used freely, or whether the code was restricted to be used to prevent future legal problems.\n","\n","- üìñ <font color='gold' ><b>[ ÏùΩÍ∏∞ ]</b></font> Open Source License Types\n","\n","- üìñ <font color='gold' ><b>[ ÏùΩÍ∏∞ ]</b></font> Github Model License Check\n","\n","- üìñ <font color='gold' ><b>[ ÏùΩÍ∏∞ ]</b></font> Can I use a model that doesn't show a license?\n"]},{"cell_type":"markdown","metadata":{"id":"EGO21TZ0N_Iu"},"source":["#### üìñ <font color='gold' ><b>[ ÏùΩÍ∏∞ ]</b></font> Open Source License Types\n","\n","\n","``` python\n","ü¶Ü\n","Before you verify the license of the model found in Github,\n","It's important to know what kinds of open source licenses are first!\n","\n","It's well organized on the site below, so let's watch it together!\n","```\n","\n","- [Choosing the right license - Github Docs](https://docs.github.com/en/github/creating-cloning-and-archiving-repositories/creating-a-repository-on-github/licensing-a-repository#choosing-the-right-license)\n","- [Choose an open source license - Choose AI License](https://choosealicense.com/)\n","- [Ïò§ÌîàÏÜåÏä§Î•º ÏÇ¨Ïö©ÌïòÍ≥† Ï§ÄÎπÑÌïòÎäî Í∞úÎ∞úÏûêÎ•º ÏúÑÌïú Í∞ÄÏù¥Îìú - if(kakao) dev 2018](https://tv.kakao.com/channel/3150758/cliplink/391717603)"]},{"cell_type":"markdown","metadata":{"id":"q2IFscSgPqj0"},"source":["#### üìñ <font color='gold' ><b>[ ÏùΩÍ∏∞ ]</b></font> Github Î™®Îç∏ ÎùºÏù¥ÏÑºÏä§ Ï≤¥ÌÅ¨\n","\n","``` python\n","ü¶Ü\n","Hugging Face is a really famous library for natural language processing!\n","Shall we look at the licenses of the transformers model together?\n","```\n","\n","- [transformers - Hugging Face Github](https://github.com/huggingface/transformers)\n"]},{"cell_type":"markdown","metadata":{"id":"0oOO5qzH2vXq"},"source":["![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/hugging%20face%20license.png?raw=true)\n","![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/apache%20license%202.0.png?raw=true)"]},{"cell_type":"markdown","metadata":{"id":"tApDeubq27rZ"},"source":["``` python\n","ü¶Ü\n","\n","It's following Apache License 2.0!\n","It's a free license that's commercially available!\n","But if you take the source code and use it, you have to specify the license and copyright\n","If you modified the source code you took and used, you have to specify this as well!\n","\n","There are restrictions, but even if you make commercial products using the hugging face,\n","You don't have to reveal the code, so you can use it to make the product with confidence!\n","\n","Since we're talking about licenses, as above,\n","Is it legal to take screenshots of Github's products? Is it illegal?\n","\n","If you are curious, please find the link below for the screenshot!\n","```\n","\n","**‚ú® Ïú†Ïö©Ìïú ÏûêÎ£å ‚ú®**\n","- [Apache License 2.0 - OLIS](https://www.olis.or.kr/license/Detailselect.do?lId=1002&mapCode=010002)\n","- [Commons:Screenshots - Wikimedia Commons](https://commons.wikimedia.org/wiki/Commons:Screenshots)"]},{"cell_type":"markdown","metadata":{"id":"D1Jje0IwRejE"},"source":["#### üìñ <font color='gold' ><b>[ ÏùΩÍ∏∞ ]</b></font> Can I use a model that doesn't show a license?\n","\n","\n","``` python\n","ü¶Ü\n","Github on license when looked in the various models when there was no!\n","May I use these models.?\n","\n","The following documents, find out together!\n","```\n","\n","- [No License - Choose AI License](https://choosealicense.com/no-permission/)"]},{"cell_type":"markdown","metadata":{"id":"C5EzHAPj3LW8"},"source":["### üõ∏ Github Repository ÌÉêÏÉâ\n","> Github provides the ability to navigate Repository. Let's take a quick look at how to take advantage of it.\n","\n","- üìñ <font color='gold' ><b>[ ÏùΩÍ∏∞ ]</b></font> Find models hidden in the Repository\n","\n","- üìñ <font color='gold' ><b>[ ÏùΩÍ∏∞ ]</b></font> View transformers.py Internal Table of Contents\n"]},{"cell_type":"markdown","metadata":{"id":"rSyB0wutN_Oi"},"source":["#### üìñ <font color='gold' ><b>[ ÏùΩÍ∏∞ ]</b></font> Find models hidden in the Repository\n","\n","\n","``` python\n","ü¶Ü\n","I'm trying to find the Transformer model code on the official Github code base of PyTorch\n","As soon as I enter the main page of PyTorch's official Github, I'm already dizzy with that huge amount of code!\n","\n","My friend who didn't see me told me to use the search function provided by Github!\n","```\n","\n","- [PyTorch - Github](https://github.com/pytorch/pytorch)"]},{"cell_type":"markdown","metadata":{"id":"K4TqNcE3PZbi"},"source":["``` python\n","ü¶Ü\n","Github Í≤ÄÏÉâÌïòÎäî Í≥≥ÏùÑ Ï∞æÏïòÏñ¥Ïöî!\n","```\n","\n","![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/github%20-%20pytorch.png?raw=true)"]},{"cell_type":"markdown","metadata":{"id":"og22SSY0QHxY"},"source":["``` python\n","ü¶Ü\n","When I enter transformer, there are 3 types of searches!\n","\n","- In this repository\n","- In this organization\n","- All Github\n","\n","What we want is to search inside the Repository, so we pressed the top one!\n","```\n","\n","![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/github%20-%20pytorch%20-%20search%20bar.png?raw=true)"]},{"cell_type":"markdown","metadata":{"id":"upJpvsqvQna2"},"source":["``` python\n","ü¶Ü\n","The result of the transformer search appears in the PyTorch official code!\n","But what I want is not a transformer model with c++ code\n","It's a transformer model made of python!\n","\n","Should I scroll down a little bit?\n","```\n","\n","![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/github%20-%20pytorch%20-%20transformer.png?raw=true)"]},{"cell_type":"markdown","metadata":{"id":"FnRVVIycQ8Cj"},"source":["``` python\n","ü¶Ü\n","transformer.py! I found it! I think we can click and go in now!\n","\n","I can't believe me! What a nice search box!\n","```\n","\n","![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/github%20-%20pytorch%20-%20transformer%20found.png?raw=true)"]},{"cell_type":"markdown","metadata":{"id":"E5k7RfnzRRo9"},"source":["``` python\n","ü¶Ü\n","Class Transformer! This is exactly the model I wanted!\n","\n","Looking at the path, it`s pytorch/torch/nn/modules/transformer.py!\n","I'd be pretty lost if I tried to find it myself!\n","```\n","\n","![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/transformers.png?raw=true)"]},{"cell_type":"markdown","metadata":{"id":"pSIGoFyWRoJ2"},"source":["#### üìñ <font color='gold' ><b>[ ÏùΩÍ∏∞ ]</b></font> View transformers.py Internal Table of Contents\n","\n","\n","``` python\n","ü¶Ü\n","If you want to check what classes and functions are available on transformer.py,\n","It would be troublesome to scroll down and check, right?\n","\n","Where can I find a table of contents inside transformers.py?\n","```\n","\n","- [transformer.py - Github](https://github.com/pytorch/pytorch/blob/35307b131df9d24bfa96103d6061cf14c797ee32/torch/nn/modules/transformer.py)"]},{"cell_type":"markdown","metadata":{"id":"gq6zcLvVRpXB"},"source":["``` python\n","ü¶Ü\n","Îπ®Í∞ÑÏÉâ Î∞ïÏä§Ïùò Jump toÎ•º Ïù¥Ïö©ÌïòÎ©¥ Ï¢ãÏïÑÏöî!\n","```\n","\n","![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/transformer%20-%20jump%20to.png?raw=true)"]},{"cell_type":"markdown","metadata":{"id":"ZziNxuyzSNKE"},"source":["``` python\n","ü¶Ü\n","Each function and class is shown in the order, can you see it?\n","Scroll does not explore with the complex code table of contents can see!\n","```\n","\n","![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/transformers%20-%20insider%20search.png?raw=true)"]},{"cell_type":"markdown","metadata":{"id":"u7iF0gyR3dZa"},"source":["### üõ∏ Github Î™®Îç∏ Ïù∏Ïö©\n","> GithubÏóêÏÑú Î†àÌçºÎü∞Ïä§(Reference) Î™®Îç∏ÏùÑ ÏÑ±Í≥µÏ†ÅÏúºÎ°ú Ï∞æÏùÄ Ïù¥ÌõÑ pip install, Î≥µÏÇ¨ Î∂ôÏó¨ÎÑ£Í∏∞, ÌòπÏùÄ git clone Îì± ÏûêÏã†ÎßåÏùò Î∞©Î≤ïÏúºÎ°ú Î™®Îç∏ ÏΩîÎìúÎ•º Í∞ÄÏ†∏ÏôîÏùÑ Í≤ÉÏûÖÎãàÎã§.In general, we are often leave a link or let it go.However, in a direct quote is a courtesy for authorship in principle cited (cite) with precisely the time to see how lightly.\n","\n","- üìñ <font color='gold' ><b>[ ÏùΩÍ∏∞ ]</b></font> If a Citation is provided\n","\n","- üìñ <font color='gold' ><b>[ ÏùΩÍ∏∞ ]</b></font> If the Citation is not available\n"]},{"cell_type":"markdown","metadata":{"id":"HxAcbyy-axop"},"source":["#### üìñ <font color='gold' ><b>[ ÏùΩÍ∏∞ ]</b></font>  If a Citation is provided\n","\n","``` python\n","ü¶Ü\n","Like PyTorch and Hugging Face, famous and official\n","Github projects usually provide Citations!\n","\n","However, the reference model is part of it\n","We don't offer Citations for each Github page!\n","\n","So here, I'm going to quote the Github model, which is where the Github model belongs\n","Please be careful to replace the Repository quote!\n","```\n","```python\n","üê¶ It's Github Repository City Citation!\n","```\n","- [PyTorch/CITATION - Github](https://github.com/pytorch/pytorch/blob/master/CITATION)\n","- [Huggingface/Transformers/citation - Github](https://github.com/huggingface/transformers#citation)\n","\n","```python\n","üê¶ Most of them follow the BibTex format, so use the conversion below!\n","\n","```\n","- [BibTeX Online Converter](https://bibtex.online/)"]},{"cell_type":"markdown","metadata":{"id":"PY5Rm509gNHe"},"source":["#### üìñ <font color='gold' ><b>[ ÏùΩÍ∏∞ ]</b></font> CitationÏù¥ Ï†úÍ≥µÎêòÏßÄ ÏïäÏùÑ Í≤ΩÏö∞\n","\n","``` python\n","ü¶Ü\n","It's always tricky to make your own quotes!\n","There are different ways to quote and it's troublesome to match it!\n","So in general, people quote roughly and pass it over!\n","\n","But at least here, let's find out how to quote properly!\n","```\n","```python\n","üê¶ If you want to create your own Citations, we recommend below!\n","```\n","\n","- [How to Cite a GitHub Repository - Wiki How](https://www.wikihow.com/Cite-a-GitHub-Repository)\n","\n","```python\n","üê¶ If you want an auto-completed city, you can do it at the following site!\n","\n","```\n","- [Free Harvard Citation Generator - Cite This For Me](https://www.citethisforme.com/citation-generator/harvard)"]},{"cell_type":"markdown","metadata":{"id":"AjV4kPz449Qf"},"source":["### üéâüéâüéâ Github ÏôÑÎ£å! üéâüéâüéâ\n","\n","```python\n","ü¶Ü\n","We're finally at the end! It's time to say goodbye!\n","I'll never forget studying together!\n","\n","See you again on Earth after the Boost Camp journey!\n","I'm going back to Earth now!\n","```"]},{"cell_type":"markdown","metadata":{"id":"Ixzc0txuqmDb"},"source":["## üéâüéäüéâ Ï∂ïÌïòÎìúÎ†§Ïöî! ÎÅùÍπåÏßÄ Ìï¥ÎÇ¥ÏÖ®Íµ∞Ïöî! üéâüéäüéâ\n","> This assignment contained a variety of but never a small amount of information about the custom model! Now you know what it takes to create a custom model, and if you're lacking something, you can find it and fill it out, and you have the knowledge to build the model you want! The process of getting here may never have been easy, but I hope it was worth it. I wish you the best of luck."]},{"cell_type":"code","metadata":{"cellView":"form","id":"v_fiPQLq700o","executionInfo":{"status":"ok","timestamp":1654941070931,"user_tz":-540,"elapsed":15,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"83035712-682b-49d2-dfca-f42de720ba51","colab":{"base_uri":"https://localhost:8080/","height":320}},"source":["#@title Î∂ÄÎçïÏù¥Í∞Ä Ï∂ïÌïòÏùò Ï∂§ÏùÑ Ï∂òÎåÄÏöî!\n","from IPython.display import Image\n","Image(url='https://post-phinf.pstatic.net/MjAxODEyMzFfMTAw/MDAxNTQ2MjE0OTg5NjAz.EHOabmOFRb9Sd4H1C8xJWAjDd-AalUHZ0mGRQc8nLJgg.QaKd2fe0gct3mQ-Ex-8qqSS1RVXjoC_-NLXo80sAQNsg.GIF/mug_obj_201812310909504083.gif?type=w1080')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.Image object>"],"text/html":["<img src=\"https://post-phinf.pstatic.net/MjAxODEyMzFfMTAw/MDAxNTQ2MjE0OTg5NjAz.EHOabmOFRb9Sd4H1C8xJWAjDd-AalUHZ0mGRQc8nLJgg.QaKd2fe0gct3mQ-Ex-8qqSS1RVXjoC_-NLXo80sAQNsg.GIF/mug_obj_201812310909504083.gif?type=w1080\"/>"]},"metadata":{},"execution_count":97}]},{"cell_type":"code","metadata":{"cellView":"form","id":"Eo7wLf2p7x_q","executionInfo":{"status":"ok","timestamp":1654941071250,"user_tz":-540,"elapsed":327,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"89165155-baad-47c5-e69e-bb77c2fe46a6","colab":{"base_uri":"https://localhost:8080/","height":294}},"source":["#@title Î∏åÎ†àÏù¥ÌÅ¨ÎåÑÏä§!\n","from IPython.display import Image\n","Image(url='https://www.wetrend.co.kr/data/editor2/wit_board/2102/07/1612656261_3c92e94dc4e55df68f76b46053008df8')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.Image object>"],"text/html":["<img src=\"https://www.wetrend.co.kr/data/editor2/wit_board/2102/07/1612656261_3c92e94dc4e55df68f76b46053008df8\"/>"]},"metadata":{},"execution_count":98}]},{"cell_type":"code","metadata":{"cellView":"form","id":"_9eeUgvl7M3O","executionInfo":{"status":"ok","timestamp":1654941071256,"user_tz":-540,"elapsed":51,"user":{"displayName":"Awol SEiD","userId":"04573728879877581209"}},"outputId":"da9b5b1a-9cff-45fa-923c-34055e5c872e","colab":{"base_uri":"https://localhost:8080/","height":370}},"source":["#@title Ïó¨Í∏∞ÏÑú Î©àÏ∂ú Ïàò ÏóÜÏßÄ! Ï∂§Ï∂∞ ÏπúÍµ¨Îì§!\n","from IPython.display import Image\n","Image(url='https://i.pinimg.com/originals/29/04/24/29042493fb118029b9014e4cb800c7ee.gif')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.Image object>"],"text/html":["<img src=\"https://i.pinimg.com/originals/29/04/24/29042493fb118029b9014e4cb800c7ee.gif\"/>"]},"metadata":{},"execution_count":99}]}]}